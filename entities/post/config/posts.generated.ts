// 이 파일은 scripts/generate-posts-data.ts 스크립트에 의해 생성되었습니다.
// 직접 수정하지 마세요.

import { GeneratedPostsMap } from '@/entities/post/model/types'

export const GENERATED_POSTS = {
  "ko": {
    "after-toy-project": {
      "slug": "after-toy-project",
      "date": "2023-10-14T00:00:00.000Z",
      "title": "소규모 프로젝트를 진행하면서 배운점",
      "description": "소규모 프로젝트를 진행하면서 배운 것들",
      "tags": [
        "회고"
      ],
      "section": "blog",
      "series": "",
      "thumbnail": "/public/posts/after-toy-project/storyboard.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRiYAAABXRUJQVlA4IBoAAAAwAQCdASoQABAABUB8JZwAA3AA/vB/j0AAAA==",
      "writer": "leey00nsu",
      "content": "\n## 소규모 프로젝트를 진행해보며\n\n학부생활을 하며 지금까지 여러 프로젝트를 경험해볼 수 있었습니다.\n\n아무것도 몰랐던 첫 프로젝트부터, 일 년이 지난 지금까지 협업을 겪으며 배우고 느낀 점을 적어보려고 합니다.\n\n### 기획의 중요성\n\n좋은 서비스를 만들기 위해서는 좋은 기획이 필요합니다.\n\n단순한 아이디어로부터 시작한 프로젝트도 , **여러 사람의 이야기를 더해나가면 좋은 프로젝트가 될 수 있습니다.**\n\n학부 레벨에서는 이러한 과정을 팀플 또는 동아리 활동밖에 없기 때문에, 다양한 경험을 하기 위해서는 **외부 대회나 행사에 많이 참가해보는 것이 좋은 것 같습니다.**\n\n### 프로젝트를 설계하는 방식\n\n`캡스톤 디자인` 과목에서 진행한 프로젝트에서 `순서도`와 `와이어프레임`에 대해서 멘토님께 자세히 배울 기회가 생겼습니다.\n\n![storyboard](/public/posts/after-toy-project/storyboard.png)\n\n![agile](/public/posts/after-toy-project/agile.png)\n\n먼저 `순서도`를 작성하고 , 순서도를 기반으로 `와이어 프레임`을 만듭니다.\n\n이때 **가장 중요한 것은 모든 팀원이 같은 생각을 가지고 있어야 한다는 점입니다.**\n\n지금까지 프로젝트를 하면서 힘들었던 점으로, 구두로 진행된 회의가 많았는데 문서로 정리하지 않다보니 했던 얘기를 또 하고 , **같은 질문을 반복하는 일**이 자주 발생했습니다.\n\n이를 방지하기 위해서라도 정확한 `문서`를 만들어서 이것을 베이스로 개발을 진행할 수 있어야 합니다.\n\n또한 `애자일 프로세스`에 대해서도 배울 수 있었습니다.\n\n### 어떻게 회의를 진행해야 할까?\n\n기존의 **주먹구구식 회의**에서 벗어나기 위하여 타 프로젝트들을 둘러보기 시작했습니다.\n\n그 중 `애자일 프로세스` 중 한 사이클을 빠르게 진행해보는 `스프린트`에 대해서, 구글 스프린트를 본따 진행된 [테오의 스프린트](https://velog.io/@teo/google-sprint-1)의 회고 글을 재미있게 읽고 적용해보게 되었습니다.\n\n![icebreaking](/public/posts/after-toy-project/icebreaking.png)\n![idea](/public/posts/after-toy-project/idea.png)\n\n원래 더 많은 과정이 있지만, `캔버스` → `아이디어 스케치` → `구현` 세 단계로 축소하여 적용하였습니다.\n\n`팀 캔버스`에서는 **팀원들의 생각을 자유롭게 적어보며 가벼운 아이스 브레이킹을 진행합니다.**\n\n`아이디어 스케치`에서는 **아이디어를 적어보며 발표를 통해 투표로 최종 아이디어를 선정합니다.**\n\n`구현` 에서는 **아이디어에 대해 각자 기능을 그려보며 최종적인 구현을 하기 위한 이야기를 나누었습니다.**\n\n이런 과정을 따라가다 보니 자연스럽게 `하나의 결과`에 도달할 수 있었습니다.\n\n최종 구현된 내용을 차치하고서라도 **이 과정을 도입한 결과 자체**에는 팀원 모두 만족하는 모습을 보았습니다.\n\n### 어떻게 협업을 해야할까?\n\n현업에서는 `github`는 물론, `slack`,`jira`와 같은 다양한 협업 툴을 사용한다고 알고 있습니다.\n\n그 중 jira 까지 배우기에는 타 팀원들에게 러닝커브가 있다고 생각되어 slack을 이용하여 팀원간의 소통을 진행했습니다.\n\ngithub에서는 팀 organization을 만들어 프론트엔드와 백엔드 레포지토리를 나누었으며,\n\nproject를 이용하여 **각 레포지토리의 이슈를 스프린트별로 트래킹할 수 있도록 하였습니다.**\n\n![sprint](/public/posts/after-toy-project/sprint.png)\n\n프로젝트들에서 `react`를 사용하였는데, **좀 더 나은 아키텍쳐 구조**를 구현하기 위하여 많은 고민 끝에 [좋은 글](https://github.com/alan2207/bulletproof-react)을 보게되어서 많은 참고가 되었습니다.\n\n여기에 `airbnb` 자바스크립트 스타일 가이드를 베이스로 하여 `eslint`와 `prettier` 규칙을 적용하여, 같은 팀원들 사이에 **동일한 코드 문법을 적용**하려고 노력하였습니다.\n\n### 결론\n\n항상 프로젝트를 진행하면서 느끼는 것이지만, 진행하면서 **이 부분은 이렇게 할 걸, 이 방식보다 다른 방식으로 진행하는게 더 좋았을텐데 하는 부분**이 존재합니다.\n\n그래도 프로젝트를 진행하면서 다음 프로젝트에는 더 나은 방식으로 해나갈 수 있다는 생각이 들면서\n\n성장해나가고 있다고 느끼고 있고, 계속해서 좋은 방식을 찾아 나가는 개발자가 되고 싶습니다.\n",
      "width": 2000,
      "height": 1968
    },
    "contribute-open-source": {
      "slug": "contribute-open-source",
      "date": "2024-02-16T00:00:00.000Z",
      "title": "오픈 소스에 기여해보기",
      "description": "오픈소스에 기여해 본 경험을 설명합니다.",
      "tags": [
        "octokit",
        "github",
        "open source"
      ],
      "section": "blog",
      "series": "",
      "thumbnail": "/public/posts/contribute-open-source/editor.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRjIAAABXRUJQVlA4ICYAAACwAQCdASoQAAsABUB8JaQAAudZHPQAAP7vtSdX42+oO6VIEKQAAA==",
      "writer": "leey00nsu",
      "content": "\r\n## 오픈 소스에 기여해보기\r\n\r\n### Octokit을 사용하여 커밋하기\r\n\r\n`블로그 서비스` 를 제작하던 중, CMS 기능을 추가하기 위하여 외부에서 깃허브에 파일을 가져오고 커밋하는 작업이 필요했습니다.\r\n\r\n깃허브에서는 [Octokit](https://github.com/octokit/rest.js) 이라는 라이브러리를 통해 REST API로 깃허브에 접근할 수 있도록 지원하고 있습니다.\r\n\r\n파일을 가져오는 것은 수월하였지만, **파일을 커밋하는 과정에서 큰 문제가 발생하였습니다.**\r\n\r\n현재 구현한 CMS 기능에서는, 유저가 에디터를 통해 마크다운 문서를 작성할 수 있도록 되어있습니다.\r\n\r\n![editor](/public/posts/contribute-open-source/editor.png)\r\n\r\n에디터에서 이미지를 업로드 할 경우 클라이언트 측에서 `File` 객체 형태로 이미지를 저장하고 있다가, 업로드를 누르면 Octokit을 이용하여 업로드하게 되어있습니다.\r\n\r\n하지만, Octokit에서 레포지토리에 커밋하기 위한 함수인 `octokit.rest.repos.createOrUpdateFile` 은 **하나의 커밋에 하나의 파일만 담을 수 있습니다.**\r\n\r\n커밋이 이미지의 개수만큼 발생하는 것을 원하지 않았기 때문에 방법을 찾던 중, 문서에서 `트리`를 이용하여 커밋할 수 있다는 것을 발견하였습니다.\r\n\r\n> 1. 브랜치의 트리 끝에 대한 참조를 가져옵니다.\r\n> 2. 커밋하려는 각 파일에 대해 블롭을 만들고, 그 후에 sha 식별자, 경로, 모드에 대한 참조를 배열에 저장합니다.\r\n> 3. 모든 블롭을 포함하는 새로운 트리를 생성하고, 기존 트리에 대한 참조에 추가하며, 이 새로운 트리에 대한 새로운 sha 포인터를 저장합니다.\r\n> 4. 이 새로운 트리를 가리키는 커밋을 생성하고, 브랜치에 푸시합니다.\r\n\r\n과정이 쉬워보이지는 않습니다.\r\n\r\n### 플러그인을 통한 해결 방법\r\n\r\n다행히도 [octokit-commit-multiple-files](https://github.com/mheap/octokit-commit-multiple-files) 플러그인을 통해 Octokit에 `createOrUpdateFiles` 함수를 추가하여 하나의 커밋에 여러 파일을 저장할 수 있습니다.\r\n\r\n하지만, 이 라이브러리를 사용하는데 **가끔씩 이미지 업로드가 정상적으로 되지 않는 것을 확인하였습니다.**\r\n\r\n해당 오류는 `5MB` 이상의 이미지를 업로드할 때만 발생하였고, 다음과 같은 에러 로그를 발견하였습니다.\r\n\r\n```markdown title=\"Error log\"\r\nError creating commit: RangeError: Maximum call stack size exceeded\r\nat RegExp.test (<anonymous>)\r\nat isBase64 (webpack-internal:///(action-browser)/./node_modules/is-base64/is-base64.js:24:52)\r\nat createBlob (webpack-internal:///(action-browser)/./node_modules/octokit-commit-multiple-files/create-or-update-files.js:181:14)\r\nat eval (webpack-internal:///(action-browser)/./node_modules/octokit-commit-multiple-files/create-or-update-files.js:95:47)\r\nat Array.map (<anonymous>)\r\nat eval (webpack-internal:///(action-browser)/./node_modules/octokit-commit-multiple-files/create-or-update-files.js:87:45)\r\nat processTicksAndRejections (node:internal/process/task_queues:95:5)\r\nError creating commit: Maximum call stack size exceeded\r\n```\r\n\r\noctokit-commit-multiple-files 라이브러리는 `isBase64` 라는 외부 라이브러리를 통해 base64를 체크하고 있습니다.\r\n\r\n하지만 isBase64는 마지막 커밋이 4년전으로 **더이상 유지보수가 되지 않는 라이브러리**로, [해당 이슈](https://github.com/miguelmota/is-base64/issues/10)를 가진 사람들이 많았습니다.\r\n\r\n따라서 해당 라이브러리를 사용하는 대신, [구현한 함수](https://github.com/webdriverio/webdriverio/issues/5208#issuecomment-613029075)를 넣어 해당 오류가 해결되는지 확인하기 위하여 클론 후 다음과 같은 함수로 대체하였습니다.\r\n\r\n```js title=\"isBase64\"\r\nfunction isBase64(str) {\r\n  var notBase64 = /[^A-Z0-9+\\/=]/i\r\n  const isString = typeof str === 'string' || str instanceof String\r\n\r\n  if (!isString) {\r\n    let invalidType\r\n    if (str === null) {\r\n      invalidType = 'null'\r\n    } else {\r\n      invalidType = typeof str\r\n      if (\r\n        invalidType === 'object' &&\r\n        str.constructor &&\r\n        str.constructor.hasOwnProperty('name')\r\n      ) {\r\n        invalidType = str.constructor.name\r\n      } else {\r\n        invalidType = `a ${invalidType}`\r\n      }\r\n    }\r\n    throw new TypeError(`Expected string but received ${invalidType}.`)\r\n  }\r\n\r\n  const len = str.length\r\n  if (!len || len % 4 !== 0 || notBase64.test(str)) {\r\n    return false\r\n  }\r\n  const firstPaddingChar = str.indexOf('=')\r\n  return (\r\n    firstPaddingChar === -1 ||\r\n    firstPaddingChar === len - 1 ||\r\n    (firstPaddingChar === len - 2 && str[len - 1] === '=')\r\n  )\r\n}\r\n```\r\n\r\n이후 정상적으로 업로드가 되는 것을 확인하였고, 이를 라이브러리 제작자에게 알리기 위해 `PR`을 작성하였습니다.\r\n\r\n![pr](/public/posts/contribute-open-source/pr.png)\r\n\r\n2주 정도 후 다음과 같은 코멘트와 함께 머지된 것을 확인할 수 있었습니다.\r\n\r\n![pr-accepted](/public/posts/contribute-open-source/pr-accepted.png)\r\n\r\n### 결론\r\n\r\n생각지도 못하게 오픈 소스에 기여하는 경험을 해볼 수 있었습니다.\r\n\r\n엄청나게 주요한 문제를 발견했다거나, 문제를 해결하는 코드를 직접 작성한 것은 아니지만 **문제를 발견하고 해결하는 방법을 제시하는 과정에서 여러가지를 배울 수 있었습니다.**\r\n\r\n![contributors](/public/posts/contribute-open-source/contributors.png)\r\n\r\n또한, 컨트리뷰터에 포함되니 나름 뿌듯한 것 같습니다.\r\n",
      "width": 2496,
      "height": 1692
    },
    "customize-zustand-persist": {
      "slug": "customize-zustand-persist",
      "date": "2023-12-15T00:00:00.000Z",
      "title": "zustand persist 커스텀하기",
      "description": "zustand persist를 입맛에 맞게 커스터마이징 해봅시다.",
      "tags": [
        "zustand",
        "indexedDB"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": null,
      "draft": false,
      "writer": "leey00nsu",
      "content": "\n## Zustand persist 커스텀하기\n\n전역상태관리로 `zustand`를 사용할 때, **해당 상태를 브라우저 저장소에 저장하고 싶을 때가 있습니다.**\n\nzustand에서는 이를 위해 zustand/middleware로 `persist`를 제공합니다.\n\nzustand [공식 문서](https://docs.pmnd.rs/zustand/integrations/persisting-store-data)에 예시와 함께 자세히 설명되어 있습니다.\n\n### 로컬,세션 스토리지에 저장하기\n\n```jsx title=\"useBearStore\"\nexport const useBearStore = create(\n  persist(\n    (set, get) => ({\n      bears: 0,\n      addABear: () => set({ bears: get().bears + 1 }),\n    }),\n    {\n      name: 'food-storage', // 스토리지의 이름\n      storage: createJSONStorage(() => sessionStorage), // 사용할 저장소\n      partialize: (state) => ({\n        canvasName: state.bears,\n      }),\n    },\n  ),\n)\n```\n\n만든 `store`를 `persist`로 감싼 후, 어떤 스토리지를 사용할 지 설정합니다.\n\n기본으로는 `localStorage`가 사용되고, `sessionStorage`로 바꿀 수 있습니다.\n\n이때 `partialize` 속성으로 원하는 상태만을 persist 하도록 할 수 있습니다.\n\n### 커스텀 스토리지에 저장하기\n\n기본적으로 로컬스토리지와 세션스토리지는 용량에 제한이 있습니다.\n\n**더 큰 용량을 저장하고 싶을 경우 브라우저 저장소 중 하나인 `IndexedDB`에 저장할 수 있습니다.**\n\n이 경우, indexedDB 라이브러리인 [idb-keyval](https://github.com/jakearchibald/idb-keyval) 을 사용해 구현할 수 있습니다.\n\n```jsx title=\"useBoundStore\"\nimport { get, set, del } from \"idb-keyval\";\n\nconst storage: StateStorage = {\n  getItem: async (name: string): Promise<string | null> => {\n    return (await get(name)) || null;\n  },\n  setItem: async (name: string, value: string): Promise<void> => {\n    await set(name, value);\n  },\n  removeItem: async (name: string): Promise<void> => {\n    await del(name);\n  },\n};\n\nexport const useBoundStore = create(\n  persist(\n    (set, get) => ({\n      bears: 0,\n      addABear: () => set({ bears: get().bears + 1 }),\n    }),\n    {\n      name: \"food-storage\",\n      storage: createJSONStorage(() => storage),\n    }\n  )\n);\n```\n\n사용법은 크게 다르지 않으며, 해당 커스텀 스토리지를 선언해준 후 사용합니다.\n\n### persist에 debounce 추가하기\n\n`나만의 수야 수호 만들기` 프로젝트에서, 캔버스의 히스토리를 저장하도록 하였습니다.\n\n이때 사용자가 캔버스와 상호작용할때마다 `persist`의 `set`이 동작하기 때문에 **너무 많은 요청이 발생합니다.**\n\n따라서, `debounce`를 추가하면 상호작용이 끝난 후의 캔버스의 상태를 저장하도록 해 요청의 수를 줄일 수 있습니다.\n\n사용되는 debounce 함수는 직접 구현하거나 lodash 등의 유틸 라이브러리를 사용할 수 있습니다.\n\n```jsx title=\"storage debounce\"\n// 커스텀 IndexdDB 스토리지\nconst IDBstorage: StateStorage = {\n  getItem: async (name: string): Promise<string | null> => {\n    return (await get(name)) || null;\n  },\n  setItem: debounce(async (name: string, value: string): Promise<void> => {\n    await set(name, value);\n  }, 1000),\n  removeItem: async (name: string): Promise<void> => {\n    await del(name);\n  },\n};\n```\n",
      "width": 0,
      "height": 0
    },
    "dockerize-nest": {
      "slug": "dockerize-nest",
      "date": "2024-02-25T00:00:00.000Z",
      "title": "NestJS 도커라이징 하기",
      "description": "NestJS를 도커에 올리기위한 방법에 대해 설명합니다.",
      "tags": [
        "NestJS",
        "docker"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": null,
      "draft": false,
      "writer": "leey00nsu",
      "content": "\r\n## NestJS 도커라이징 하기\r\n\r\n기존에 만든 nest 프로젝트를 `도커`로 띄우기 위해 `도커 이미지`로 만들어야 합니다.\r\n\r\n우선 도커를 설치해야 하는데 리눅스 기반에서는 [도커 엔진](https://docs.docker.com/engine/)을 설치하면 도커가 포함되어 있습니다.\r\n\r\n만약 윈도우 또는 맥 환경이라면 `도커 데스크탑`을 설치하면 GUI 환경에서 손쉽게 도커를 다룰 수 있습니다.\r\n\r\n도커를 설치한 후 , 도커라이징할 프로젝트의 루트폴더에 가서 도커 설정 파일을 생성해줍니다.\r\n\r\n- `DockerFile` : 도커 이미지에 대한 설정파일\r\n- `.dockerignore` : 이미지에 제외할 파일 목록\r\n\r\n.dockerignore에는 git 관련 파일, 환경변수 파일, node_modules, Dockerfile 자체를 제외해줍니다.\r\n\r\n저는 다음과 같이 Dockerfile을 설정하였습니다.\r\n\r\n```docker title=\"DockerFile\"\r\nFROM node:20-alpine\r\nRUN mkdir -p /var/app\r\nWORKDIR /var/app\r\nCOPY . .\r\nRUN npm install\r\nRUN npm run build\r\nEXPOSE 3000\r\nCMD [\"npm\",\"start\"]\r\n```\r\n\r\n과정을 간단하게 설명하자면 다음과 같습니다.\r\n\r\n1. node-20-alphine(최소화된 버전) 버전을 사용합니다.\r\n2. /var/app 이라는 폴더를 만든 후 , 그 안에 현재 루트폴더의 내용을 복사합니다.\r\n3. 그 후 npm install을 하여 명시된 디펜던시를 설치하고 빌드합니다.\r\n4. 도커 컨테이너가 사용할 포트를 3000으로 설정합니다.\r\n5. 서버를 실행합니다.\r\n\r\n이제 도커 이미지를 빌드해봅시다.\r\n\r\n```bash title=\"도커 이미지 빌드\"\r\ndocker build -t (이미지명) .\r\n```\r\n\r\n빌드가 완료되었다면 다음 명령어로 현재 로컬에 저장된 도커 이미지를 확인할 수 있습니다.\r\n\r\n```bash title=\"도커 이미지 확인\"\r\ndocker images\r\n```\r\n\r\n이 도커 이미지를 컨테이너에 띄우기 위해서는 다음과 같이 실행하면 됩니다.\r\n\r\n(여기서는 호스트의 3000번 포트를 컨테이너의 3000번과 연결시켰습니다.)\r\n\r\n```bash title=\"도커 컨테이너 실행\"\r\ndocker run -p 3000:3000 도커이미지ID\r\n```\r\n\r\n다른 [다양한 명령어들](https://docs.docker.com/engine/reference/commandline/run/)이 존재하니 필요에 따라 적용하면 됩니다.\r\n",
      "width": 0,
      "height": 0
    },
    "explore-canvas": {
      "slug": "explore-canvas",
      "date": "2023-07-05T00:00:00.000Z",
      "title": "리액트에서 Canvas 다루기",
      "description": "리액트에서 Canvas를 다루는 라이브러리에 대해 설명합니다.",
      "tags": [
        "react",
        "canvas",
        "konva",
        "fabric"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/explore-canvas/konva-demo.png",
      "draft": true,
      "blurDataURL": "data:image/webp;base64,UklGRjQAAABXRUJQVlA4ICgAAAAwAQCdASoQAAsABUB8JaQAA3AA/vCXN1U+cup1H/5xpY1qxT0wAAAA",
      "writer": "leey00nsu",
      "content": "\n## 리액트에서 Canvas 다루기\n\n### Konva.js vs Fabric.js\n\n이번 프로젝트를 진행하면서, 펜으로 그리고 지우는 기능과 이미지 파일을 업로드하고 레이어링하는 기능이 필요했습니다.\n\n물론 canvas API를 통해 모든 기능을 직접 구현할 수 있겠지만, 이미 잘 나와있는 라이브러리를 사용하는 것이 더 안전하고 효율적으로 프로그램을 개발할 수 있기 때문에 라이브러리를 사용하기로 결정했습니다.\n\nkonva와 fabric 모두 구현하려는 목적에 부합하기 때문에 어느 쪽을 선택해도 상관 없으므로 간단하게 두 라이브러리를 사용해보고 비교해보겠습니다.\n\n### React에서의 Konva\n\nReact에서는 `konva`를 리액트용으로 래핑한 [react-konva](https://github.com/konvajs/react-konva) 라이브러리가 존재합니다.\n\nkonva 문서와 동일하게 구현할 수 있지만 리액트스럽게 컴포넌트식으로 구현할 수 있습니다.\n\n만약 물체를 리사이징하려면 따로 transformer라는 구현체를 객체에 붙여서 따로 구현해야 합니다.\n\n![konva-demo](/public/posts/explore-canvas/konva-demo.png)\n\n```jsx title=\"konva\"\nimport { Layer, Rect, Stage } from 'react-konva'\n\nconst SomeRect = () => {\n  return <Rect x={20} y={20} width={50} height={50} fill=\"black\" />\n}\n\nconst App = () => {\n  return (\n    <Stage width={window.innerWidth} height={window.innerHeight}>\n      <Layer>\n        <SomeRect />\n      </Layer>\n    </Stage>\n  )\n}\n\nexport default App\n```\n\n### React에서의 Fabric\n\nReact에서 `fabric`을 리액트용으로 래핑한 라이브러리가 존재는 하지만, 현재 타입스크립트 기반에서 오류가 발생하여.\n\nfabric js를 직접 호출하여 사용해보겠습니다.\n\n또한 기본적으로 객체를 조절하는 transformer나 selectbox가 구현되어 있습니다. (konva에서는 따로 구현해야 합니다.)\n\n[공식 문서가](http://fabricjs.com/) 자세하게 되어있으므로 큰 어려움 없이 구현할 수 있습니다.\n\n![fabric-demo](/public/posts/explore-canvas/fabric-demo.png)\n\n```jsx title=\"fabric\"\nimport { fabric } from 'fabric'\nimport { useEffect, useState } from 'react'\n\nconst App = () => {\n  const [canvas, setCanvas] = (useState < fabric.Canvas) | (null > null)\n\n  const initCanvas = () =>\n    new fabric.Canvas('canvas', {\n      height: 800,\n      width: 800,\n      backgroundColor: 'gray',\n    })\n\n  useEffect(() => {\n    const newCanvas = initCanvas()\n    setCanvas(newCanvas)\n\n    return () => {\n      newCanvas.dispose() // 언마운트 될 때 캔버스를 지웁니다.\n    }\n  }, [])\n\n  const addRect = () => {\n    if (canvas) {\n      const rect = new fabric.Rect({\n        width: 200,\n        height: 200,\n        fill: 'yellow',\n      })\n\n      canvas.add(rect)\n      canvas.renderAll()\n    }\n  }\n\n  return (\n    <div>\n      <button onClick={addRect}>Add Rect</button>\n      <canvas id=\"canvas\" />\n    </div>\n  )\n}\n\nexport default App\n```\n\n### 결론\n\n두 방식으로 모두 구현해보았는데, 두 라이브러리 모두 `Canvas API`를 기반으로 하므로 비슷한 기능을 가지고 있습니다.\n\n대신 `fabric`은 기본적으로 `selectbox`, `transformer`를 **큰 수고 없이 구현할 수 있다는 점이 좋은 점중 하나입니다.**\n\n현재 프로젝트는 konva를 사용했지만, 만약 다시 동일한 기능을 구현한다면 fabric으로 구현해보면 좋을 것 같습니다.\n",
      "width": 1120,
      "height": 754
    },
    "external-next-image": {
      "slug": "external-next-image",
      "date": "2024-01-23T00:00:00.000Z",
      "title": "외부 이미지 next/image 적용하기",
      "description": "plaiceholder를 통해 외부 이미지에 next/image를 적용하는 과정에 대해서 설명합니다.",
      "tags": [
        "Next.js",
        "plaiceholder"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/external-next-image/result.webp",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRj4AAABXRUJQVlA4IDIAAACwAQCdASoNABAABUB8JZwAAudZ1UmAAP7vsurenlhEAtO3ekeE6UhL4d1UYOacMZQoAA==",
      "writer": "leey00nsu",
      "content": "\n## 외부 이미지 next/image 적용하기\n\n### next/image\n\n`Next.js`에서는 최적화를 위해서 이미지를 나타낼 때 `img` 태그 대신 `next/image` 컴포넌트를 사용하라는 경고를 볼 수 있습니다.\n\nnext/image를 사용하면 다음과 같은 장점을 쉽게 얻을 수 있습니다.\n\n- `webp`와 같은 **더 작은 용량의 이미지 포맷으로 이미지 서빙**\n- `srcset`을 이용하여 **디바이스별 적절한 이미지 서빙**\n- `placeholder` 제공으로 **CLS(Cumulative Layout Shift) 방지**\n\n이번 포스팅에서는 placeholder에 대하여 중점적으로 다루어보겠습니다.\n\nnext/image에서는 다음과 같이 이미지에 대해 `width`,`height` 와 같은 `메타데이터`를 자동으로 추출하고 `blurDataUrl`도 생성해주는 것을 알 수 있습니다.\n\n```jsx title=\"next/image\"\nimport Image from 'next/image'\n\nimport profilePic from './me.png'\n\nexport default function Page() {\n  return (\n    <Image\n      src={profilePic}\n      alt=\"Picture of the author\"\n      // width={500} automatically provided\n      // height={500} automatically provided\n      // blurDataURL=\"data:...\" automatically provided\n      // placeholder=\"blur\" // Optional blur-up while loading\n    />\n  )\n}\n```\n\n하지만 [공식 문서](https://nextjs.org/docs/app/building-your-application/optimizing/images)에 따르면 메타데이터는 **정적으로 import 된 이미지 파일을 기준으로 빌드타임에 생성**하기 때문에 `외부 이미지`를 대상으로는 직접 메타데이터를 넣어주어야 합니다.\n\n따라서 외부 이미지에 대해서 메타데이터를 처리하는 방법에 대해 알아보겠습니다.\n\n### Plaiceholder\n\n> \"Plaiceholder\" is a suite of **server-side** functions for creating low quality image placeholders (LQIP).\n\n[plaiceholder](https://plaiceholder.co/docs)는 **저화질의 placeholder 이미지를 서버 사이드에서 생성할 수 있도록 만들어진 라이브러리입니다.**\n\n단색, CSS, SVG, Base64 을 모두 지원합니다.\n\n라이브러리를 설치하려면 이미지 전처리 라이브러리인 `sharp` 를 설치해야 합니다.\n\n```jsx title=\"sharp 설치\"\nnpm install sharp\nnpm install plaiceholder\n```\n\n외부 이미지에 대해 plaiceholder를 사용하기 위해서는 이미지 url을 통해 `fetch`한 후 `버퍼`로 만들어 전달하면 됩니다.\n\n따라서 자바스크립트에서는 `arrayBuffer`로 만들어준 후 버퍼로 변경하여 전달할 수 있습니다.\n\n또한 함수에 생성될 `lqip` 이미지의 사이즈 등 여러 속성을 전달할 수 있습니다.\n\n```jsx title=\"getMetadata.ts\"\nimport { getPlaiceholder } from 'plaiceholder';\n\nexport default async function getMetadata(imageUrl: string) {\n  const res = await fetch(imageUrl);\n\n  const buffer = await res.arrayBuffer();\n\n  const { base64, metadata } = await getPlaiceholder(Buffer.from(buffer), {\n    size: 8,\n  });\n\n  return { base64, metadata };\n}\n```\n\nnext/image는 blurDataUrl로 `base64`를 받으므로, base64에 대한 반환 값을 받아보겠습니다.\n\nplaiceholder에서는 다음과 같이 base64와 메타데이터를 반환합니다.\n\n```jsx title=\"plaiceholder 반환 값\"\nbase64: string;\nmetadata: {\n    orientation?: number;\n    format?: keyof sharp.FormatEnum;\n    size?: number;\n    space?: keyof sharp.ColourspaceEnum;\n    channels?: sharp.Channels;\n    depth?: string;\n    density?: number;\n    chromaSubsampling: string;\n    isProgressive?: boolean;\n    pages?: number;\n    pageHeight?: number;\n    loop?: number;\n    delay?: number[];\n    pagePrimary?: number;\n    hasProfile?: boolean;\n    hasAlpha?: boolean;\n    exif?: Buffer;\n    icc?: Buffer;\n    iptc?: Buffer;\n    xmp?: Buffer;\n    tifftagPhotoshop?: Buffer;\n    compression?: \"av1\" | \"hevc\";\n    background?: number | {\n        r: number;\n        g: number;\n        b: number;\n    };\n    levels?: sharp.LevelMetadata[];\n    subifds?: number;\n    resolutionUnit?: \"inch\" | \"cm\";\n    formatMagick?: string;\n    width: number;\n    height: number;\n};\n```\n\n또한, 외부 이미지를 서빙할 때 `optimized` 옵션을 적용하기 위해서는 해당 이미지 도메인을 `remotePatterns`에 등록해주어야 합니다.\n\n```jsx title=\"next.config.js\"\nmodule.exports = {\n  images: {\n    remotePatterns: [\n      {\n        protocol: 'https',\n        hostname: 'example.com',\n        port: '',\n        pathname: '/account123/**',\n      },\n    ],\n  },\n}\n```\n\n이제 이 함수를 호출하여 Image 컴포넌트에 넣을 수 있습니다.\n\n```jsx title=\"GithubChart.tsx\"\nconst GithubChart = async () => {\n  const url =\n    'https://cdn.pixabay.com/photo/2023/07/22/04/15/motorbike-8142649_1280.jpg'\n  const { base64, metadata } = await getMetadata(url)\n\n  return (\n    <Image\n      alt=\"motorcycle\"\n      width={metadata.width}\n      height={metadata.height}\n      src={url}\n      blurDataURL={base64}\n      placeholder=\"blur\"\n    />\n  )\n}\n```\n\n### 결과\n\n![result.webp](/public/posts/external-next-image/result.webp)\n\n순서대로 plaiceholder X, plaiceholder O 에 대한 결과이며\n\n결과 테스트를 위하여 `Fast 3G` 환경에서 실행하였습니다.\n\n다음과 같이, 적용하지 않은 쪽은 이미지가 완전히 로딩되기 전까지 보이지 않으며 `Layout Shift`가 발생합니다.\n\n따라서, next/image를 유용하게 사용하기 위해서는 해당 라이브러리를 사용하는 것을 고려해볼 수 있습니다.\n\n또한 `optimized` 옵션을 적용했을 때 **두 배 이상의 용량 차이를 보여주었습니다.**\n\n![diff](/public/posts/external-next-image/diff.png)\n\n### 적용 사례\n\n제 [블로그](https://blog.leey00nsu.com/)에는, 해당 라이브러리를 사용하여 초기에 블러 이미지를 보여준 후 자연스럽게 트랜지션 되도록 사용하고 있습니다.\n\n![demo](/public/posts/external-next-image/demo.gif)\n",
      "width": 600,
      "height": 768
    },
    "framer-motion-page-transition": {
      "slug": "framer-motion-page-transition",
      "date": "2023-09-11T00:00:00.000Z",
      "title": "framer-motion으로 페이지 트랜지션 구현하기",
      "description": "framer-motion으로 페이지 트랜지션을 구현하는것에 대해 설명합니다.",
      "tags": [
        "react",
        "framer-motion",
        "AnimatePresence"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/framer-motion-page-transition/result.gif",
      "draft": true,
      "blurDataURL": "data:image/webp;base64,UklGRioAAABXRUJQVlA4IB4AAACQAQCdASoMABAABUB8JaQAAp1HI1AA9WZ88xAAAAA=",
      "writer": "leey00nsu",
      "content": "\n## framer-motion으로 페이지 트랜지션 구현하기\n\n`react` 기반의 프로젝트에서 `애니메이션`을 구현할 때 `framer-motion` 을 사용합니다. 이를 기반으로 페이지를 이동시킬 때마다 다른 페이지를 보여줄 때 페이지 트랜지션을 구현해보고자 합니다.\n\n### framer-motion?\n\n[framer-motion](https://www.framer.com/motion/)은 다음과 같은 라이브러리로 자신을 소개하고 있습니다.\n\n> Complete documentation of the Framer Motion animation library. A production-ready motion library for React.\n\nreact를 위한 **모션 라이브러리**로 `framer` 에 의해 제공됩니다.\n\n라이브러리는 다음과 같이 설치할 수 있습니다.\n\n```shell title=\"framer-motion\"\nnpm install framer-motion\n```\n\n### 작동 방식\n\n기본적으로 `motion` 이라는 컴포넌트에 리액트 컴포넌트들이 래핑되어 있으므로 , 이를 가져와 사용합니다.\n\n`initial` 값에는 시작되는 스타일 값을 부여할 수 있습니다.\n\n`animate` 옵션에 목표 스타일 값을 부여할 수 있으며 , `framer-motion`이 자동적으로 이 값에 의해 애니메이션 시켜줍니다.\n\n```jsx title=\"motion.div\"\n<motion.div initial={{ opacity: 0 }} animate={{ opacity: 1 }} />\n```\n\n예를 들자면 이 컴포넌트는 `initial`이 `opacity: 0`이므로 투명한 상태로 시작하였다가 `animate`에 있는 `opacity:1` 에 의해 보여지게 됩니다.\n\n또한 `transition` 이라는 속성에 딜레이나 애니메이션의 타입 (Tween,Spring) 등을 지정할 수 있으므로 **애니메이션을 원하는대로 조정할 수 있습니다.**\n\n### AnimatePresence와 exit\n\n`framer-motion`에는 이외에도 다양한 옵션들이 존재하며 [공식 문서](https://www.framer.com/motion/)가 예제와 함께 상세히 되어있습니다.\n\n이 글에서 필요로 하는 부분은 위에서 설명한 `initial`,`animate`,그리고 `exit` 옵션입니다.\n\n`exit` 는 주로 `AnimatePresence` 와 함께 쓰이는 옵션입니다.\n\n`AnimatePresence`는 **리액트상에서 컴포넌트가 DOM 트리에서 언마운트될 때 이를 인지한 후 exit 애니메이션이 끝날때까지 언마운트를 지연시킵니다.**\n\n공식 문서에서는 다음과 같은 예제가 있습니다.\n\n```jsx title=\"AnimatePresence\"\nimport { AnimatePresence, motion } from 'framer-motion'\n\nexport const MyComponent = ({ isVisible }) => (\n  <AnimatePresence>\n    {isVisible && (\n      <motion.div\n        initial={{ opacity: 0 }}\n        animate={{ opacity: 1 }}\n        exit={{ opacity: 0 }}\n      />\n    )}\n  </AnimatePresence>\n)\n```\n\n### react-router와 framer-motion\n\nreact는 `SPA` 이므로 주로 **라우트 시스템**을 이용하기 위해 `react-router` 를 사용합니다.\n\n이 글에서 구현하려는 목표 또한 **페이지를 이동시킬 때마다 다른 페이지를 보여줄 때 페이지 트랜지션을 보여주는 것입니다.**\n\nreact-router의 설정은 생략하고 추가로 설정할 부분에 대해서 설명하겠습니다.\n\n```jsx title=\"routes.tsx\"\nconst location = useLocation();\nconst { pageHistory } = useTransitionStore();\n\n...\n<AnimatePresence>\n\t<Routes location={location} key={pageHistory + location.pathname}>\n    <Route path=\"/\" element={<MainPage />} />\n    <Route path=\"/a\" element={<Page1 />} />\n    <Route path=\"/b\" element={<Page2 />} />\n\t  <Route path=\"/c\" element={<Page3 />} />\n\t  <Route path=\"/d\" element={<Page4 />} />\n\t</Routes>\n</AnimatePresence>\n```\n\n`AnimatePresence` 바로 아래에 `motion 컴포넌트`가 존재해야 하므로 , 위의 코드와 같이 , `Routes`를 `AnimatePresence`로 감싸주었습니다.\n\n또한 Routes의 key에 pageHistory+location.pathname 을 넘겨주고 있습니다.\n\n**motion 컴포넌트에는 애니메이션을 실행할 객체를 구분하기 위하여 `key`가 필요합니다.**\n\n이 key가 바뀌지 않았다면 애니메이션이 다시 실행되지 않습니다.\n\nkey로서 애니메이션 되는 객체를 구분하므로 만약 지나온 경로를 넣지 않으면\n\na → b → a 로 갈때 a 가 두번 나오므로 **애니메이션이 겹치게 될 수 있습니다.**\n\n따라서 **현재 위치+모든 경로를 key로 부여하는 것입니다**.\n\n<br />\n\n이제 각 페이지 컴포넌트들을 설정해보겠습니다.\n\n페이지 컴포넌트들은 Layout 이라는 컴포넌트로 래핑되어 있습니다.\n\n```jsx title=\"Layout\"\ninterface LayoutProps {\n  children: React.ReactNode;\n}\n\nconst Layout = (props: LayoutProps) => {\n  const { currentDirection } = useTransitionStore();\n\n  let initialX = 0;\n  if (currentDirection === \"left\") initialX = 500;\n  if (currentDirection === \"right\") initialX = -500;\n\n  const exitX = currentDirection === \"left\" ? -500 : 500;\n\n  return (\n    <motion.div\n      initial={{ x: initialX }}\n      animate={{ x: 0 }}\n      exit={{ x: exitX }}\n      transition={{ duration: 0.5 }}\n      className=\"layout\"\n    >\n      {props.children}\n    </motion.div>\n  );\n};\n```\n\n`currentDirection`은 현재 슬라이드가 움직일 방향을 담고 있습니다.\n\n만약 뒤로가기를 누르면 `left`로 설정되고 오른쪽에서 왼쪽으로 움직입니다.\n\n다른 페이지를 누르면 `right`로 설정되고 왼쪽에서 오른쪽으로 움직입니다.\n\n현재 페이지의 width가 500px 이므로 500으로 명시해두었습니다.\n\n![structure](/public/posts/framer-motion-page-transition/structure.png)\n\n해당 코드는 `framer-motion`에 의해 그림과 같은 순서로 애니메이션 됩니다.\n\n(참고로 layout의 css에서 position:absolute로 해주어야 x 를 이용한 트랜지션을 할 수 있습니다.)\n\n최종 결과는 다음과 같습니다.\n\n![result](/public/posts/framer-motion-page-transition/result.gif)\n\n### 결론\n\n간단한 애니메이션에서부터 복잡한 애니메이션까지 `framer-motion` 을 이용하면 비교적 간단하게 만들 수 있어서 자주 사용하고 있습니다.\n\n이번에는 페이지 트랜지션을 구현해보았는데 , `react-router`와 연동하는 부분이 복잡할 뿐 애니메이션 자체는 간단해서 쉽게 접근할 수 있었습니다.\n\n**프로젝트에서 모바일 뷰로 나타내야 할 때 트랜지션을 넣으면 앱처럼 작동하는 것 같은 느낌을 줄 수 있어서 생각해볼만한 테크닉이라고 생각합니다.**\n",
      "width": 600,
      "height": 772
    },
    "migration-supabase": {
      "slug": "migration-supabase",
      "date": "2024-09-18T00:00:00.000Z",
      "title": "Supabase 마이그레이션하기",
      "description": "Supabase 클라우드의 데이터를 셀프 호스팅으로 변경하며 데이터를 마이그레이션 해봅시다.",
      "tags": [
        "supabase"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/migration-supabase/supabase.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRi4AAABXRUJQVlA4ICIAAACQAQCdASoQAAoABUB8JZwAAuP9bYAA/u9MdlrdmpDMAAAA",
      "writer": "leey00nsu",
      "content": "\r\n# supabase 마이그레이션 하기\r\n\r\n## Supabase\r\n\r\n![supabase](/public/posts/migration-supabase/supabase.png)\r\n\r\n`Supabase`는 오픈 소스 백엔드 서비스로, 개발자가 손쉽게 전체 백엔드를 구축할 수 있도록 도와주는 `BaaS` 입니다.. 기본적으로 Supabase는 `PostgreSQL` 데이터베이스를 기반으로 하며, 실시간 데이터베이스, 인증, 스토리지, 그리고 RESTful API를 자동으로 생성해 주는 기능을 제공합니다.\r\n\r\n주요 기능은 다음과 같습니다.\r\n\r\n1. **데이터베이스**: PostgreSQL을 기반으로 한 확장 가능한 관계형 데이터베이스.\r\n2. **실시간 기능**: 데이터베이스에서 실시간으로 데이터를 동기화하고 업데이트할 수 있는 기능.\r\n3. **인증**: 사용자 인증 및 권한 관리 시스템 제공(GitHub, Google, Facebook 등의 외부 로그인 서비스 통합 가능).\r\n4. **스토리지**: 이미지, 비디오 등의 파일을 저장하고 관리할 수 있는 기능.\r\n5. **자동 생성 API**: PostgreSQL 스키마를 기반으로 자동으로 RESTful API 및 GraphQL을 생성.\r\n\r\nSupabase는 Firebase와 비슷한 기능을 제공해주며, 특히 PostgreSQL과의 통합을 필요로 하는 경우 많은 개발자들이 사용하고 있습니다.\r\n\r\n## \b왜 셀프 호스팅을 하게 되었나\r\n\r\n현재는 본격적인 백엔드 어플리케이션이 필요하지 않고 단순한 CRUD 기능이 필요할 때 supabase를 활용하고 있습니다.\r\n\r\n블로그의 조회수 처리에도 supabase를 활용하였는데요, 간단하게 백엔드를 구성하기에 정말 좋지만 **몇 가지 단점이 있습니다.**\r\n\r\n1. **프로젝트 2개까지만 무료입니다.**\r\n2. **1주 동안 대시보드를 방문하지 않으면 (관리하지 않으면) 프로젝트가 일시중지 됩니다.**\r\n\r\n모든 프로젝트들을 일주일마다 관리하기도 힘들 뿐더러 혹시나 까먹게 되면 프로젝트가 일시중지되어 다시 풀어주어야 하는등 귀찮음이 있습니다.\r\n\r\n따라서 도커를 통해 셀프 호스팅을 하기로 마음먹게 되었습니다.\r\n\r\n## 셀프 호스팅\r\n\r\n[공식문서](https://supabase.com/docs/guides/self-hosting/docker)에 도커를 통한 셀프 호스팅 방법에 대해 설명되어 있습니다.\r\n\r\n이번 포스트에서는 해당 과정에 대해 자세히 다루지 않겠습니다. (단순히 `도커 컴포즈` 파일을 통해 env만 수정하고 실행하면 되는 간단한 과정입니다.)\r\n\r\n## Postgresql 마이그레이션 하기\r\n\r\n### pg_dump로 백업하기\r\n\r\n기본적인 셀프 호스팅 supabase가 준비가 되었다면, 이제 내용물을 교체할 시간입니다.\r\n\r\nsupabase는 내부적으로 `postgresql` 을 사용하기 때문에 `pg_dump`와 `psql`을 사용하여 마이그레이션을 진행할 수 있습니다.\r\n\r\n![table-old](/public/posts/migration-supabase/table-old.png)\r\n\r\n현재 블로그 조회수 테이블은 다음과 같습니다.\r\n\r\n해당 데이터를 기존의 supabase 데이터로부터 백업하기 위해서 pg_dump 를 사용하겠습니다.\r\n여기서 사용되는 postgresql의 정보는 supabase의 project settings > database 에서 확인할 수 있습니다.\r\n\r\n```bash title=\"pg_dump\"\r\nsudo apt-get install postgresql-15\r\npg_dump postgresql://[YOUR_USER]:[YOUR-PASSWORD]@[YOUR_HOST]:[YOUR_PORT]/postgres > database-dump.sql\r\n```\r\n\r\n정상적으로 된다면 다음으로 넘어가시면 되지만 **만약 Ubuntu 버전이 20.04여서 postgresql 15를 설치할 수 없을 경우**, 다음과 같은 과정을 통해 설치하신 후 진행하면 됩니다.\r\n\r\n1. PostgreSQL 공식 저장소 추가\r\n   PostgreSQL의 최신 버전은 Ubuntu의 기본 저장소에는 포함되지 않기 때문에 PostgreSQL 공식 저장소를 추가해야 합니다.\r\n\r\n```bash title=\"PostgreSQL 공식 저장소 추가 명령\"\r\nsudo sh -c 'echo \"deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main\" > /etc/apt/sources.list.d/pgdg.list'\r\n```\r\n\r\n2. PostgreSQL 저장소의 GPG 키 추가\r\n   PostgreSQL 패키지의 무결성을 확인하기 위해 GPG 키를 추가합니다.\r\n\r\n```bash title=\"PostgreSQL 저장소의 GPG 키 추가\"\r\nwget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -\r\n```\r\n\r\n3. 패키지 목록 업데이트\r\n   PostgreSQL 공식 저장소를 추가한 후, 패키지 목록을 업데이트합니다.\r\n\r\n```bash title=\"패키지 목록 업데이트\"\r\nsudo apt-get update\r\n```\r\n\r\n4. PostgreSQL 15 설치\r\n   이제 PostgreSQL 15을 설치할 수 있습니다.\r\n\r\n```bash title=\"PostgreSQL 15 설치\"\r\nsudo apt-get install postgresql-15\r\n```\r\n\r\n### psql로 백업 적용하기\r\n\r\n정상적으로 백업 데이터가 생성되었다면 `database-dump.sql` 라는 파일이 생성되었을 것입니다.\r\n\r\n이제 이 파일을 통해 백업을 적용하기 위해서는 **셀프 호스팅된 postgresql의 도커 컨테이너 내부에서 psql을 실행해야합니다.**\r\n\r\n`docker ps` 와 같은 명령어를 통해 해당 컨테이너의 ID를 알아낸 후 백업 파일을 도커 컨테이너로 전송해줍니다.\r\n\r\n```\bbash title=\"도커 컨테이너로 파일 전송\"\r\ndocker cp /path/to/database-dump.sql [컨테이너ID]:/path/in/container/\r\n```\r\n\r\n이후 해당 컨테이너로 접속하여 줍니다.\r\n\r\n```\bbash title=\"도커 컨테이너 접속\"\r\ndocker exec -it [컨테이너ID] bash\r\n```\r\n\r\n이제 전송된 백업 파일의 위치에서 psql 명령어를 실행해주면 됩니다.\r\n\r\n```\bbash title=\"psql\"\r\npsql -U [YOUR_USER] -d postgres -f database-dump.sql\r\n```\r\n\r\n정상적으로 처리되었는지 셀프 호스팅된 supabase의 gui로 접속해보면 다음과 같이 잘 적용된 것을 볼 수 있습니다.\r\n\r\n![table-new](/public/posts/migration-supabase/table-new.png)\r\n\r\n## 결론\r\n\r\n앞서 말한 두 가지 단점 때문에 셀프 호스팅을 하였지만, 셀프 호스팅에도 **여러 프로젝트를 관리할 수 없다는 단점**이 존재합니다. (orgnization이 없습니다.)\r\n\r\n만약 단순히 db를 사용하기 위해서라면 postgresql만 호스팅하고 prisma와 같은 orm을 사용하는게 더 나을 수도 있습니다.\r\n\r\n하지만 supabase가 제공하는 다른 강력한 기능들과 내장된 gui는 셀프 호스팅에서도 여전히 제공되기 때문에 편리함을 위해서 앞으로도 사용할 것 같습니다.\r\n\r\n## 레퍼런스\r\n\r\n[https://supabase.com/docs/guides/self-hosting/docker](https://supabase.com/docs/guides/self-hosting/docker)\r\n\r\n[https://ironeko.com/posts/creating-a-local-backup-of-a-supabase-database](https://ironeko.com/posts/creating-a-local-backup-of-a-supabase-database)\r\n\r\n[https://medium.com/devops-technical-notes-and-manuals/how-to-install-and-configure-postgresql-on-ubuntu-20-04-4fd3cf072d6f](https://medium.com/devops-technical-notes-and-manuals/how-to-install-and-configure-postgresql-on-ubuntu-20-04-4fd3cf072d6f)\r\n",
      "width": 2090,
      "height": 1250
    },
    "mock-with-msw": {
      "slug": "mock-with-msw",
      "date": "2023-08-18T00:00:00.000Z",
      "title": "msw로 API 모킹하기",
      "description": "msw 라이브러리를 사용해 API를 모킹하는 법에 대해 알아봅시다.",
      "tags": [
        "react",
        "msw",
        "api"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/mock-with-msw/scrum.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRjYAAABXRUJQVlA4ICoAAACwAQCdASoQAAYABUB8JQBOgCPtvsfwAP7hWXoOM//OQNttKEv+y4cAAAA=",
      "writer": "leey00nsu",
      "content": "\n## msw로 모킹하기\n\n프로젝트를 진행해 나가면서 개발을 시작하기 전 보통 회의를 거쳐 **어떠한 기능을 구현할 지와**\n\n**그 기능에 맞는 데이터를 이야기해보는 시간을 갖게됩니다.**\n\n![scrum](/public/posts/mock-with-msw/scrum.png)\n\n그 결과로 다음과 같이 각 데이터에 접근할 수 있는 API 명세서가 만들어지게 되며 , 프론트엔드 개발자는 이 규칙에 따라 서버에 요청하게 됩니다.\n\n### 왜 모킹해야 할까?\n\n프론트엔드와 백엔드가 속도를 맞춰 함께 개발할 수 있는 이상적인 환경이라면 실제 데이터를 가지고 개발하면 되기 때문에 문제가 없습니다.\n\n하지만 **개발 단계에서 이는 쉽지 않은 조건임을 여러 프로젝트를 거치면서 느낄 수 있었습니다.**\n\n프론트엔드 개발자의 입장에서 백엔드가 구현되지 않았을 때 기다려야 하는 부분이 필연적으로 존재합니다.\n\n따라서 기한내에 완성하기 위해서는 `현재는 없지만 만들어질 API`를 이용하고 테스트하는것이 효율적으로 개발할 수 있는 방식일 것입니다.\n\n### msw 라이브러리의 도입\n\n[`msw`](https://mswjs.io/) 는 이러한 문제점을 해결할 수 있는 라이브러리로 다음과 같이 자신을 소개하고 있습니다.\n\n> Mock by intercepting requests on the network level. Seamlessly reuse the same mock definition for testing, development, and debugging.\n>\n> Mock Service Worker is an API mocking library that uses Service Worker API to intercept actual requests.\n\n설명에 의하면 `Service Worker API`를 사용하여 **네트워크 레벨에서 요청을 가로채어 모킹을 해주는 기능**을 가지고 있습니다.\n\n![msw-structure](/public/posts/mock-with-msw/msw-structure.png)\n\n### msw 실제 프로젝트에 사용해보기\n\n`msw`를 사용하기 위해서는 서비스 워커를 만들어야하는데 , 관련된 파일을 보통 mocks 폴더 밑에 위치시킵니다.\n\n```jsx title=\"mocks/worker.js\"\nimport { setupWorker } from 'msw'\n\nimport { handlers } from './handler'\n\nexport const worker = setupWorker(...handlers)\n```\n\n이 서비스 워커를 어플리케이션의 최상단에서 구동하기 위해서 , 최상단 진입 컴포넌트에 넣어줍니다.\n\n(제 경우 main.jsx 입니다.)\n\n```jsx title=\"src/main.jsx\"\nimport { worker } from './mocks/worker'\n\n// msw Mock 서버를 실행합니다.\nif (process.env.NODE_ENV === 'development') {\n  worker.start()\n}\n```\n\n이제 실제 프로젝트에서 적용된 코드를 가지고 예시를 살펴보겠습니다.\n\n`dummyKoPosts`라는 더미데이터를 만들고 , 이를 요청했을 때 응답을 해줄 핸들러를 작성해야 합니다.\n\n```jsx title=\"더미 데이터\"\n// 더미 유저 데이터\nexport const dummyKoUser1: User = {\n  id: 1,\n  nickname: '일론 머스크',\n  language: 'ko',\n  avatar:\n    'https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Elon_Musk_Royal_Society_%28crop2%29.jpg/225px-Elon_Musk_Royal_Society_%28crop2%29.jpg',\n  followers: 100,\n};\n\n// 더미 게시글 데이터\nexport const dummyKoPosts: Post[] = [\n  {\n    id: 1,\n    author: dummyKoUser1,\n    title: '꾸뻬 씨의 사랑 여행',\n    content:\n      '사랑이 없으면 사는 게 얼마나 밋밋하겠어요? 사랑은 우릴 흥분시키고 즐겁게 해주죠. 사랑을 하면 삶은 모험의 연속이 되고, 만남은 순간순간 아찔한 경이가 된답니다. 물론 늘 그런 건 아니지만요. 그래도 전 사랑이 현대 생활의 가장 큰 불행, 즉 권태로부터 우릴 지켜준다고 믿고 있습니다. 우리나라의 경우이긴 하지만 우린 지나칠 정도로 보호받으며 살고 있어요. 그런 우리에게 사랑은 마지막으로 남아 있는 모험이지요. 우릴 늘 젊게 만들어주는 사랑 만세예요.',\n    summary: '사랑으로 인한 모험과 아찔한 순간을 믿는 긍정적인 시각',\n    photos: [],\n    views: 50,\n    likes: 50,\n    comments: [\n      {\n        id: 1,\n        author: dummyKoUser2,\n        content: '잘 봤어요!',\n        created_at: '2023-08-07',\n      },\n      {\n        id: 2,\n        author: dummyKoUser3,\n        content: '정말 공감되는 글이에요',\n        created_at: '2023-08-07',\n      },\n    ],\n    created_at: '2023-08-07',\n    category: 'book',\n  },\n  ...\n];\n```\n\n```jsx title=\"mocks/handler.js\"\nexport const handlers = [\n  rest.get(`/ko_post`, (req, res, ctx) => {\n    return res(ctx.status(200), ctx.json(dummyKoPosts))\n  }),\n]\n```\n\n이제 `fetch`나 `axios`와 같은 함수를 이용하여 /ko_post 를 요청하면 **핸들러에 get에 바인딩된 그대로**\n\n**200코드와 함께 dummyKoPosts를 반환하게 됩니다.**\n\n```jsx title=\"getKoPostPage\"\n// 더미 게시글 페이지를 받아옵니다.\nexport const getKoPostPage = async () => {\n  const response = await axios.get('/ko_post')\n  return response.data\n}\n```\n\n이 호출 결과를 실제 프로젝트 화면에 나타내면 다음과 같습니다.\n\n![result](/public/posts/mock-with-msw/result.png)\n\n### 결론\n\n단순히 더미 데이터를 사용하다가 `msw`라는 모킹 라이브러리를 발견하게되어 , 프로젝트 초기 단계에서 유용하게 사용하고 있습니다.\n\n또한 네트워크 응답 상태를 직접 조작하여서 `엣지 케이스`들에 대해 쉽게 대응할 수 있다는 장점도 있습니다.\n\n이미 만든 모킹 코드를 이용하여 `Jest`나 `Storybook`과 같은 테스트 도구에 이용하는 방법에 대해서도 공부해보면 좋을 것 같습니다.\n",
      "width": 2000,
      "height": 698
    },
    "nextjs-github-action-ci-cd": {
      "slug": "nextjs-github-action-ci-cd",
      "date": "2024-05-09T00:00:00.000Z",
      "title": "github actions로 Docker를 이용해 Next.js CI/CD 구현하기",
      "description": "github actions로 Docker를 이용해 Next.js CI/CD를 구현하는 방법에 대해서 설명합니다.",
      "tags": [
        "docker",
        "github",
        "ci/cd",
        "Next.js"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/nextjs-github-action-ci-cd/oracle_cloud.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRjQAAABXRUJQVlA4ICgAAACwAQCdASoQABAABUB8JZwAAu06tbKAAP7x3xYuDpvoCbISu16AAAAA",
      "writer": "leey00nsu",
      "content": "\r\n## github actions로 Docker를 이용해 Next.js CI/CD 구현하기\r\n\r\n`Next.js`를 사용하여 프로젝트를 구성한 후, 배포를 할 단계가 찾아왔습니다.\r\n\r\nVercel을 이용하여 쉽게 배포할 수 있는 방법도 있겠지만, 이번 기회에 기존에 만들어 두었던 `Oracle cloud`를 활용하여 CI/CD에 도전해보게 되었습니다.\r\n\r\n### CI/CD?\r\n\r\n우선 CI/CD에 대해서 간단하게 알아보자면, [Redhat](https://www.redhat.com/ko/topics/devops/what-is-ci-cd) 에서는 다음과 같이 설명하고 있습니다.\r\n\r\n> CI/CD는 지속적 통합(Continuous Integration) 및 지속적 제공/배포(Continuous Delivery/Deployment)를 의미하며, 소프트웨어 개발 라이프사이클을 간소화하고 가속화하는 것을 목표로 합니다.\r\n\r\n해당 설명에 의하면 다음과 같은 일련의 과정을 CI/CD라 할 수 있습니다.\r\n\r\n- `지속적 통합 (Continuous Integration, CI)`: 여러 개발자가 동시에 개발하는 경우, 코드의 충돌이나 오류를 방지하기 위해 개발자가 코드를 중앙 저장소에 자주 통합하는 작업을 의미하며, 새 코드를 주기적으로 가져와 자동으로 빌드하고 테스트합니다. 만약 문제가 발견되면 팀에 알림을 보내고 문제를 해결할 수 있도록 합니다.\r\n- `지속적 배포 또는 지속적 제공 (Continuous Deployment/Delivery, CD)`: 지속적 배포는 새로운 코드 변경 사항을 자동으로 프로덕션 환경에 배포하는 것을 의미합니다.\r\n\r\n여기서 저는 **새로운 커밋이 레포지토리에 등록될 때마다 클라우드에 접근하여 코드를 반영하고, 빌드하여 배포하는 과정**을 진행해보도록 하겠습니다.\r\n\r\n### Docker를 이용한 Next.js 빌드\r\n\r\nNext.js를 배포하고자 할 때, [공식 문서](https://nextjs.org/docs/app/building-your-application/deploying#docker-image)에서 필요한 설정을 제공하고 있습니다.\r\n\r\n해당 파일을 참고하여 `.dockerignore`와 `Dockerfile`을 작성해주었습니다.\r\n\r\n**참고로 Docker로 빌드할 때 이미지 용량을 줄이기 위해서는 기존 Next.js output 설정을 `standalone`으로 변경해주어야 합니다.**\r\n\r\n```js title=\"next.config.mjs\"\r\n/** @type {import('next').NextConfig} */\r\nmodule.exports = {\r\n  output: 'standalone',\r\n}\r\n```\r\n\r\n또한 현재 제가 운영중인 Oracle Cloud의 구조는 다음과 같습니다.\r\n\r\n![oracle_cloud](/public/posts/nextjs-github-action-ci-cd/oracle_cloud.png)\r\n\r\nNginx를 Docker에서 돌리고 있으며, 기존에 다른 프로젝트를 운영중이기 때문에 새롭게 배포할 Next.js 프로젝트도 해당 Nginx와 연결시켜주어야 했습니다.\r\n\r\n따라서, `docker-compose` 파일을 작성하여 **같은 network 설정을 통해 Nginx와 연결시켜주도록 하였습니다.**\r\n\r\n```yml title=\"docker-compose.yml\"\r\nservices:\r\n  noveloper:\r\n    container_name: noveloper\r\n    image: noveloper\r\n    ports:\r\n      - '4000:4000'\r\n    networks:\r\n      - nginx-network\r\n\r\nnetworks:\r\n  nginx-network:\r\n    external: true\r\n```\r\n\r\n이제, github actions 설정을 통해 커밋을 감지하고 새로운 코드로 빌드하는 워크플로우를 추가하면 됩니다.\r\n\r\n### Github actions 설정\r\n\r\ngithub actions를 추가할 레포지토리의 actions 탭에서 새로운 워크플로우를 추가해봅시다.\r\n\r\n```yml title=\"deploy.yml\"\r\nname: deploy\r\non:\r\n  push:\r\n    branches: ['main'] # main 브랜치에 새로운 커밋이 푸시되면 실행합니다.\r\njobs:\r\n  deploy:\r\n    runs-on: ubuntu-latest\r\n    steps:\r\n      - uses: actions/checkout@v3.3.0\r\n\r\n      - name: execute remote ssh # 클라우드 인스턴스에 ssh로 접근합니다.\r\n        uses: appleboy/ssh-action@master\r\n        with:\r\n          host: ${{ secrets.REMOTE_SSH_HOST }}\r\n          username: ${{ secrets.REMOTE_SSH_USERNAME }}\r\n          key: ${{ secrets.REMOTE_SSH_KEY }}\r\n          port: ${{ secrets.REMOTE_SSH_PORT }}\r\n          script: |\r\n            cd noveloper\r\n            git pull origin main\r\n            docker build -t noveloper .\r\n            docker compose down\r\n            docker compose up -d\r\n            docker rmi $(docker images -f \"dangling=true\" -q)\r\n```\r\n\r\nmain 브랜치에 새로운 커밋이 푸시되면 클라우드 인스턴스에 ssh로 접근하도록 구성하였고\r\n\r\n정상적으로 ssh에 접속할 수 있도록 필요한 **host,username,key,port**를 환경변수로 등록해주었습니다.\r\n\r\n접속한 후에는 script를 통하여, 다음과 같은 과정을 실행하도록 구성하였습니다.\r\n\r\n1. `cd noveloper` : 프로젝트 폴더로 이동\r\n2. `git pull origin main` : 새로운 커밋 pull\r\n3. `docker build -t noveloper .` : 프로젝트명의 docker 이미지 빌드\r\n4. `docker compose up -d` : 기존에 작성한 docker-compose.yml에 구성된 내용으로 docker 컨테이너 실행\r\n5. `docker rmi $(docker images -f \"dangling=true\" -q)` : 오래된 이미지 삭제\r\n\r\n### 결과\r\n\r\n이제 새로운 커밋이 등록되면 다음과 같이 등록한 actions가 실행되게 됩니다.\r\n\r\n![actions_success](/public/posts/nextjs-github-action-ci-cd/actions_success.png)\r\n\r\n현재 제 프로젝트에서는 평균 약 3분 정도 시간이 소요됩니다.\r\n\r\n### 결론\r\n\r\n미리 구성해둔 Nginx를 활용하여 Docker 컨테이너에 올린 Next.js를 쉽게 배포할 수 있었습니다.\r\n\r\n또한, 매번 프로젝트를 배포할 때마다 `vercel`에 의존하였는데, 이렇게 **클라우드를 활용하여 직접 배포를 진행해보니 새롭게 알게되는 것들이 많았습니다.**\r\n\r\n지금 구성한 과정 중에서 틀린 부분이 있을 수 있지만, 추후에도 계속해서 보완해나가도록 노력해보겠습니다.\r\n",
      "width": 4136,
      "height": 4104
    },
    "nivo-chart": {
      "slug": "nivo-chart",
      "date": "2023-08-07T00:00:00.000Z",
      "title": "nivo chart로 데이터 시각화하기",
      "description": "nivo 라이브러리를 사용하여 데이터를 시각화하는 방법에 대해 설명합니다.",
      "tags": [
        "react",
        "nivo",
        "chart",
        "graph",
        "artfolio"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/nivo-chart/result1.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRkYAAABXRUJQVlA4IDoAAADwAQCdASoQAAoABUB8JbAC7AEPApXr+gAA/u1kbeEZh9ajk3eGOSFXP8V2EtBgzubHSTfv721QAAAA",
      "writer": "leey00nsu",
      "content": "\n## nivo chart로 데이터 시각화하기\n\n![result1](/public/posts/nivo-chart/result1.png)\n![result2](/public/posts/nivo-chart/result2.png)\n\n`artfolio` 프로젝트를 진행하면서 위와 같이 `실시간 경매가`와 , `태그`를 표시할 그래프를 구현해야 했습니다.\n\n제 기준에서 **커스터마이징이 잘 되며 문서가 자세한 라이브러리**를 고르다 `nivo`를 선택하였습니다.\n\n### nivo?\n\n[nivo 문서](https://nivo.rocks/)에서는 다음과 같이 라이브러리를 소개하고 있습니다.\n\n> [nivo](https://github.com/plouc/nivo) provides supercharged React components to easily build dataviz apps, it's built on top of d3.\n>\n> Several libraries already exist for React d3 integration, but just a few provide server side rendering ability and fully declarative charts.\n\n설명에 의하면 nivo는 `D3` 이라는 데이터기반 시각화 라이브러리를 이용하여 리액트에서 쉽게 사용할 수 있도록 만든 리액트 라이브러리입니다.\n\n### 라인 차트 만들기\n\n실시간 경매가는 `라인 차트`로 그려져야 하므로 , nivo의 Line 항목을 살펴보겠습니다.\n\n![nivo-document](/public/posts/nivo-chart/nivo-document.png)\n\n좌측에는 실시간으로 커스터마이징 할 수 있게 되어있으며 , 오른쪽에 차트의 모습과 코드를 살펴볼 수 있습니다.\n\n라인 차트를 그리려면 `ResponsiveLine` 컴포넌트가 필요하므로 `@nivo/line` 을 설치해주어야 합니다.\n\n그 후 제공되는 코드를 넣으면 다음과 같은 `svg` 가 그려집니다.\n\n![line-example](/public/posts/nivo-chart/line-example.png)\n\n기본적으로 `data` 에 할당되는 데이터셋에 의하여 차트가 자동적으로 그려지게 됩니다.\n\n하지만 제가 구현할 실시간 경매가 차트는 x축에는 시간 , y축에는 가격이 표시되므로 데이터를 변경해야 합니다.\n\n현재 더미데이터는 다음과 같이 구성되어 있습니다.\n\n```jsx title=\"chartData\"\nconst chartData = [\n  {\n    id: 'japan',\n    color: 'hsl(148, 70%, 50%)',\n    data: [\n      {\n        x: 'plane',\n        y: 248,\n      },\n      {\n        x: 'helicopter',\n        y: 293,\n      },\n      {\n        x: 'boat',\n        y: 151,\n      },\n      {\n        x: 'train',\n        y: 55,\n      },\n      {\n        x: 'subway',\n        y: 282,\n      },\n      {\n        x: 'bus',\n        y: 90,\n      },\n      {\n        x: 'car',\n        y: 225,\n      },\n      {\n        x: 'moto',\n        y: 85,\n      },\n      {\n        x: 'bicycle',\n        y: 68,\n      },\n      {\n        x: 'horse',\n        y: 153,\n      },\n      {\n        x: 'skateboard',\n        y: 240,\n      },\n      {\n        x: 'others',\n        y: 298,\n      },\n    ],\n  },\n]\n```\n\n변경할 데이터에는 x축에 시간이 할당 될 것이므로 다음과 같이 바꿀 수 있습니다.\n\n```jsx title=\"chartData\"\nconst chartData = [\n  {\n    id: 'price',\n    color: 'hsl(148, 70%, 50%)',\n    data: [\n      {\n        x: new Date('2023-08-04 13:00'),\n        y: 1000,\n      },\n      {\n        x: new Date('2023-08-05 13:00'),\n        y: 1100,\n      },\n      {\n        x: new Date('2023-08-06 13:00'),\n        y: 1500,\n      },\n      {\n        x: new Date('2023-08-07 13:00'),\n        y: 2000,\n      },\n    ],\n  },\n]\n```\n\n이제 축(axis)을 담당하는 `xScale`과 `axisBottom`을 수정해야 합니다.\n\n시간을 데이터로 하였을때는 xScale에서 type을 time으로 지정해주는 방법이 존재하지만,\n**이 경우 중간값이 자동적으로 계산되어 데이터의 포인트를 정확하게 정해주기 힘들기 때문에**\n\npoint로 지정한 후 axisBottom에서 format을 이용해 , 시간을 `intl`을 이용해 보기좋게 포매팅하여 표시해주도록 하는 방식을 택했습니다.\n\n또한 차트 그라디언트 색이 x축을 넘어서 표시되는데 , **이때** `areaBaselineValue`**의 값을 데이터 y의 최소값으로 지정해주어야 넘치지 않고 표시되게 됩니다.**\n\n최종 이미지와 코드는 다음과 같습니다.\n\n![line-example2](/public/posts/nivo-chart/line-example2.png)\n\n```jsx title=\"LineChart\"\nconst LineChart = () => {\n  return (\n    <ResponsiveLine\n      data={chartData}\n      margin={{ top: 50, right: 60, bottom: 50, left: 60 }}\n      xScale={{ type: 'point' }}\n      yScale={{\n        type: 'linear',\n        min: 'auto',\n        max: 'auto',\n        stacked: true,\n        reverse: false,\n      }}\n      axisTop={null}\n      axisRight={null}\n      axisBottom={{\n        format: (tick) =>\n          new Intl.DateTimeFormat('ko', {\n            dateStyle: 'short',\n            timeStyle: 'short',\n          }).format(tick),\n        tickSize: 5,\n        tickPadding: 5,\n        tickRotation: 0,\n      }}\n      axisLeft={{\n        tickSize: 5,\n        tickPadding: 5,\n        tickRotation: 0,\n      }}\n      enableGridY={false}\n      pointSize={10}\n      pointColor={{ theme: 'background' }}\n      pointBorderWidth={2}\n      pointBorderColor={{ from: 'serieColor' }}\n      pointLabelYOffset={-12}\n      enableArea={true}\n      areaBaselineValue={chartData[0].data[0].y}\n      isInteractive={false}\n      useMesh={true}\n    />\n  )\n}\n```\n\n### 파이 차트 만들기\n\n이제 그림의 태그를 표시할 `파이 차트`를 만들어보겠습니다.\n\n라인 차트와 유사하게 , 파이 차트를 그리려면 `ResponsivePie` 컴포넌트가 필요하므로 `@nivo/pie` 를 설치합니다.\n\n그 후 제공되는 코드를 넣으면 다음과 같은 파이 차트가 그려집니다.\n\n![pie-example](/public/posts/nivo-chart/pie-example.png)\n\n기본적으로 `data` 에 할당되는 데이터셋에 의하여 차트가 자동적으로 그려지게 됩니다.\n\n제가 구현할 태그 차트와 유사하지만 `value`와 `label`이 숫자가 밖으로 나오게 반대로 표시되어야 합니다.\n\n파이 안쪽의 글자는 `arcLabel`에 해당하는데 , 여기에 `id`를 할당합니다.\n\n파이 바깥의 글자는 `arcLinkLabel`에 해당하는데 , 여기에는 `value`를 할당해줍니다.\n\n이때 value에 %를 붙여서 표시하고 싶으므로 , `${d.value}%` 와 같이 표시해줍니다.\n\n최종 이미지와 코드는 다음과 같습니다.\n\n![pie-example2](/public/posts/nivo-chart/pie-example2.png)\n\n```jsx title=\"PieChart\"\nconst PieChart = () => {\n  return (\n    <ResponsivePie\n      data={chartData}\n      margin={{ top: 40, right: 80, bottom: 80, left: 80 }}\n      innerRadius={0.5}\n      padAngle={0.7}\n      cornerRadius={3}\n      activeOuterRadiusOffset={8}\n      borderWidth={1}\n      borderColor={{\n        from: 'color',\n        modifiers: [['darker', 0.2]],\n      }}\n      arcLabel=\"id\"\n      arcLinkLabel={(d) => `${d.value}%`}\n      arcLinkLabelsSkipAngle={10}\n      arcLinkLabelsTextColor=\"#333333\"\n      arcLinkLabelsThickness={2}\n      arcLinkLabelsColor={{ from: 'color' }}\n      arcLabelsSkipAngle={10}\n      arcLabelsTextColor={{\n        from: 'color',\n        modifiers: [['darker', 2]],\n      }}\n      isInteractive={false}\n    />\n  )\n}\n```\n\n### 결론\n\n리액트 환경에서 nivo를 사용하면 데이터를 쉽게 시각화할 수 있어 유용하게 사용할 수 있었습니다.\n\n다양한 차트 라이브러리가 있지만 nivo를 사용하며 아직까지 다른 라이브러리를 사용해야할 이유를 느끼지 못하였기에 차트가 필요하면 앞으로도 nivo를 적극적으로 활용할 것 같습니다.\n",
      "width": 2000,
      "height": 1235
    },
    "optimistic-update": {
      "slug": "optimistic-update",
      "date": "2023-12-19T00:00:00.000Z",
      "title": "react query를 사용한 낙관적 업데이트",
      "description": "react query를 사용해 낙관적 업데이트를 하는 과정에 대해 설명합니다.",
      "tags": [
        "react-query",
        "optimistic update"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/optimistic-update/optimistic-X.gif",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRkoAAABXRUJQVlA4ID4AAADQAQCdASoNABAABUB8JZQAAl2+yUgLgAD+79eZWyJtlD1d+xfoiNvw13rI86QsDclAA0pffkQoLnd/IbgAAA==",
      "writer": "leey00nsu",
      "content": "\n## react-query 낙관적 업데이트(Optimistic Update) 하기\n\n프로젝트에 `좋아요` 기능을 추가하려고 합니다.\n\n사용자가 좋아요 버튼을 누르면 `useMutation`을 통해 api를 호출하는 방식입니다.\n\n```jsx title=\"useMutation\"\nconst { mutate: toggleListLikeMutate } = useMutation({\n    mutationKey: ['toggleListLikeArticle'],\n    retry: false,\n    mutationFn: toggleLikeArticle,\n\t\t...\n})\n```\n\n기본적으로 호출한 결과를 화면에 표시하기 위해서 `onSuccess` 콜백을 통해 해당 `쿼리 키`를 무효화시켜 데이터를 갱신시킬 수 있습니다.\n\n```jsx title=\"onSuccess\"\nonSuccess: () => {\n    queryClient.invalidateQueries({ queryKey: ['getArticleList'] });\n},\n```\n\n하지만 네트워크 환경에 따라, **서버에서 응답이 오는 시간까지 UI에 변화가 없게 됩니다.**\n\n따라서 UX 개선을 위해 `낙관적 업데이트(Optimistic Update)`를 사용해볼 수 있습니다.\n\n### 낙관적 업데이트\n\n`낙관적 업데이트`는 `mutate`를 성공하였을 때 예상되는 결과로 쿼리 데이터를 **먼저 변화시켜주는 것입니다.**\n\n[공식문서](https://tanstack.com/query/latest/docs/react/guides/optimistic-updates)에 따르면 좋아요를 예시로 들었을 때, 기존 방식과의 차이는 다음과 같습니다.\n\n```markdown {5} title=\"낙관적 업데이트 적용 X\"\n-> 좋아요 클릭\n-> 서버에 요청\n-> 서버 응답\n-> 서버 데이터로 쿼리를 다시 갱신\n-> 클라이언트 UI 변화 (좋아요 수 : 1 , 좋아요 X → 좋아요 수 : 2 , 좋아요 O)\n```\n\n```markdown {3} title=\"낙관적 업데이트 적용 O\"\n-> 좋아요 클릭\n-> 서버에 요청\n-> 클라이언트 UI 변화 (좋아요 수 : 1 , 좋아요 X → 좋아요 수 : 2 , 좋아요 O)\n-> 서버 응답\n-> 실제 서버 데이터로 쿼리를 다시 갱신\n```\n\n실제 적용된 코드를 살펴보겠습니다.\n\n```jsx title=\"useToggleLike\"\nconst { mutateAsync: toggleLikeMutate } = useMutation({\n    mutationKey: ['toggleLikeArticle'],\n    retry: false,\n    mutationFn: toggleLikeArticle,\n    onMutate: async id => {\n\t\t\t// 상세 쿼리를 취소한다. (낙관적 업데이트가 덮어쓰지 않도록)\n      await queryClient.cancelQueries({ queryKey: ['getArticle', id] });\n\n      const previousArticle = queryClient.getQueryData<\n        ApiResponse<ListArticle>\n      >(['getArticle', id]);\n\n      // 쿼리 데이터에 대하여 좋아요 상태를 업데이트한다.\n      const uploadArticle = produce(previousArticle, draft => {\n        const article = draft?.data;\n        if (article) {\n          article.isLiked = !article?.isLiked;\n          article.likeCount += article?.isLiked ? 1 : -1;\n        }\n      });\n\n      // 쿼리 데이터를 낙관적 업데이트한다.\n      queryClient.setQueryData(['getArticle', id], uploadArticle);\n\n      return { previousArticle, id };\n    },\n    onError: (err, _, context) => {\n\t\t\t// 에러 발생시 기존 데이터로 롤백\n\t\t\tqueryClient.setQueryData(\n\t\t        ['getArticle', context?.id],\n\t\t        context?.previousArticle,\n\t\t      );\n    },\n    onSuccess: (err, _, context) => {\n\t\t\t// 성공 시 쿼리 재요청\n\t\t\tqueryClient.invalidateQueries({ queryKey: ['getArticle', context?.id] });\n    },\n  });\n```\n\n먼저 `onMutate` 콜백에서 `cancelQueries`를 통해 쿼리를 취소합니다.\n\n이 과정을 통하여, **만약 이 mutate 중에 해당 쿼리 키에 대해서 업데이트가 발생해도 반영되지 않습니다.**\n\n그 후, 기존 데이터를 변형시켜 예상되는 결과로 만들어줍니다.\n\n예제 코드에서는 불변성 관리 라이브러리인 `immer`를 사용하여 객체를 변형시켰습니다.\n\n이제 변형시킨 결과를 해당 쿼리 키에 적용시켜주면 **마치 서버에서 응답이 온 것 처럼** 쿼리 키가 업데이트 됩니다.\n\n또한 에러가 발생했을 때는 기존의 쿼리 데이터로 다시 롤백시켜주고, 성공시에는 실제 응답으로 데이터를 덮어쓰면 됩니다.\n\n또는 에러나 성공 모두에 대한 케이스인 `onSettled`를 통해 결과와 상관없이 재요청하도록 하는 방법도 존재합니다.\n\n```jsx title=\"onSettled\"\nonSettled: () => {\n      // 응답 시 쿼리 재요청\n      queryClient.invalidateQueries({\n        queryKey: [\n          'getArticleList',\n          currentOrderBy,\n          currentOrder,\n          filter.author,\n        ],\n      });\n    },\n```\n\n### 결과\n\n낙관적 업데이트를 적용한 결과를 브라우저의 mid-tier 네트워크를 통해 `느린 네트워크 상황`에서 확인해보겠습니다.\n\n|                      낙관적 업데이트 적용 X                       |                      낙관적 업데이트 적용 O                       |\n| :---------------------------------------------------------------: | :---------------------------------------------------------------: |\n| ![optimistic-X](/public/posts/optimistic-update/optimistic-X.gif) | ![optimistic-O](/public/posts/optimistic-update/optimistic-O.gif) |\n\n한 눈에 봐도 **낙관적 업데이트를 한 쪽의 UI 반영이 더 빠른 것을 알 수 있습니다.**\n\n모든 요청에 대해 낙관적 업데이트를 적용하기는 어렵기 때문에 반영할 수 있는 부분을 고려하면 **좋은 UX**를 구현할 수 있을 것 같습니다.\n",
      "width": 374,
      "height": 454
    },
    "prettier-import-order": {
      "slug": "prettier-import-order",
      "date": "2023-11-05T00:00:00.000Z",
      "title": "prettier import 설정하기",
      "description": "prettier를 사용하여 import 순서를 정렬하는 법에 대해 설명합니다.",
      "tags": [
        "prettier"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/prettier-import-order/messy-order.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRigAAABXRUJQVlA4IBwAAAAwAQCdASoQAAMABUB8JZwAA3AA/u4WN1ZGgAAA",
      "writer": "leey00nsu",
      "content": "\n## Prettier에서 import 순서 정렬하기\n\n프로젝트를 진행하다 보면, import를 할 때 구분없이 쌓이는 경우가 많습니다.\n\n![messy-order](/public/posts/prettier-import-order/messy-order.png)\n\n**prettier를 이용해서 특정한 순서를 가지고 import 순서를 정렬한다면, 나중에 코드를 볼 때 쉽게 읽힐 것입니다.**\n\n따라서 해당 정렬을 도와주는 라이브러리인 [prettier-plugin-sort-imports](https://github.com/trivago/prettier-plugin-sort-imports)를 설치해보겠습니다.\n\n```jsx title=\"@trivago/prettier-plugin-sort-imports\"\nnpm i @trivago/prettier-plugin-sort-imports\n```\n\n설치한 후, 기존에 prettier 설정에 추가하면 됩니다.\n\n제 경우에는 설정 파일이 `.prettierrc` 이므로 해당 파일에 추가하였습니다.\n\n```jsx title=\".prettierrc\"\n{\n\t...\n  \"importOrder\": [\n    \"<THIRD_PARTY_MODULES>\",\n    \"^@/constants/(.*)$\",\n    \"^@/apis/(.*)$\",\n    \"^@/store/(.*)$\",\n    \"^@/hooks/(.*)$\",\n    \"^@/pages/(.*)$\",\n    \"^@/features/(.*)$\",\n    \"^@/components/(.*)$\",\n    \"^@/ui/(.*)$\",\n    \"^[./]\"\n  ],\n  \"importOrderSeparation\": true,\n  \"importOrderSortSpecifiers\": true,\n  \"plugins\": [\n    \"@trivago/prettier-plugin-sort-imports\",\n\t\t...\n  ]\n}\n```\n\n`importOrder`에 정렬할 순서를 정규표현식으로 적어줍니다.\n\n여기서, `THIRD_PARTY_MODULES`는, 외부 라이브러리를 의미합니다.\n\n`importOrderSeparation` 를 true로 하면, 작성한 순서마다 한 줄의 공백을 추가합니다.\n\n![ordered-order](/public/posts/prettier-import-order/ordered-order.png)\n\n이제 prettier를 다시 작동시키게 되면 import 순서가 정렬된 것을 볼 수 있습니다.\n",
      "width": 1146,
      "height": 210
    },
    "react-infinite-scroll": {
      "slug": "react-infinite-scroll",
      "date": "2023-05-09T00:00:00.000Z",
      "title": "리액트에서 무한스크롤 구현해보기",
      "description": "리액트에서 무한 스크롤을 구현하는법에 대해 설명합니다.",
      "tags": [
        "react",
        "무한 스크롤"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/react-infinite-scroll/demo.gif",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRkQAAABXRUJQVlA4IDgAAACwAQCdASoIABAABUB8JaQAAucKdTAAAP68nwF/ysnuLP9aCe54uSJBvDTjGrkN88jnuKFZqIAAAA==",
      "writer": "leey00nsu",
      "content": "\n## 무한스크롤\n\n리스트에 끝에 닿았을 때 , api를 호출하여 리스트를 추가하는것을 구현하고자 합니다.\n\n흔히 이런 방식을 `무한 스크롤(Infinite Scroll)` 방식이라고 합니다.\n\n이때 **스크롤 이벤트를 감시하여 체크하는 방법**과 , **리스트가 뷰포트에 들어왔을때 체크하는 방법** 두 방식으로 기능을 구현할 수 있습니다.\n\n하지만, 스크롤 이벤트 방식은 성능 이슈가 발생할 수 있으며 , 요소가 많을 경우 처리하기 힘들기 때문에 뷰포트를 이용하여 구현해 보겠습니다.\n\n### Intersection Observer API를 이용한 구현\n\n`Intersection Observer API`는 브라우저에서 제공하는 자바스크립트 API중 하나로 **요소가 뷰포트에 나타나거나 사라질 때 콜백 함수를 호출하여 처리합니다.**\n\n여기서는 커스텀훅인 `useIntersectionObserver`를 직접 구현하여 사용하였지만, `react-intersection-observer`와 같은 커스텀 훅 라이브러리를 사용할 수도 있습니다.\n\n```jsx title=\"useIntersectionObserver\"\nimport { useRef } from \"react\";\nexport default function useIntersectionObserver(callback: () => void) {\n  const observer = useRef(\n    new IntersectionObserver(\n      (entries, observer) => {\n        entries.forEach((entry) => {\n          if (entry.isIntersecting) {\n            callback();\n          }\n        });\n      },\n      { threshold: 1 }\n    )\n  );\n\n  const observe = (element: any) => {\n    observer.current.observe(element);\n  };\n\n  const unObserve = (element: any) => {\n    observer.current.unobserve(element);\n  };\n\n  return [observe, unObserve];\n}\n```\n\n`useRef`를 이용해 기준이 될 요소에 ref 속성을 부여한 후, 커스텀 훅에 ref를 등록하면 이 요소가 뷰포트에 나타날때마다 콜백 함수가 실행되게 됩니다.\n\n여기서는 다음 페이지를 fetch해오는 함수를 콜백에 등록시켜보겠습니다.\n\n```jsx title=\"useRef\"\n...\nconst infScroll = useRef(null);\n\n\nconst [observe, unObserve] = useIntersectionObserver(() => {\n  fetchNextPage(); // 다음 페이지를 fetch해오는 함수이다.\n});\n\nuseEffect(() => {\n    observe(infScroll.current);\n}, []);\n\n...\n\n<div ref={infScroll} >\n  ...\n</div>\n```\n\n### 결과\n\n![infinite-scroll-demo](/public/posts/react-infinite-scroll/demo.gif)\n\n예상대로 스크롤 끝이 인식되면 계속해서 리스트를 불러오는 것을 볼 수 있습니다.\n",
      "width": 600,
      "height": 1132
    },
    "syu-character-maker-retrospect": {
      "slug": "syu-character-maker-retrospect",
      "date": "2024-01-31T00:00:00.000Z",
      "title": "나만의 수야, 수호 만들기 회고",
      "description": "나만의 수야, 수호 만들기 프로젝트를 배포하며 느낀 점을 적어봅니다.",
      "tags": [
        "나만의 수야 수호 만들기",
        "회고"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/syu-character-maker-retrospect/syu-character-maker.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRlgAAABXRUJQVlA4IEwAAAAQAgCdASoQAAwABUB8JYgCdH8AE4hbWYIAAP7t2TKFgVfpxWwNQzz52hsFyxrgKkcmOkM0G688OWT3tPE41JUxGSne8Jo5vEPrZAAA",
      "writer": "leey00nsu",
      "content": "\r\n## 나만의 수야, 수호 만들기 회고\r\n\r\n### 나만의 수야 수호 만들기?\r\n\r\n다사다난하던 1학기가 끝나고, 모든 인턴에 떨어진 저는 시간적으로 여유가 생겼습니다.\r\n\r\n무엇을 할 지 고민하다 이전에 틀만 만들어두었던 프로젝트를 고도화하기로 결정하였습니다.\r\n\r\n그 프로젝트는 `나만의 수야 수호 만들기` 라는 프로젝트입니다.\r\n\r\n`나만의 수야 수호 만들기`는 삼육대학교의 마스코트인 수야와 수호를 꾸밀 수 있는 프로그램입니다.\r\n\r\n아이디어는 [개발진스](https://devjeans.dev-hee.com/) 라는 프로젝트를 모티브로 시작되었습니다.\r\n\r\n기존의 형태는 캐릭터인 수야, 수호를 선택하고 , 그 위에 단색 펜으로 그림을 그리는 구조였습니다.\r\n\r\n![syu-character-maker](/public/posts/syu-character-maker-retrospect/syu-character-maker.png)\r\n\r\n### 어떻게 고도화 할 것인가?\r\n\r\n지금의 프로젝트는 단순한 정적 페이지이기 때문에 `vercel`을 통해 호스팅되고 있습니다.\r\n\r\n프로젝트에 백엔드를 추가하고 `같은 도메인`에서 프론트엔드와 백엔드를 함께 배포할 것입니다.\r\n\r\n### 왜 같은 도메인에 배포하나요?\r\n\r\n백엔드는 `nest` 에 `postgres,redis` 를 연결하여 `RESTAPI` 서버로 사용합니다.\r\n\r\n사용자가 그린 그림을 서버에 저장하도록 할 것이므로 `유저 인증` 기능이 필요합니다.\r\n\r\n이때 유저의 인증과정에서 `세션` 방식을 채택하였는데 그 이유는 다음과 같습니다.\r\n\r\n지금까지의 다른 팀 프로젝트에서는 인증이라고 하면 모두 `jwt` 방식을 사용하였습니다.\r\n\r\n그때는 jwt를 많이 쓰는구나 하고 넘어갔지만, 이번에는 서버도 제가 담당하므로 확실한 이유가 있어야 합니다.\r\n\r\n궁금하여 검색을 해 본 결과 세션과 jwt의 특징과 주요한 차이점은 다음과 같았습니다.\r\n\r\n> `세션` : 서버측에서 접속한 사용자 정보를 저장하고 , 세션ID를 클라이언트에 전달한다.\r\n>\r\n> - 장점 : 서버에 저장하므로 , 클라이언트에 노출되지 않아 안전하다. 서버에서 만료하기 편하다.\r\n> - 단점 : 서버 부하가 증가할 수 있다. 또한 분산 환경에 대응이 복잡해진다.\r\n\r\n> `jwt` : 사용자 정보로 jwt를 생성해 클라이언트에 전달한다.\r\n>\r\n> - 장점 : 클라이언트에서 저장하므로, 서버의 부담이 줄어들고 분산 환경에서 상태를 쉽게 공유할 수 있다.\r\n> - 단점 : jwt는 클라이언트에 저장되므로 보안을 고려해야 한다. 만료하기 어렵다.\r\n\r\n사실 제가 구성한 프로젝트의 규모에서는 어느쪽을 택해도 상관 없기 때문에 해본적 없었던 세션 방식으로 구현해보기로 결정하였습니다.\r\n\r\n세션ID는 클라이언트에 쿠키로 저장됩니다. 따라서 클라이언트에서 **서버로 요청할 때 헤더에 쿠키를 담아서 보내주어야** 이를 처리할 수 있습니다.\r\n\r\n이때, 클라이언트에서는 [프론트엔드 개발자에게 악명 높은](https://evan-moon.github.io/2020/05/21/about-cors/) `CORS` 정책을 따라야만 쿠키를 전송할 수 있습니다.\r\n\r\n> 브라우저에서는 보안을 위해 동일 출처 정책(Same-Origin Policy)을 따라, 동일한 출처에서만 리소스에 접근할 수 있도록 제한하고 있습니다.\r\n> 하지만 다른 도메인의 리소스에 접근하는 일이 빈번하게 발생하므로 CORS(Cross-Origin Resource Sharing)를 따라 접근할 수 있는 것입니다.\r\n\r\nCORS 정책을 따르기 위해서는 서버측에서 `응답 헤더`에 대해 설정을 해주어야 합니다.\r\n\r\n또한 보안을 위해 쿠키의 `HttpOnly`를 설정해줍니다.\r\n\r\n```markdown title=\"CORS 설정\"\r\nAccess-Control-Allow-Origin: 허용된 출처를 나타냅니다.\r\nAccess-Control-Allow-Methods: 허용된 HTTP 메서드를 나타냅니다.\r\nAccess-Control-Allow-Credentials: 쿠키 및 자격 증명을 허용할지 여부를 나타냅니다.\r\n\r\nSameSite=None: 쿠키가 항상 cross-site 요청에 포함되도록 허용합니다. 단, Secure 속성이 필요합니다.\r\nSameSite=Lax: 일부 상황에서만 cross-site 요청에 포함되도록 허용합니다.(예: 탐색을 통한 GET 요청).\r\nSameSite=Strict: 모든 cross-site 요청에서 쿠키가 전송되지 않도록 제한합니다.\r\n```\r\n\r\n또한 클라이언트 쪽에서도 `요청 헤더`에 대해 설정을 해주어야 합니다.\r\n\r\n```jsx title=\"fetch나 axios 요청 헤더\"\r\ncredentials: include\r\n```\r\n\r\n이때, 요청 헤더가 `credentials: include` 일때 `Access-Control-Allow-Origin = '*'` 로 설정해 두었다면 , 브라우저에서 오류가 발생합니다.\r\n\r\n따라서 **다른 도메인에서 쿠키를 보내기 위해서는 `Access-Control-Allow-Origin` 에 URL을 명시해야 합니다.**\r\n\r\n이제 쿠키를 보낼 준비가 되었습니다.\r\n\r\n쿠키를 다른 도메인에 보내기 위해서 `SameSite=none`을 설정하기 위해서는 , `secure=true`여야 합니다.\r\n\r\nsecure를 사용하려면 프로토콜이 https여야 하기 때문에 서버의 프로토콜을 `https`로 변경해야 하는데, 서버의 **프로토콜이 https가 되면 , http와도 다른 도메인이 되므로** , 클라이언트 또한 https로 변경되어야 합니다.\r\n\r\n모두 변경하였다면 클라이언트, 서버 모두 https일 때 쿠키 전송을 위한 세팅을 마쳤습니다.\r\n\r\n또한 정상적으로 쿠키가 전송되는 것을 확인할 수 있었습니다.\r\n\r\n하지만 … **크로스 브라우징 테스트를 하던 중 `safari`에서 쿠키가 전달이 안되고 있는 것을 발견했습니다.**\r\n\r\n![safari-cookie-issue](/public/posts/syu-character-maker-retrospect/safari-cookie-issue.png)\r\n\r\n검색을 해보니, **safari 기본 설정에서는 `SameSite=none`을 해주었더라도 다른 도메인끼리 쿠키를 전달할 수 없도록 바뀌었다고 합니다.**\r\n\r\n따라서, **safari에 대응하기 위해서는 클라이언트와 서버가 같은 도메인이 되어야 합니다.**\r\n\r\n### 오라클 클라우드에 배포하기\r\n\r\n앞서 클라이언트와 서버를 **같은 도메인**에 배포해야 하는 결론에 다다랐습니다.\r\n\r\n따라서 기존의 프론트엔드는 `vercel`에 호스팅 되어있었는데, 이를 클라우드로 호스팅 되도록 모두 변경해야 합니다.\r\n\r\n클라우드에는 `aws,gcp,azure` 등등 유명한 서비스가 많습니다. 보통 많은 사람들이 사용하는 것은 aws 일 것입니다.\r\n\r\n하지만 **aws에서 무료로 제공되는 ec2 인스턴스의 성능이 낮기 때문에** `oracle`을 채택하였습니다.\r\n\r\n> oracle 클라우드는 비교적 후발주자로서 프리티어로 제공하는 인스턴스의 성능이 다른 클라우드 서비스보다 좋으며(4코어 24기가), 트래픽 아웃바운드를 10TB 까지 무료로 제공해줍니다.\r\n\r\n대신 단점으로는, 유저풀이 적기 때문에 **정보와 오류에 대한 해결방법이 적다는 점**입니다.\r\n\r\n그래도 이 단점을 상쇄할 만큼 성능적인 부분이 앞서기 때문에, oralce 인스턴스로 결정했습니다.\r\n\r\n이전에 aws를 사용해 본 경험이 있는데, 용어가 약간 다를뿐 기본적으로 제공하는 서비스의 구조는 비슷해서 금방 적응할 수 있었습니다.\r\n\r\n또한 전반적인 진행은 정리가 잘 된 [블로그](https://sonhc.tistory.com/906)를 따라 진행하였습니다.\r\n\r\n### 배포 과정\r\n\r\n프로젝트는 다음과 같은 구조를 가지도록 구성하였습니다.\r\n\r\n![project-structure](/public/posts/syu-character-maker-retrospect/project-structure.png)\r\n\r\n`nest`에 `postgreSQL DB`와 세션 DB로 `redis`를 활용하였고 `도커`와 `도커 컴포즈`를 사용하여 쉽게 배포 하기 위해 노력했습니다.\r\n\r\n처음 구성해보았는데 한 번 해보고 나니 전체적인 프로젝트의 흐름을 파악할 수 있는 좋은 경험이였습니다.\r\n\r\n### 후기\r\n\r\n고도화를 진행하면서, **어떻게 사용자들이 편하게 사용할 수 있을지**에 대해서 많은 시간 고민하였습니다.\r\n\r\n물론, 타겟 유저층이 학교 사람들이기 떄문에 많은 유저를 확보할 수 있을거라고는 생각하지 않았습니다.\r\n\r\n하지만 얼마나 많은 사람들이 이용해줄까 하는 호기심에 `구글 애널리틱스`를 추가하여 배포한 날로부터 측정하였습니다.\r\n\r\n![everytime](/public/posts/syu-character-maker-retrospect/everytime.png)\r\n\r\n![analytics](/public/posts/syu-character-maker-retrospect/analytics.png)\r\n\r\n1월 3일에 배포를 한 후, 약 `300`명 정도의 사람들이 접속하였지만 확실히 배포하고 며칠 뒤부터는 많은 관심을 끌지 못한 것을 볼 수 있습니다.\r\n\r\n이렇게 이번 배포를 통해 **유저를 끌어모은다는 것이 쉽지 않은 일이구나**라는 것을 표면적으로 느낄 수 있었습니다.\r\n\r\n하지만, 많은 것을 배우며 제작하면서 즐거웠기 때문에 만족스러운 프로젝트였습니다.\r\n",
      "width": 2000,
      "height": 1475
    },
    "taking-meal-retrospect": {
      "slug": "taking-meal-retrospect",
      "date": "2023-01-28T00:00:00.000Z",
      "title": "밥 한끼 하자 회고",
      "description": "첫 팀 프로젝트인 밥 한끼 하자를 끝낸 후기",
      "tags": [
        "react-native",
        "회고"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/taking-meal-retrospect/taking-meal-banner.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRk4AAABXRUJQVlA4IEIAAACQAQCdASoQAAkABUB8JbACdACWEYAA1wl6933/0ujVHOL7phxCIJroZERmBmpf/+BAhUx0ovic5bPfP60LO38gAAA=",
      "writer": "leey00nsu",
      "content": "\n## 밥 한끼 하자\n\n![taking-meal-banner](/public/posts/taking-meal-retrospect/taking-meal-banner.png)\n\n[밥 한끼 하자](https://github.com/leey00nsu/TakingMeal)는 삼육대학교 SW 경진대회에 참가하기 위해 만들어진 프로젝트입니다.\n\n당시 GDSC 리드님과 코어분들, 그리고 타 동아리 멤버 한분이 있는 상태에서 제게 제안이 와 수락하게 되었습니다.\n\n당시에는 편입을 하고 나서 한 학기를 수강한 후 3학년 여름방학을 보내고 있던 중이었습니다. 프로그래밍에 대한 기초를 한 학기만에 다지기는 쉽지 않았고 추가적인 공부가 필요한 상태에서 이런 제안을 받아 기쁘면서도 당황스러웠습니다. 그러나 **프로젝트 경험이 개발자에게 있어 가장 중요하다고 생각하여** 프로젝트에 참가하게 되었습니다.\n\n### 팀 내 역할\n\n팀은 프론트엔드 2, 백엔드 2, 디자인 1로 이루어져 있어 이상적이라고 할 수도 있었지만, 사실 저는 프론트엔드에서 도움이 되지 않았습니다. (아무것도 몰랐기 때문에), 따라서 나머지 한 분이 리드하고 따라가는 형식이었습니다.\n가장 좋았던 점은 프로젝트를 어떻게 진행해가는지에 대해서 배울 수 있었다는 것이었습니다. **백엔드와 협업하는 것이 처음이었는데, API 명세서를 작성하는 등의 문서 작성이 협업에 꽤나 도움이 된다는 것**을 알 수 있었습니다.\n\n초기에 프로젝트의 목표가 앱으로 구체화 되었고, 리드 프론트엔드 분이 자신이 리액트를 할 줄 알기 때문에 리액트 네이티브로 개발하는 게 어떻겠냐고 하여 리액트 네이티브로 개발하게 되었습니다. 그때 당시 저는 리액트도 할 줄 모르고 당연히 리액트 네이티브도 할 줄 몰랐기 때문에 딱히 상관은 없었습니다. 리드 프론트엔드 분이 지도 부분, 가게 검색 등을 맡았고, 저는 영양소 차트, 음식 검색 및 추가 등을 맡았습니다. 리액트 네이티브를 100% 이해하지는 못해도 돌아가게는 할 수 있었기 때문에 **작동을 우선한 개발**을 하였습니다.\n\n### 힘들었던 점\n\n제 파트 중에서 가장 힘들었던 것은 리액트 네이티브에서 차트를 그리는 것이었습니다. 차트 라이브러리를 찾아보니 `victory-chart`라고 하는 라이브러리가 마음에 들어 사용하게 되었고 테스트 중에도 문제가 없어서 그 쪽으로 개발하게 되었습니다. 그러나 개발 도중 특정 화면에서 렌더링 시간이 너무 오래 걸려 확인해보니 차트 부분에서 병목이 발생했습니다. 원인을 찾을 수가 없어 그냥 라이브러리를 포기하고 **직접 차트를 구현하게 되었습니다.** 다시 생각해보면 단순 막대 그래프여서 금방 만들 수 있었으므로 굳이 라이브러리를 사용할 필요조차 없었습니다. 직접 만든 차트를 붙여보니 렌더링도 빠르고 잘 작동하였습니다.\n\n또 한 가지 문제였던 것은 생명주기(life cycle) 문제였습니다. 그때 당시 스와이프로 화면을 넘기는 것을 구현할 때 `react-native-tab-view` 라는 라이브러리를 사용하였습니다. 이 라이브러리의 작동 방식상 모든 컴포넌트가 작동되는 상태에서 스와이프시 화면을 넘기는 것이었기 때문에 `useEffect`를 조심해서 사용해야 했습니다. 하지만 리액트를 잘 몰랐기 때문에 **의존성을 간과한 채 한 컴포넌트에 무수한 useEffect를 작성하였고, 그 결과 예상할 수 없는 사이드 이펙트와 버그를 가지게 되었습니다.** 당시의 저로서는 해결할 수 없었기 때문에 심각한 오류만 수정한 채 프로젝트를 마무리하게 되었습니다.\n\n### 후기\n\n제게 있어서는 제대로 구성이 갖춰진 첫 팀 프로젝트여서 의미가 큽니다. 회고를 쓰는 지금도 리액트를 잘 다룬다고는 할 수 없지만, 이때에 비하면 많이 나아졌다고 생각됩니다. 크로스 플랫폼으로 개발하고 싶은 생각이 있기 때문에, 공부를 좀 더 하여 제대로 된 `react-native` 프로젝트에도 도전해보고 싶습니다.\n",
      "width": 1920,
      "height": 1080
    },
    "why-i-do-not-use-vercel-anymore": {
      "slug": "why-i-do-not-use-vercel-anymore",
      "date": "2024-07-04T00:00:00.000Z",
      "title": "내가 더 이상 Vercel 호스팅을 사용하지 않는 이유",
      "description": "Vercel에서 오픈소스 셀프 호스팅 플랫폼인 Coolify로 옮긴 이야기",
      "tags": [
        "ci/cd",
        "docker",
        "coolify"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/why-i-do-not-use-vercel-anymore/current-structure.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRigAAABXRUJQVlA4IBwAAAAwAQCdASoQAAwABUB8JZwAA3AA/vCTsLWcmgAA",
      "writer": "leey00nsu",
      "content": "\r\n## 내가 더 이상 Vercel 호스팅을 사용하지 않는 이유\r\n\r\n지금까지는 토이프로젝트들을 `오라클 클라우드`에 배포하고 있었습니다.\r\n\r\n![current-structure](/public/posts/why-i-do-not-use-vercel-anymore/current-structure.png)\r\n\r\n`Nginx`를 이용하여 도커 위에 실행되는 프로젝트들을 리버시 프록시를 통해 SSL 인증서를 적용시키고, 접속을 분배해주고 있었습니다.\r\n\r\n하지만 지금의 형태에서 새로운 프로젝트를 추가하기 위해서는 프로젝트를 도커라이징 하는 `Github Actions`를 추가하고, 해당 프로젝트를 Nginx 설정에 추가하고 SSL을 적용하는 등 **번거로운 절차**를 걸쳐야 합니다.\r\n\r\n### Vercel\r\n\r\n따라서 정적 페이지나, Next.js의 경우에는 [Vercel](https://vercel.com/)을 통해 배포를 하기도 하였습니다.\r\n\r\nVercel의 호스팅 서비스를 이용하면 Github 레포지토리를 자동으로 연결하여 CI/CD를 편하게 설정하고 쉽게 배포할 수 있습니다.\r\n\r\n하지만 Vercel의 기본적으로 무료 플랜을 제공하지만, 고급 기능을 사용하거나 높은 트래픽을 처리해야 하는 경우 비용을 고려해야할 수도 있었습니다.\r\n\r\n또한, Nest.js 와 다른 컨테이너 기반의 프로젝트들을 편하게 호스팅하기 위하여 Vercel을 떠나 **기존의 오라클 클라우드를 사용하는 셀프 호스팅 방식을 고려하게 되었습니다.**\r\n\r\n### Coolify\r\n\r\n> Self-hosting with superpowers. An open-source & self-hostable Heroku / Netlify / Vercel alternative.\r\n\r\n`Coolify`는 개발자가 애플리케이션을 쉽게 배포하고 관리할 수 있도록 돕는 오픈소스 셀프 호스팅 플랫폼으로 인프라를 간편하게 관리하고, 다양한 애플리케이션을 배포할 수 있는 기능을 제공하며, **Vercel, Heroku, Netlify와 같은 관리형 서비스의 대안으로 사용할 수 있습니다.**\r\n\r\n### Why Coolify?\r\n\r\n그렇다면 왜 다양한 셀프 호스팅 플랫폼 중 Coolify를 선택했을까요?\r\n\r\n1. **셀프 호스팅 플랫폼**\r\n\r\n- `Coolify`는 사용자가 자신의 서버에 직접 설치하여 운영할 수 있는 셀프 호스팅 플랫폼입니다. 이를 통해 비용을 절감하고 데이터와 애플리케이션을 완전히 제어할 수 있습니다.\r\n\r\n2. **다양한 애플리케이션 지원**\r\n\r\n- Node.js, Python, Ruby, PHP 등 다양한 프로그래밍 언어로 작성된 애플리케이션을 지원합니다. Docker 이미지를 통해 어떤 언어로 작성된 애플리케이션이든 쉽게 배포할 수 있습니다.\r\n\r\n3. **자동화된 CI/CD 파이프라인**\r\n\r\n- Git 저장소와 통합되어 코드 변경 사항이 발생할 때마다 자동으로 빌드하고 배포할 수 있는 CI/CD 파이프라인을 제공합니다.\r\n\r\n4. **간편한 설정과 관리**\r\n\r\n- 직관적인 웹 인터페이스를 통해 애플리케이션과 서버를 쉽게 설정하고 관리할 수 있습니다. 복잡한 설정 없이 간편하게 애플리케이션을 배포할 수 있습니다.\r\n\r\n5. **SSL/TLS 지원**\r\n\r\n- `Let's Encrypt`와 통합되어 SSL/TLS 인증서를 자동으로 발급하고 갱신합니다. 이를 통해 보안 설정을 간편하게 유지할 수 있습니다.\r\n\r\n6. **리버스 프록시 및 로드 밸런싱**\r\n\r\n- `Traefik`과 같은 리버스 프록시와 로드 밸런서를 사용하여 트래픽을 효율적으로 관리하고, 고가용성을 유지할 수 있습니다.\r\n\r\n7. **롤링 업데이트 지원**\r\n\r\n- 롤링 업데이트 기능을 통해 애플리케이션을 가동 중단 없이 점진적으로 업데이트할 수 있습니다. 이를 통해 서비스의 연속성을 유지하고, 안정성을 확보할 수 있습니다.\r\n\r\n8. **모니터링 및 로깅**\r\n\r\n- 애플리케이션의 성능과 상태를 모니터링하고, 로그를 수집하여 문제를 신속하게 해결할 수 있습니다.\r\n\r\n### Coolify 시작하기\r\n\r\nCoolify를 시작하기 위해서는 간단한 bash 명령어를 실행시키면 됩니다. 자세한 설명은 [공식문서](https://coolify.io/docs/installation)에 있습니다.\r\n\r\n```bash title=\"coolify 설치\"\r\ncurl -fsSL https://cdn.coollabs.io/coolify/install.sh | bash\r\n```\r\n\r\n설치가 모두 끝나면, http://localhost:8000 를 통해 Coolify 대시보드 에 접근할 수 있습니다.\r\n\r\n![dashboard](/public/posts/why-i-do-not-use-vercel-anymore/dashboard.png)\r\n\r\n### 도메인 설정\r\n\r\nCoolify 프로젝트의 도메인을 설정하기 위해서는, `가비아`와 같은 도메인 제공 서비스를 통해 도메인을 발급받아야 합니다.\r\n\r\n이때, **`와일드 카드 도메인`을 설정하게 된다면, 프로젝트가 계속해서 추가되더라도 project1.domain, proejct2.domain, ... 과 같이 서브 도메인을 동적으로 설정할 수 있습니다.**\r\n\r\n### 배포\r\n\r\n![deploy](/public/posts/why-i-do-not-use-vercel-anymore/deploy.png)\r\n\r\nUI를 통해 프로젝트를 추가하여 새롭게 배포를 시작할 수 있습니다.\r\n\r\n기본적으로 Coolify는 [Nixpacks](https://nixpacks.com/docs)라는 빌드 팩을 사용하여 **배포하려는 애플리케이션의 종류를 감지하고 그에 따라 빌드합니다.**\r\n\r\n또한, `도커 이미지`나 `도커 컴포즈` 파일을 통해서 프로젝트를 배포할 수도 있으며, 기존에 Coolify에 미리 설정된 어플리케이션들을 사용할 수도 있습니다.\r\n\r\n그리고 한번 배포된 프로젝트는 새로운 커밋이 발생할 경우 자동적으로 재배포가 이루어집니다.\r\n\r\n### 무중단 배포\r\n\r\n![rolling-updates](/public/posts/why-i-do-not-use-vercel-anymore/rolling-updates.png)\r\n\r\n또한 Coolify는 `롤링 업데이트` 기능을 제공하여, 애플리케이션 배포 시 무중단 서비스를 가능하게 합니다.\r\n\r\n1. **컨테이너 기반 배포**\r\n\r\n- Coolify는 주로 컨테이너화된 애플리케이션을 배포합니다. Docker와 같은 컨테이너 기술을 사용하여 애플리케이션을 격리된 환경에서 실행합니다.\r\n\r\n2. **점진적 인스턴스 업데이트**\r\n\r\n- 애플리케이션 인스턴스를 한 번에 하나씩 업데이트합니다. 예를 들어, 10개의 인스턴스가 실행 중이라면, 먼저 1개를 업데이트한 후, 업데이트가 성공하면 다음 인스턴스를 업데이트하는 방식입니다.\r\n\r\n3. **로드 밸런싱**\r\n\r\n- 업데이트 중인 인스턴스를 제외한 나머지 인스턴스가 계속해서 트래픽을 처리합니다. 이를 통해 서비스의 연속성을 유지할 수 있습니다. Coolify는 Traefik과 같은 로드 밸런서를 사용하여 트래픽을 관리합니다.\r\n\r\n4. **헬스 체크**\r\n\r\n- 각 인스턴스가 업데이트된 후, Coolify는 해당 인스턴스의 상태를 확인합니다. 헬스 체크를 통과한 인스턴스만 트래픽을 처리하도록 허용합니다.\r\n\r\n5. **자동 롤백**\r\n\r\n- 만약 업데이트된 인스턴스에서 문제가 발견되면, Coolify는 해당 인스턴스를 이전 버전으로 롤백합니다. 이를 통해 안정성을 확보할 수 있습니다.\r\n\r\n### 결론\r\n\r\nCoolify를 이용하기 위해서는 인스턴스의 사양이 어느정도 보장되어야 한다는 제한 사항을 감수한다면 **현재까지는 Vercel에서 Coolify로 옮긴 것에 대해 만족하고 있습니다.**\r\n\r\nCoolify를 찾아보던 중 한 유튜버가 Coolify를 [아기들을 위한 쿠버네티스](https://www.youtube.com/shorts/LrKqptIOFTw) 라고 부른 것을 봤습니다.\r\n\r\n쿠버네티스는 어렵다는 이미지가 있어서 다가가기 힘들었는데 **Coolify를 통해 컨테이너화된 애플리케이션을 배포, 확장, 관리하기 위한 도구를 쉽게 체험해볼 수 있는 것 같습니다.**\r\n",
      "width": 5384,
      "height": 4201
    },
    "why-use-react-query": {
      "slug": "why-use-react-query",
      "date": "2023-08-02T00:00:00.000Z",
      "title": "react-query 도대체 왜 사용하는 걸까?",
      "description": "react-query 를 사용하여 비동기 함수를 사용하는 방식에 대해 설명합니다.",
      "tags": [
        "react",
        "react-query",
        "artfolio"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/why-use-react-query/query-structure.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRiwAAABXRUJQVlA4ICAAAAAwAQCdASoQAAYABUB8JaQAA3AA/vCAarNcLCP6Ur44AA==",
      "writer": "leey00nsu",
      "content": "\n## react-query 왜 사용할까?\n\n`react-query`를 검색해보면 다음과 같은 라이브러리라고 합니다.\n\n> React Query is **a data-fetching and state management library for React applications that simplifies fetching, caching, and updating data**.\n\n설명에 있듯이 `react-query`는 react 어플리케이션에서 비동기 데이터를 관리하고 캐시하며 상태를 관리하며 갱신하는데 도움을 주는 라이브러리입니다.\n\n이번에`artfolio` 프로젝트를 진행하면서 , 기존에 `useEffect`를 사용하여 비동기를 처리 하던 방식에서 react-query 를 사용하여 관리하는 방식을 채택하였습니다.\n\n기존의 useEffect를 이용한 비동기 처리 코드를 보면 다음과 같습니다.\n\n### useEffect를 사용한 코드\n\n```jsx title=\"useEffect\"\nimport React, { useEffect, useState } from 'react'\n\nfunction App() {\n  const [data, setData] = useState(null)\n  const [isLoading, setIsLoading] = useState(false)\n  const [error, setError] = useState(null)\n\n  useEffect(() => {\n    setIsLoading(true)\n    fetchData()\n      .then((response) => {\n        setData(response.data)\n        setIsLoading(false)\n      })\n      .catch((error) => {\n        setError(error)\n        setIsLoading(false)\n      })\n  }, [])\n\n  return (\n    <div>\n      {isLoading ? <p>Loading...</p> : null}\n      {error ? <p>Error: {error.message}</p> : null}\n      {data ? <p>Data: {data}</p> : null}\n    </div>\n  )\n}\n\nexport default App\n```\n\n반면 react-query를 사용하면 코드를 더 간결하게 작성할 수 있습니다.\n\n### react-query를 사용한 코드\n\n```jsx title=\"react-query\"\nimport React from 'react'\nimport { useQuery } from 'react-query'\n\nfunction App() {\n  const { data, isLoading, error } = useQuery('data', fetchData)\n\n  return (\n    <div>\n      {isLoading ? <p>Loading...</p> : null}\n      {error ? <p>Error: {error.message}</p> : null}\n      {data ? <p>Data: {data}</p> : null}\n    </div>\n  )\n}\n\nexport default App\n```\n\n`useQuery` 는 react-query에서 제공하는 훅으로써 , 데이터를 비동기적으로 가져오는데 사용됩니다.\n\n```jsx title=\"useQuery\"\nconst { data, ...options } = useQuery(queryKey, queryFunction, options)\n```\n\n- `queryKey` : 쿼리키는 어떤 데이터를 가져올 지 나타냅니다.\n- `queryFunction` : 데이터를 가져오는 함수이며 `Promise`를 반환해야합니다.\n- `option` : 다양한 옵션을 넣을 수 있습니다.\n\n## useQuery 도입\n\n이제 실제 `artfolio` 프로젝트에서 적용된 예시를 보겠습니다.\n\n![description](/public/posts/why-use-react-query/description.png)\n\n위 사진은 경매 상세 정보페이지입니다.\n\n위의 22350원과 , 밑의 22350원은 현재 경매가를 나타내는데 , **현재 경매가는 웹소켓 연동으로 인하여 서버 데이터와 실시간 동기화 되어야 합니다.**\n\n따라서 입찰하기를 누르는 순간 , 현재 경매가가 갱신되며 두 컴포넌트는 같은 값을 나타내야 합니다.\n\n상위 컴포넌트에서 데이터를 받아 props drilling으로 뿌려주는 간단한 일처럼 보이지만\n\n**두 컴포넌트는 상하관계가 아니며 분리되어 있으므로 전역적으로 관리하거나 각각 서버측에 요청을 해야 합니다.**\n\n이때, 서버데이터를 전역상태로 관리하는 것은 좋지 않은 방식이라고 생각했기에 다른 방식을 고려하게 되었습니다.\n\n<br />\n\n이 문제는 `쿼리키` 를 사용해서 , 요청시 같은 쿼리키를 사용함으로써 업데이트되면 다른 한 쪽도 캐싱되어 있는 데이터를 가져옴으로써 같은 데이터를 가지게 하였습니다.\n\n과정을 간단하게 풀어낸다면 다음과 같습니다.\n\n![query-structure](/public/posts/why-use-react-query/query-structure.png)\n\n실제로 적용하면 입찰과 동시에 경매 페이지의 내용(차트)도 함께 변하는 것을 볼 수 있습니다.\n\n![result](/public/posts/why-use-react-query/result.gif)\n\n## 결론\n\n이 외에도 비동기 함수를 사용할 때 대부분 react-query를 사용하였는데\n\nisLoading,isError와 같은 변수들로 데이터 상태를 추적할 수 있으며 , 쿼리옵션에 따라 데이터를 자동적으로 페칭하거나 유효 기간을 정할 수 있는 등 편리한 요소가 많으므로 앞으로도 사용할 것 같습니다.\n",
      "width": 1642,
      "height": 606
    },
    "why-use-ui-library": {
      "slug": "why-use-ui-library",
      "date": "2024-05-19T00:00:00.000Z",
      "title": "프론트엔드 UI 라이브러리를 사용하는 이유",
      "description": "프론트엔드 UI 라이브러리를 사용하는 이유에 대해서 설명합니다.",
      "tags": [
        "design",
        "mantine"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/why-use-ui-library/mantine.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRkIAAABXRUJQVlA4IDYAAADQAQCdASoQAAoABUB8JQBdgCHw+HpBwAD+1Ouizja34DlSdAPW0ALU1qFq0jqQ90JVQxQAAAA=",
      "writer": "leey00nsu",
      "content": "\r\n## 프론트엔드 UI 라이브러리를 사용하는 이유\r\n\r\n![mantine](/public/posts/why-use-ui-library/mantine.png)\r\n\r\n최근에 진행한 [noveloper](https://github.com/leey00nsu/noveloper) 프로젝트에서는 UI 라이브러리인 mantine을 사용하였습니다.\r\n\r\n외에도 저는 지금까지 진행해온 대부분의 프로젝트에서 `bootstrap`, `shadcn`, `daisyUI`, `NextUI` 와 같은 `프론트엔드 UI 라이브러리`를 사용해왔습니다.\r\n\r\n그렇다면 왜 이러한 **라이브러리**를 사용했을까요?\r\n\r\n### 바퀴를 재발명할 필요는 없다.\r\n\r\n**직접 모든 컴포넌트들을 구축하고 처음부터 스타일링 하는 것은 쉬운 일이 아닙니다.**\r\n\r\n만약 `CSS`를 이용하여 디자인적으로 훌륭한 컴포넌트들을 만들었다고 할 지라도 디자인 뿐만 아니라 `브라우저 호환성`, `접근성`, `반응형 디자인`, `성능`과 같은 사항들을 모두 고려해야 합니다.\r\n\r\nUI 라이브러리들에서는 이런 것들을 고려하여 **테스팅하고 컴포넌트들을 개발하고, 커뮤니티를 통해 유지보수 되므로 혼자서 모든 것을 처리하는 것보다 효율적으로 해결할 수 있습니다.**\r\n\r\n![mantine-issue](/public/posts/why-use-ui-library/mantine-issue.png)\r\n(mantine은 24.7k의 스타를 가졌지만 이슈는 단 24개인 것을 보니 얼마나 유지보수가 잘 되고 있는지 알 수 있습니다.)\r\n\r\n또한, 미리 만들어져 있는 컴포넌트를 사용하여 프로젝트를 빠르게 프로토타이핑 할 수 있습니다.\r\n\r\n### 프론트엔드 개발자와 디자이너\r\n\r\n**저는 디자인을 잘 하지 못합니다.**\r\n\r\n하지만 프론트엔드 개발자로서 유저들에게 **깔끔한 UI**를 제공하는 것은 항상 고민되는 부분이였습니다.\r\n\r\n서로 다른 UI 컴포넌트들이 일관성을 가지게 하는 것은 쉬운일이 아닙니다.\r\n\r\nUI 라이브러리는 일반적으로 일관된 디자인을 가지고 있으며, 깔끔하고 정돈된 디자인을 보이기 때문에 **베이스 디자인**으로 삼기에 훌륭합니다.\r\n\r\n### 디자인 시스템과 커스터마이징\r\n\r\n그렇다고해서 UI 라이브러리를 사용한 모든 프로젝트가 같은 디자인을 가지게 되는 것은 아닙니다.\r\n\r\n대부분의 라이브러리들에서는 **컴포넌트 별 커스터마이징 기능과 더불어 프로젝트 전체에 대해서 커스터마이징 할 수 있도록 테마를 수정하는 기능을 제공하기 때문에 각 프로젝트에 맞는 `디자인 시스템`을 구축할 수도 있습니다.**\r\n\r\n예를들어, [인프랩의 디자인시스템 구축](https://tech.inflab.com/20240224-design-system/) 에서는 왜 디자인 시스템을 오픈소스인 mantine을 베이스로 개발했는지에 대한 이유를 알아볼 수 있습니다.\r\n\r\n### 단점\r\n\r\n그렇다면 UI 라이브러리를 사용하는것은 **항상 옳을까요?**\r\n\r\n다음과 같은 단점들에 대해서도 생각해 볼 필요가 있습니다.\r\n\r\n- `오픈 소스` : 오픈 소스들은 언제나 유지 보수가 중단될 수 있는 위험을 가지고 있습니다. 또한, 오픈 소스의 개발 방향이 프로젝트가 원하는 방향과 다를 수 있습니다.\r\n- `번들 크기` : 라이브러리의 모든 컴포넌트가 코드에 포함되어 성능 문제가 발생할 수 있습니다.\r\n- `종속성` : 해당 UI 라이브러리가 다른 라이브러리에 종속성을 가지고 있다먼 버전 업데이트시 문제가 발생할 수 있습니다.\r\n- `학습 곡선` : 해당 라이브러리에 대해 팀이 학습하는 시간이 필요합니다.\r\n\r\n따라서 팀원간의 대화를 통해 프로젝트의 요구사항을 고려하여 UI 라이브러리에 대한 선택을 하는 것이 좋아보입니다.\r\n\r\n### 결론\r\n\r\n프로젝트를 진행하면서 다양한 UI 라이브러리를 사용해왔지만 그 이유로 단순히 편하다 라고만 생각했었습니다.\r\n\r\n이번 글을 포스팅하며, 다른 개발자들의 UI 라이브러리 사용에 대한 생각들을 알아보고 정리하며 머릿속으로 생각했던 이유들이 깔끔하게 설명되는 것 같습니다.\r\n",
      "width": 2268,
      "height": 1440
    }
  },
  "en": {
    "after-toy-project": {
      "slug": "after-toy-project",
      "date": "2023-10-14T00:00:00.000Z",
      "title": "Lessons Learned from Conducting a Small-Scale Project",
      "description": "Insights gained from conducting a small-scale project",
      "tags": [
        "회고"
      ],
      "section": "blog",
      "series": "",
      "thumbnail": "/public/posts/after-toy-project/storyboard.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRiYAAABXRUJQVlA4IBoAAAAwAQCdASoQABAABUB8JZwAA3AA/vB/j0AAAA==",
      "writer": "leey00nsu",
      "content": "\n## Conducting a Small-Scale Project\n\nDuring my undergraduate studies, I have had the opportunity to experience various projects.\n\nFrom my first project, where I knew nothing, to now, after a year of collaboration, I would like to share what I have learned and felt.\n\n### The Importance of Planning\n\nTo create a good service, good planning is essential.\n\nA project that starts from a simple idea can become a great project when **the stories of many people are added.**\n\nAt the undergraduate level, this process is mostly limited to team projects or club activities, so to gain diverse experiences, it seems beneficial to **participate in external competitions or events.**\n\n### How to Design a Project\n\nIn the `Capstone Design` course, I had the opportunity to learn in detail about `flowcharts` and `wireframes` from my mentor.\n\n![storyboard](/public/posts/after-toy-project/storyboard.png)\n\n![agile](/public/posts/after-toy-project/agile.png)\n\nFirst, I create a `flowchart`, and based on that flowchart, I develop a `wireframe`.\n\nAt this point, **the most important thing is that all team members must share the same understanding.**\n\nOne of the challenges I faced during projects was that many meetings were conducted verbally, and without documenting them, we often repeated discussions and **asked the same questions repeatedly.**\n\nTo prevent this, it is essential to create accurate `documentation` that can serve as a base for development.\n\nI also learned about the `Agile process`.\n\n### How Should Meetings Be Conducted?\n\nTo move away from the **haphazard meetings**, I started looking into other projects.\n\nAmong them, I found the retrospective of [Teo's Sprint](https://velog.io/@teo/google-sprint-1), which was conducted based on Google Sprint, particularly interesting, and I applied it to our work.\n\n![icebreaking](/public/posts/after-toy-project/icebreaking.png)\n![idea](/public/posts/after-toy-project/idea.png)\n\nAlthough there are originally more steps, I condensed the process into three stages: `Canvas` → `Idea Sketch` → `Implementation`.\n\nIn the `Team Canvas`, we conduct light ice-breaking by allowing team members to freely jot down their thoughts.\n\nIn the `Idea Sketch`, we write down ideas and select the final idea through presentations and voting.\n\nDuring `Implementation`, we discussed how to visualize each feature based on the ideas to finalize the implementation.\n\nFollowing this process naturally led us to `one result`.\n\nRegardless of the final implementation, I observed that all team members were satisfied with the **outcome of introducing this process.**\n\n### How Should Collaboration Be Done?\n\nI understand that in the industry, various collaboration tools such as `GitHub`, `Slack`, and `Jira` are used.\n\nSince I thought that learning Jira would present a learning curve for other team members, we communicated using Slack.\n\nOn GitHub, we created a team organization to separate the frontend and backend repositories, and used projects to **track issues by sprint for each repository.**\n\n![sprint](/public/posts/after-toy-project/sprint.png)\n\nIn our projects, we used `React`, and after much consideration to implement a **better architectural structure**, I found a [great article](https://github.com/alan2207/bulletproof-react) that served as a valuable reference.\n\nAdditionally, based on the `Airbnb` JavaScript style guide, we applied `eslint` and `prettier` rules to ensure **consistent code syntax among team members.**\n\n### Conclusion\n\nI always feel that while conducting projects, there are moments when I think, **I should have done this differently, or it would have been better to proceed in another way.**\n\nHowever, I also feel that as I progress through projects, I can approach the next one in a better way, and I am growing as a developer who wants to continue finding better methods.\n",
      "width": 2000,
      "height": 1968
    },
    "contribute-open-source": {
      "slug": "contribute-open-source",
      "date": "2024-02-16T00:00:00.000Z",
      "title": "Trying to Contribute to Open Source",
      "description": "This post describes my experience contributing to open source.",
      "tags": [
        "octokit",
        "github",
        "open source"
      ],
      "section": "blog",
      "series": "",
      "thumbnail": "/public/posts/contribute-open-source/editor.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRjIAAABXRUJQVlA4ICYAAACwAQCdASoQAAsABUB8JaQAAudZHPQAAP7vtSdX42+oO6VIEKQAAA==",
      "writer": "leey00nsu",
      "content": "\r\n## Trying to Contribute to Open Source\r\n\r\n### Committing with Octokit\r\n\r\nWhile creating a `blog service`, I needed to import files from GitHub and commit them to add CMS functionality.\r\n\r\nGitHub supports access to its REST API through a library called [Octokit](https://github.com/octokit/rest.js).\r\n\r\nImporting files was straightforward, but **a significant issue arose during the process of committing files.**\r\n\r\nIn the current implementation of the CMS functionality, users can write markdown documents through an editor.\r\n\r\n![editor](/public/posts/contribute-open-source/editor.png)\r\n\r\nWhen uploading images in the editor, the images are stored as `File` objects on the client side, and upon clicking upload, they are uploaded using Octokit.\r\n\r\nHowever, the function `octokit.rest.repos.createOrUpdateFile` for committing to the repository can only handle **one file per commit.**\r\n\r\nSince I did not want commits to occur for each image, I searched for a solution and discovered that commits could be made using a `tree` in the document.\r\n\r\n> 1. Get a reference to the end of the branch's tree.\r\n> 2. For each file to be committed, create a blob and store references to the sha identifier, path, and mode in an array.\r\n> 3. Create a new tree containing all the blobs, add it to the reference of the existing tree, and save a new sha pointer for this new tree.\r\n> 4. Create a commit pointing to this new tree and push it to the branch.\r\n\r\nThe process does not seem easy.\r\n\r\n### Solution through a Plugin\r\n\r\nFortunately, the [octokit-commit-multiple-files](https://github.com/mheap/octokit-commit-multiple-files) plugin allows adding a `createOrUpdateFiles` function to Octokit, enabling the storage of multiple files in a single commit.\r\n\r\nHowever, I found that **sometimes image uploads did not work correctly when using this library.**\r\n\r\nThis error only occurred when uploading images larger than `5MB`, and I discovered the following error log.\n\n```markdown title=\"Error log\"\nError creating commit: RangeError: Maximum call stack size exceeded\nat RegExp.test (<anonymous>)\nat isBase64 (webpack-internal:///(action-browser)/./node_modules/is-base64/is-base64.js:24:52)\nat createBlob (webpack-internal:///(action-browser)/./node_modules/octokit-commit-multiple-files/create-or-update-files.js:181:14)\nat eval (webpack-internal:///(action-browser)/./node_modules/octokit-commit-multiple-files/create-or-update-files.js:95:47)\nat Array.map (<anonymous>)\nat eval (webpack-internal:///(action-browser)/./node_modules/octokit-commit-multiple-files/create-or-update-files.js:87:45)\nat processTicksAndRejections (node:internal/process/task_queues:95:5)\nError creating commit: Maximum call stack size exceeded\n```\n\nThe octokit-commit-multiple-files library checks for base64 using an external library called `isBase64`.\n\nHowever, isBase64 is no longer maintained, with the last commit being 4 years ago, and many people have reported [this issue](https://github.com/miguelmota/is-base64/issues/10).\n\nTo resolve this, I cloned the library and replaced the base64 check with [this implemented function](https://github.com/webdriverio/webdriverio/issues/5208#issuecomment-613029075) to see if it would fix the error.\n\n```js title=\"isBase64\"\nfunction isBase64(str) {\n  var notBase64 = /[^A-Z0-9+\\/=]/i\n  const isString = typeof str === 'string' || str instanceof String\n\n  if (!isString) {\n    let invalidType\n    if (str === null) {\n      invalidType = 'null'\n    } else {\n      invalidType = typeof str\n      if (\n        invalidType === 'object' &&\n        str.constructor &&\n        str.constructor.hasOwnProperty('name')\n      ) {\n        invalidType = str.constructor.name\n      } else {\n        invalidType = `a ${invalidType}`\n      }\n    }\n    throw new TypeError(`Expected string but received ${invalidType}.`)\n  }\n\n  const len = str.length\n  if (!len || len % 4 !== 0 || notBase64.test(str)) {\n    return false\n  }\n  const firstPaddingChar = str.indexOf('=')\n  return (\n    firstPaddingChar === -1 ||\n    firstPaddingChar === len - 1 ||\n    (firstPaddingChar === len - 2 && str[len - 1] === '=')\n  )\n}\n```\n\nAfter this change, I confirmed that uploads were working correctly, and I wrote a `PR` to inform the library maintainer.\n\n![pr](/public/posts/contribute-open-source/pr.png)\n\nAbout two weeks later, I saw that it was merged with the following comment.\n\n![pr-accepted](/public/posts/contribute-open-source/pr-accepted.png)\r\n\r\n### Conclusion\r\n\r\nUnexpectedly, I had the opportunity to contribute to open source.\r\n\r\nWhile I did not discover a major issue or write code to solve a problem directly, **I learned a lot through the process of identifying a problem and suggesting a solution.**\r\n\r\n![contributors](/public/posts/contribute-open-source/contributors.png)\r\n\r\nAdditionally, being included as a contributor feels quite rewarding.",
      "width": 2496,
      "height": 1692
    },
    "customize-zustand-persist": {
      "slug": "customize-zustand-persist",
      "date": "2023-12-15T00:00:00.000Z",
      "title": "Customizing Zustand Persist",
      "description": "Let's customize Zustand persist to suit our needs.",
      "tags": [
        "zustand",
        "indexedDB"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": null,
      "draft": false,
      "writer": "leey00nsu",
      "content": "\n## Customizing Zustand Persist\n\nWhen using `zustand` for global state management, **there are times when you want to store that state in the browser's storage.**\n\nZustand provides `persist` through zustand/middleware for this purpose.\n\nThe Zustand [official documentation](https://docs.pmnd.rs/zustand/integrations/persisting-store-data) explains this in detail with examples.\n\n### Saving to Local or Session Storage\n\n```jsx title=\"useBearStore\"\nexport const useBearStore = create(\n  persist(\n    (set, get) => ({\n      bears: 0,\n      addABear: () => set({ bears: get().bears + 1 }),\n    }),\n    {\n      name: 'food-storage', // Name of the storage\n      storage: createJSONStorage(() => sessionStorage), // Storage to use\n      partialize: (state) => ({\n        canvasName: state.bears,\n      }),\n    },\n  ),\n)\n```\n\nAfter wrapping the created `store` with `persist`, you set which storage to use.\n\nBy default, `localStorage` is used, but it can be changed to `sessionStorage`.\n\nAt this point, you can use the `partialize` property to persist only the desired state.\n\n### Saving to Custom Storage\n\nBy default, local storage and session storage have size limitations.\n\n**If you want to store a larger amount of data, you can save it to `IndexedDB`, one of the browser storage options.**\n\nIn this case, you can implement it using the indexedDB library [idb-keyval](https://github.com/jakearchibald/idb-keyval).\n\n```jsx title=\"useBoundStore\"\nimport { get, set, del } from \"idb-keyval\";\n\nconst storage: StateStorage = {\n  getItem: async (name: string): Promise<string | null> => {\n    return (await get(name)) || null;\n  },\n  setItem: async (name: string, value: string): Promise<void> => {\n    await set(name, value);\n  },\n  removeItem: async (name: string): Promise<void> => {\n    await del(name);\n  },\n};\n\nexport const useBoundStore = create(\n  persist(\n    (set, get) => ({\n      bears: 0,\n      addABear: () => set({ bears: get().bears + 1 }),\n    }),\n    {\n      name: \"food-storage\",\n      storage: createJSONStorage(() => storage),\n    }\n  )\n);\n```\n\nThe usage is not significantly different; you declare the custom storage and then use it.\n\n### Adding Debounce to Persist\n\nIn the project \"Creating My Own Suya Guardian,\" we saved the history of the canvas.\n\nAt this time, every time the user interacts with the canvas, `persist`'s `set` is triggered, resulting in **too many requests.**\n\nTherefore, by adding `debounce`, you can save the state of the canvas after the interaction is finished, reducing the number of requests.\n\nThe debounce function used can be implemented directly or you can use utility libraries like lodash.\n\n```jsx title=\"storage debounce\"\n// Custom IndexedDB storage\nconst IDBstorage: StateStorage = {\n  getItem: async (name: string): Promise<string | null> => {\n    return (await get(name)) || null;\n  },\n  setItem: debounce(async (name: string, value: string): Promise<void> => {\n    await set(name, value);\n  }, 1000),\n  removeItem: async (name: string): Promise<void> => {\n    await del(name);\n  },\n};\n```",
      "width": 0,
      "height": 0
    },
    "dockerize-nest": {
      "slug": "dockerize-nest",
      "date": "2024-02-25T00:00:00.000Z",
      "title": "Dockerizing NestJS",
      "description": "This post explains how to deploy NestJS on Docker.",
      "tags": [
        "NestJS",
        "docker"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": null,
      "draft": false,
      "writer": "leey00nsu",
      "content": "\r\n## Dockerizing NestJS\r\n\r\nTo run an existing Nest project on `Docker`, you need to create a `Docker image`.\r\n\r\nFirst, you need to install Docker. On Linux-based systems, installing the [Docker Engine](https://docs.docker.com/engine/) includes Docker.\r\n\r\nIf you are on Windows or Mac, you can install `Docker Desktop` to easily manage Docker in a GUI environment.\r\n\r\nAfter installing Docker, navigate to the root folder of the project you want to dockerize and create the Docker configuration files.\r\n\r\n- `DockerFile`: Configuration file for the Docker image\r\n- `.dockerignore`: List of files to exclude from the image\r\n\r\nIn the .dockerignore file, exclude git-related files, environment variable files, node_modules, and the Dockerfile itself.\r\n\r\nI configured my Dockerfile as follows:\r\n\r\n```docker title=\"DockerFile\"\r\nFROM node:20-alpine\r\nRUN mkdir -p /var/app\r\nWORKDIR /var/app\r\nCOPY . .\r\nRUN npm install\r\nRUN npm run build\r\nEXPOSE 3000\r\nCMD [\"npm\",\"start\"]\r\n```\r\n\r\nTo briefly explain the process:\r\n\r\n1. Use the node-20-alpine (minimized version).\r\n2. Create a folder named /var/app and copy the contents of the current root folder into it.\r\n3. Then run npm install to install the specified dependencies and build the project.\r\n4. Set the port that the Docker container will use to 3000.\r\n5. Start the server.\r\n\r\nNow, let's build the Docker image.\r\n\r\n```bash title=\"Build Docker Image\"\r\ndocker build -t (image-name) .\r\n```\r\n\r\nOnce the build is complete, you can check the Docker images stored locally with the following command:\r\n\r\n```bash title=\"Check Docker Images\"\r\ndocker images\r\n```\r\n\r\nTo run this Docker image in a container, you can execute the following command.\r\n\r\n(Here, we connected port 3000 of the host to port 3000 of the container.)\r\n\r\n```bash title=\"Run Docker Container\"\r\ndocker run -p 3000:3000 (docker-image-ID)\r\n```\r\n\r\nThere are various [other commands](https://docs.docker.com/engine/reference/commandline/run/) available, so feel free to apply them as needed.",
      "width": 0,
      "height": 0
    },
    "explore-canvas": {
      "slug": "explore-canvas",
      "date": "2023-07-05T00:00:00.000Z",
      "title": "Working with Canvas in React",
      "description": "This post explains libraries for handling Canvas in React.",
      "tags": [
        "react",
        "canvas",
        "konva",
        "fabric"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/explore-canvas/konva-demo.png",
      "draft": true,
      "blurDataURL": "data:image/webp;base64,UklGRjQAAABXRUJQVlA4ICgAAAAwAQCdASoQAAsABUB8JaQAA3AA/vCXN1U+cup1H/5xpY1qxT0wAAAA",
      "writer": "leey00nsu",
      "content": "\n## Working with Canvas in React\n\n### Konva.js vs Fabric.js\n\nDuring this project, I needed features for drawing and erasing with a pen, as well as uploading image files and layering them.\n\nOf course, I could implement all the features directly using the canvas API, but I decided to use libraries since they allow for safer and more efficient program development.\n\nBoth konva and fabric meet the intended purpose, so it doesn't matter which one I choose. Therefore, I will briefly try both libraries and compare them.\n\n### Konva in React\n\nIn React, there is a library called [react-konva](https://github.com/konvajs/react-konva) that wraps `konva` for React.\n\nYou can implement it similarly to the konva documentation, but in a more React-like component style.\n\nIf you want to resize an object, you need to attach a separate transformer implementation to the object.\n\n![konva-demo](/public/posts/explore-canvas/konva-demo.png)\n\n```jsx title=\"konva\"\nimport { Layer, Rect, Stage } from 'react-konva'\n\nconst SomeRect = () => {\n  return <Rect x={20} y={20} width={50} height={50} fill=\"black\" />\n}\n\nconst App = () => {\n  return (\n    <Stage width={window.innerWidth} height={window.innerHeight}>\n      <Layer>\n        <SomeRect />\n      </Layer>\n    </Stage>\n  )\n}\n\nexport default App\n```\n\n### Fabric in React\n\nThere is a library that wraps `fabric` for React, but currently, it has errors in the TypeScript environment.\n\nSo, I will directly call and use fabric js.\n\nAdditionally, it has built-in transformers and select boxes for manipulating objects. (In konva, you need to implement this separately.)\n\nThe [official documentation](http://fabricjs.com/) is detailed, so you can implement it without much difficulty.\n\n![fabric-demo](/public/posts/explore-canvas/fabric-demo.png)\n\n```jsx title=\"fabric\"\nimport { fabric } from 'fabric'\nimport { useEffect, useState } from 'react'\n\nconst App = () => {\n  const [canvas, setCanvas] = (useState < fabric.Canvas) | (null > null)\n\n  const initCanvas = () =>\n    new fabric.Canvas('canvas', {\n      height: 800,\n      width: 800,\n      backgroundColor: 'gray',\n    })\n\n  useEffect(() => {\n    const newCanvas = initCanvas()\n    setCanvas(newCanvas)\n\n    return () => {\n      newCanvas.dispose() // Clears the canvas when unmounted.\n    }\n  }, [])\n\n  const addRect = () => {\n    if (canvas) {\n      const rect = new fabric.Rect({\n        width: 200,\n        height: 200,\n        fill: 'yellow',\n      })\n\n      canvas.add(rect)\n      canvas.renderAll()\n    }\n  }\n\n  return (\n    <div>\n      <button onClick={addRect}>Add Rect</button>\n      <canvas id=\"canvas\" />\n    </div>\n  )\n}\n\nexport default App\n```\n\n### Conclusion\n\nI implemented both methods, and both libraries have similar functionalities based on the `Canvas API`.\n\nHowever, one of the advantages of `fabric` is that it allows you to implement `selectbox` and `transformer` **with minimal effort.**\n\nCurrently, the project uses konva, but if I were to implement the same functionality again, I would consider using fabric.",
      "width": 1120,
      "height": 754
    },
    "external-next-image": {
      "slug": "external-next-image",
      "date": "2024-01-23T00:00:00.000Z",
      "title": "Applying next/image to External Images",
      "description": "This post explains the process of applying next/image to external images using plaiceholder.",
      "tags": [
        "Next.js",
        "plaiceholder"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/external-next-image/result.webp",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRj4AAABXRUJQVlA4IDIAAACwAQCdASoNABAABUB8JZwAAudZ1UmAAP7vsurenlhEAtO3ekeE6UhL4d1UYOacMZQoAA==",
      "writer": "leey00nsu",
      "content": "\n## Applying next/image to External Images\n\n### next/image\n\nIn `Next.js`, you may see a warning suggesting the use of the `next/image` component instead of the `img` tag for image optimization.\n\nUsing next/image provides the following advantages:\n\n- Serving images in **smaller formats** like `webp`\n- Serving appropriate images for **different devices** using `srcset`\n- Providing a **placeholder** to prevent CLS (Cumulative Layout Shift)\n\nIn this post, we will focus on the placeholder feature.\n\nWith next/image, you can see that it automatically extracts metadata such as `width` and `height` for images and also generates a `blurDataUrl`.\n\n```jsx title=\"next/image\"\nimport Image from 'next/image'\n\nimport profilePic from './me.png'\n\nexport default function Page() {\n  return (\n    <Image\n      src={profilePic}\n      alt=\"Picture of the author\"\n      // width={500} automatically provided\n      // height={500} automatically provided\n      // blurDataURL=\"data:...\" automatically provided\n      // placeholder=\"blur\" // Optional blur-up while loading\n    />\n  )\n}\n```\n\nHowever, according to the [official documentation](https://nextjs.org/docs/app/building-your-application/optimizing/images), metadata is generated at build time based on **statically imported image files**, so you need to manually provide metadata for `external images`.\n\nTherefore, let's explore how to handle metadata for external images.\n\n### Plaiceholder\n\n> \"Plaiceholder\" is a suite of **server-side** functions for creating low-quality image placeholders (LQIP).\n\n[plaiceholder](https://plaiceholder.co/docs) is a library designed to **generate low-quality placeholder images on the server side**.\n\nIt supports solid colors, CSS, SVG, and Base64.\n\nTo install the library, you need to install the image processing library `sharp`.\n\n```jsx title=\"Installing sharp\"\nnpm install sharp\nnpm install plaiceholder\n```\n\nTo use plaiceholder for external images, you can fetch the image URL and convert it to a `buffer` to pass it along.\n\nIn JavaScript, you can create an `arrayBuffer` and then convert it to a buffer for passing.\n\nYou can also pass various properties such as the size of the `lqip` image to the function.\n\n```jsx title=\"getMetadata.ts\"\nimport { getPlaiceholder } from 'plaiceholder';\n\nexport default async function getMetadata(imageUrl: string) {\n  const res = await fetch(imageUrl);\n\n  const buffer = await res.arrayBuffer();\n\n  const { base64, metadata } = await getPlaiceholder(Buffer.from(buffer), {\n    size: 8,\n  });\n\n  return { base64, metadata };\n}\n```\n\nnext/image receives the `base64` as `blurDataUrl`, so let's look at the return value for base64.\n\nplaiceholder returns the base64 and metadata as follows:\n\n```jsx title=\"plaiceholder return value\"\nbase64: string;\nmetadata: {\n    orientation?: number;\n    format?: keyof sharp.FormatEnum;\n    size?: number;\n    space?: keyof sharp.ColourspaceEnum;\n    channels?: sharp.Channels;\n    depth?: string;\n    density?: number;\n    chromaSubsampling: string;\n    isProgressive?: boolean;\n    pages?: number;\n    pageHeight?: number;\n    loop?: number;\n    delay?: number[];\n    pagePrimary?: number;\n    hasProfile?: boolean;\n    hasAlpha?: boolean;\n    exif?: Buffer;\n    icc?: Buffer;\n    iptc?: Buffer;\n    xmp?: Buffer;\n    tifftagPhotoshop?: Buffer;\n    compression?: \"av1\" | \"hevc\";\n    background?: number | {\n        r: number;\n        g: number;\n        b: number;\n    };\n    levels?: sharp.LevelMetadata[];\n    subifds?: number;\n    resolutionUnit?: \"inch\" | \"cm\";\n    formatMagick?: string;\n    width: number;\n    height: number;\n};\n```\n\nAdditionally, to apply the `optimized` option when serving external images, you need to register the image domain in `remotePatterns`.\n\n```jsx title=\"next.config.js\"\nmodule.exports = {\n  images: {\n    remotePatterns: [\n      {\n        protocol: 'https',\n        hostname: 'example.com',\n        port: '',\n        pathname: '/account123/**',\n      },\n    ],\n  },\n}\n```\n\nNow you can call this function and pass it to the Image component.\n\n```jsx title=\"GithubChart.tsx\"\nconst GithubChart = async () => {\n  const url =\n    'https://cdn.pixabay.com/photo/2023/07/22/04/15/motorbike-8142649_1280.jpg'\n  const { base64, metadata } = await getMetadata(url)\n\n  return (\n    <Image\n      alt=\"motorcycle\"\n      width={metadata.width}\n      height={metadata.height}\n      src={url}\n      blurDataURL={base64}\n      placeholder=\"blur\"\n    />\n  )\n}\n```\n\n### Results\n\n![result.webp](/public/posts/external-next-image/result.webp)\n\nThe results for plaiceholder X and plaiceholder O are shown in order.\n\nI tested the results in a `Fast 3G` environment.\n\nAs you can see, the side without the placeholder does not show the image until it is fully loaded, causing a `Layout Shift`.\n\nTherefore, to effectively use next/image, you might consider using this library.\n\nAlso, when applying the `optimized` option, it showed a **size difference of more than double**.\n\n![diff](/public/posts/external-next-image/diff.png)\n\n### Use Case\n\nIn my [blog](https://blog.leey00nsu.com/), I use this library to initially show a blurred image and then transition smoothly.\n\n![demo](/public/posts/external-next-image/demo.gif)",
      "width": 600,
      "height": 768
    },
    "framer-motion-page-transition": {
      "slug": "framer-motion-page-transition",
      "date": "2023-09-11T00:00:00.000Z",
      "title": "Implementing Page Transitions with framer-motion",
      "description": "This post explains how to implement page transitions using framer-motion.",
      "tags": [
        "react",
        "framer-motion",
        "AnimatePresence"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/framer-motion-page-transition/result.gif",
      "draft": true,
      "blurDataURL": "data:image/webp;base64,UklGRioAAABXRUJQVlA4IB4AAACQAQCdASoMABAABUB8JaQAAp1HI1AA9WZ88xAAAAA=",
      "writer": "leey00nsu",
      "content": "\n## Implementing Page Transitions with framer-motion\n\nWhen implementing `animations` in a `react`-based project, we use `framer-motion`. Based on this, we aim to implement page transitions that show different pages each time we navigate.\n\n### What is framer-motion?\n\n[framer-motion](https://www.framer.com/motion/) introduces itself as follows:\n\n> Complete documentation of the Framer Motion animation library. A production-ready motion library for React.\n\nIt is a **motion library** provided by `framer` for React.\n\nThe library can be installed as follows:\n\n```shell title=\"framer-motion\"\nnpm install framer-motion\n```\n\n### How it Works\n\nBasically, React components are wrapped in a component called `motion`, so we import and use it.\n\nYou can assign starting style values to the `initial` property.\n\nYou can assign target style values to the `animate` option, and `framer-motion` will automatically animate to these values.\n\n```jsx title=\"motion.div\"\n<motion.div initial={{ opacity: 0 }} animate={{ opacity: 1 }} />\n```\n\nFor example, this component starts with `initial` as `opacity: 0`, so it begins in a transparent state and becomes visible due to `opacity: 1` in `animate`.\n\nAdditionally, you can specify delays or animation types (Tween, Spring, etc.) in the `transition` property, allowing you to **customize the animation as desired.**\n\n### AnimatePresence and exit\n\n`framer-motion` offers various options, and the [official documentation](https://www.framer.com/motion/) provides detailed examples.\n\nThe parts needed for this article are the `initial`, `animate`, and `exit` options described above.\n\nThe `exit` option is mainly used with `AnimatePresence`.\n\n`AnimatePresence` **delays the unmounting of components in the React DOM tree until the exit animation is complete.**\n\nThe official documentation provides the following example.\n\n```jsx title=\"AnimatePresence\"\nimport { AnimatePresence, motion } from 'framer-motion'\n\nexport const MyComponent = ({ isVisible }) => (\n  <AnimatePresence>\n    {isVisible && (\n      <motion.div\n        initial={{ opacity: 0 }}\n        animate={{ opacity: 1 }}\n        exit={{ opacity: 0 }}\n      />\n    )}\n  </AnimatePresence>\n)\n```\n\n### react-router and framer-motion\n\nSince React is a `SPA`, we primarily use `react-router` for the **routing system**.\n\nThe goal of this article is also to **show page transitions each time we navigate to a different page.**\n\nI will skip the setup of react-router and explain the additional configurations.\n\n```jsx title=\"routes.tsx\"\nconst location = useLocation();\nconst { pageHistory } = useTransitionStore();\n\n...\n<AnimatePresence>\n\t<Routes location={location} key={pageHistory + location.pathname}>\n    <Route path=\"/\" element={<MainPage />} />\n    <Route path=\"/a\" element={<Page1 />} />\n    <Route path=\"/b\" element={<Page2 />} />\n\t  <Route path=\"/c\" element={<Page3 />} />\n\t  <Route path=\"/d\" element={<Page4 />} />\n\t</Routes>\n</AnimatePresence>\n```\n\nThe `motion component` must exist directly below `AnimatePresence`, so we wrapped `Routes` with `AnimatePresence` as shown in the code above.\n\nWe also pass `pageHistory + location.pathname` as the key for Routes.\n\n**The motion component requires a `key` to distinguish the object that will execute the animation.**\n\nIf this key does not change, the animation will not run again.\n\nBy using the key to distinguish the animated object, if we do not include the previous path, when going from a to b to a, a will appear twice, causing **animations to overlap.**\n\nThus, we assign **the current location + all paths as the key**.\n\n<br />\n\nNow, let's set up the page components.\n\nThe page components are wrapped in a component called Layout.\n\n```jsx title=\"Layout\"\ninterface LayoutProps {\n  children: React.ReactNode;\n}\n\nconst Layout = (props: LayoutProps) => {\n  const { currentDirection } = useTransitionStore();\n\n  let initialX = 0;\n  if (currentDirection === \"left\") initialX = 500;\n  if (currentDirection === \"right\") initialX = -500;\n\n  const exitX = currentDirection === \"left\" ? -500 : 500;\n\n  return (\n    <motion.div\n      initial={{ x: initialX }}\n      animate={{ x: 0 }}\n      exit={{ x: exitX }}\n      transition={{ duration: 0.5 }}\n      className=\"layout\"\n    >\n      {props.children}\n    </motion.div>\n  );\n};\n```\n\n`currentDirection` holds the direction in which the current slide is moving.\n\nIf the back button is pressed, it is set to `left`, moving from right to left.\n\nIf another page is clicked, it is set to `right`, moving from left to right.\n\nThe current page width is set to 500px, hence the value of 500.\n\n![structure](/public/posts/framer-motion-page-transition/structure.png)\n\nThe code will animate in the order shown in the image due to `framer-motion`.\n\n(Note: To use x for transitions, the layout's CSS must have position:absolute.)\n\nThe final result is as follows.\n\n![result](/public/posts/framer-motion-page-transition/result.gif)\n\n### Conclusion\n\nFrom simple animations to complex ones, `framer-motion` allows for relatively easy creation, making it a frequent choice for me.\n\nThis time, I implemented page transitions, and while integrating with `react-router` was complex, the animation itself was simple and easily accessible.\n\n**I believe that adding transitions when displaying in mobile view can give an app-like feel, making it a technique worth considering.**",
      "width": 600,
      "height": 772
    },
    "migration-supabase": {
      "slug": "migration-supabase",
      "date": "2024-09-18T00:00:00.000Z",
      "title": "Migrating Supabase",
      "description": "Let's migrate data from Supabase Cloud to self-hosting.",
      "tags": [
        "supabase"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/migration-supabase/supabase.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRi4AAABXRUJQVlA4ICIAAACQAQCdASoQAAoABUB8JZwAAuP9bYAA/u9MdlrdmpDMAAAA",
      "writer": "leey00nsu",
      "content": "\r\n# Migrating Supabase\r\n\r\n## Supabase\r\n\r\n![supabase](/public/posts/migration-supabase/supabase.png)\r\n\r\n`Supabase` is an open-source backend service that helps developers easily build a complete backend. It is essentially a `BaaS` (Backend as a Service). Supabase is based on a `PostgreSQL` database and provides features such as real-time databases, authentication, storage, and automatic generation of RESTful APIs.\r\n\r\nThe main features are as follows:\r\n\r\n1. **Database**: A scalable relational database based on PostgreSQL.\r\n2. **Real-time Features**: The ability to synchronize and update data in real-time from the database.\r\n3. **Authentication**: A user authentication and authorization management system (can integrate with external login services like GitHub, Google, Facebook, etc.).\r\n4. **Storage**: The ability to store and manage files such as images and videos.\r\n5. **Automatically Generated APIs**: Automatically generates RESTful APIs and GraphQL based on the PostgreSQL schema.\r\n\r\nSupabase offers similar functionalities to Firebase and is widely used by developers who need integration with PostgreSQL.\r\n\r\n## Why Self-Hosting?\r\n\r\nCurrently, we are using Supabase when we need simple CRUD functionalities without requiring a full-fledged backend application.\r\n\r\nWe also utilized Supabase for handling blog view counts. While it is great for quickly setting up a backend, there are **a few drawbacks.**\r\n\r\n1. **Only two projects are free.**\r\n2. **If the dashboard is not visited for a week (not managed), the project will be paused.**\r\n\r\nIt is challenging to manage all projects weekly, and if forgotten, the project gets paused, requiring reactivation, which can be cumbersome.\r\n\r\nThus, we decided to self-host using Docker.\r\n\r\n## Self-Hosting\r\n\r\nThe [official documentation](https://supabase.com/docs/guides/self-hosting/docker) explains how to self-host using Docker.\r\n\r\nThis post will not cover the process in detail. (It is a simple process of modifying the env through a `docker-compose` file and running it.)\r\n\r\n## Migrating PostgreSQL\r\n\r\n### Backing Up with pg_dump\r\n\r\nOnce the basic self-hosted Supabase is set up, it's time to replace the contents.\r\n\r\nSince Supabase uses `PostgreSQL` internally, we can proceed with the migration using `pg_dump` and `psql`.\r\n\r\n![table-old](/public/posts/migration-supabase/table-old.png)\r\n\r\nThe current blog view count table looks like this.\r\n\r\nTo back up this data from the existing Supabase database, we will use pg_dump. The PostgreSQL information used here can be found in Supabase's project settings > database.\r\n\r\n```bash title=\"pg_dump\"\r\nsudo apt-get install postgresql-15\r\npg_dump postgresql://[YOUR_USER]:[YOUR-PASSWORD]@[YOUR_HOST]:[YOUR_PORT]/postgres > database-dump.sql\r\n```\r\n\r\nIf everything goes smoothly, you can proceed to the next step. However, **if you cannot install PostgreSQL 15 due to Ubuntu version 20.04**, you can follow these steps to install it and then proceed.\r\n\r\n1. Add the PostgreSQL official repository\r\n   The latest version of PostgreSQL is not included in Ubuntu's default repository, so you need to add the PostgreSQL official repository.\r\n\r\n```bash title=\"Add PostgreSQL Official Repository Command\"\r\nsudo sh -c 'echo \"deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main\" > /etc/apt/sources.list.d/pgdg.list'\r\n```\r\n\r\n2. Add the GPG key for the PostgreSQL repository\r\n   Add the GPG key to verify the integrity of the PostgreSQL packages.\r\n\r\n```bash title=\"Add GPG Key for PostgreSQL Repository\"\r\nwget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -\r\n```\r\n\r\n3. Update the package list\r\n   After adding the PostgreSQL official repository, update the package list.\r\n\r\n```bash title=\"Update Package List\"\r\nsudo apt-get update\r\n```\r\n\r\n4. Install PostgreSQL 15\r\n   Now you can install PostgreSQL 15.\r\n\r\n```bash title=\"Install PostgreSQL 15\"\r\nsudo apt-get install postgresql-15\r\n```\r\n\r\n### Applying Backup with psql\r\n\r\nIf the backup data has been successfully created, a file named `database-dump.sql` should have been generated.\r\n\r\nTo apply this backup, you need to **run psql inside the Docker container of the self-hosted PostgreSQL.**\r\n\r\nUse a command like `docker ps` to find the ID of the container, then transfer the backup file to the Docker container.\r\n\r\n```bash title=\"Transfer File to Docker Container\"\r\ndocker cp /path/to/database-dump.sql [CONTAINER_ID]:/path/in/container/\r\n```\r\n\r\nNext, access the container.\r\n\r\n```bash title=\"Access Docker Container\"\r\ndocker exec -it [CONTAINER_ID] bash\r\n```\r\n\r\nNow, execute the psql command at the location of the transferred backup file.\r\n\r\n```bash title=\"psql\"\r\npsql -U [YOUR_USER] -d postgres -f database-dump.sql\r\n```\r\n\r\nIf everything was processed correctly, you can check the self-hosted Supabase GUI to see that it has been applied successfully.\r\n\r\n![table-new](/public/posts/migration-supabase/table-new.png)\r\n\r\n## Conclusion\r\n\r\nDue to the two drawbacks mentioned earlier, we opted for self-hosting, but self-hosting also has the **disadvantage of not being able to manage multiple projects** (there is no organization).\r\n\r\nIf you only need to use a database, it might be better to host just PostgreSQL and use an ORM like Prisma.\r\n\r\nHowever, the other powerful features and the built-in GUI provided by Supabase are still available in self-hosting, so I believe I will continue to use it for convenience.\r\n\r\n## References\r\n\r\n[https://supabase.com/docs/guides/self-hosting/docker](https://supabase.com/docs/guides/self-hosting/docker)\r\n\r\n[https://ironeko.com/posts/creating-a-local-backup-of-a-supabase-database](https://ironeko.com/posts/creating-a-local-backup-of-a-supabase-database)\r\n\r\n[https://medium.com/devops-technical-notes-and-manuals/how-to-install-and-configure-postgresql-on-ubuntu-20-04-4fd3cf072d6f](https://medium.com/devops-technical-notes-and-manuals/how-to-install-and-configure-postgresql-on-ubuntu-20-04-4fd3cf072d6f)",
      "width": 2090,
      "height": 1250
    },
    "mock-with-msw": {
      "slug": "mock-with-msw",
      "date": "2023-08-18T00:00:00.000Z",
      "title": "Mocking APIs with MSW",
      "description": "Let's learn how to mock APIs using the MSW library.",
      "tags": [
        "react",
        "msw",
        "api"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/mock-with-msw/scrum.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRjYAAABXRUJQVlA4ICoAAACwAQCdASoQAAYABUB8JQBOgCPtvsfwAP7hWXoOM//OQNttKEv+y4cAAAA=",
      "writer": "leey00nsu",
      "content": "\n## Mocking with MSW\n\nAs we progress through a project, we typically hold meetings before starting development to discuss **what features to implement and**\n\n**the data that corresponds to those features.**\n\n![scrum](/public/posts/mock-with-msw/scrum.png)\n\nAs a result, an API specification document is created that outlines how to access each piece of data, and frontend developers will make requests to the server according to these rules.\n\n### Why Mock?\n\nIn an ideal environment where frontend and backend can develop in sync, there would be no issues developing with real data.\n\nHowever, **I have realized through various projects that this is not an easy condition during the development phase.**\n\nFrom the perspective of a frontend developer, there are inevitably parts where one has to wait when the backend is not implemented.\n\nTherefore, to complete the project on time, it would be more efficient to use and test the `APIs that do not exist yet but will be created`.\n\n### Introducing the MSW Library\n\n[`msw`](https://mswjs.io/) is a library that can solve these issues, introducing itself as follows:\n\n> Mock by intercepting requests on the network level. Seamlessly reuse the same mock definition for testing, development, and debugging.\n>\n> Mock Service Worker is an API mocking library that uses Service Worker API to intercept actual requests.\n\nAccording to the description, it has the ability to **mock by intercepting requests at the network level using the `Service Worker API`.**\n\n![msw-structure](/public/posts/mock-with-msw/msw-structure.png)\n\n### Using MSW in a Real Project\n\nTo use `msw`, you need to create a service worker, and the related files are usually placed under a mocks folder.\n\n```jsx title=\"mocks/worker.js\"\nimport { setupWorker } from 'msw'\n\nimport { handlers } from './handler'\n\nexport const worker = setupWorker(...handlers)\n```\n\nTo run this service worker at the top level of the application, you need to include it in the top-level entry component.\n\n(In my case, it's main.jsx.)\n\n```jsx title=\"src/main.jsx\"\nimport { worker } from './mocks/worker'\n\n// Start the MSW Mock server.\nif (process.env.NODE_ENV === 'development') {\n  worker.start()\n}\n```\n\nNow, let's look at an example using the code applied in a real project.\n\nWe need to create dummy data called `dummyKoPosts` and write a handler that will respond when this data is requested.\n\n```jsx title=\"Dummy Data\"\n// Dummy user data\nexport const dummyKoUser1: User = {\n  id: 1,\n  nickname: 'Elon Musk',\n  language: 'ko',\n  avatar:\n    'https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Elon_Musk_Royal_Society_%28crop2%29.jpg/225px-Elon_Musk_Royal_Society_%28crop2%29.jpg',\n  followers: 100,\n};\n\n// Dummy post data\nexport const dummyKoPosts: Post[] = [\n  {\n    id: 1,\n    author: dummyKoUser1,\n    title: 'The Love Journey of Mr. Kuppe',\n    content:\n      'How bland life would be without love? Love excites us and brings us joy. When we love, life becomes an adventure, and every encounter becomes a thrilling moment. Of course, it’s not always like that. But I believe that love protects us from the greatest misfortune of modern life, which is boredom. In our country, we live in a way that is overly protected. For us, love is the last remaining adventure. Long live love, which keeps us young.',\n    summary: 'A positive perspective believing in the adventures and thrilling moments brought by love',\n    photos: [],\n    views: 50,\n    likes: 50,\n    comments: [\n      {\n        id: 1,\n        author: dummyKoUser2,\n        content: 'I enjoyed reading this!',\n        created_at: '2023-08-07',\n      },\n      {\n        id: 2,\n        author: dummyKoUser3,\n        content: 'This resonates with me!',\n        created_at: '2023-08-07',\n      },\n    ],\n    created_at: '2023-08-07',\n    category: 'book',\n  },\n  ...\n];\n```\n\n```jsx title=\"mocks/handler.js\"\nexport const handlers = [\n  rest.get(`/ko_post`, (req, res, ctx) => {\n    return res(ctx.status(200), ctx.json(dummyKoPosts))\n  }),\n]\n```\n\nNow, when you make a request to /ko_post using functions like `fetch` or `axios`, it will return **dummyKoPosts with a 200 code, exactly as bound in the handler.**\n\n```jsx title=\"getKoPostPage\"\n// Fetches the dummy post page.\nexport const getKoPostPage = async () => {\n  const response = await axios.get('/ko_post')\n  return response.data\n}\n```\n\nWhen this call result is displayed on the actual project screen, it looks like this.\n\n![result](/public/posts/mock-with-msw/result.png)\n\n### Conclusion\n\nI discovered the mocking library `msw` while simply using dummy data, and I am finding it useful in the early stages of the project.\n\nAdditionally, it has the advantage of easily handling `edge cases` by directly manipulating network response statuses.\n\nIt would also be beneficial to study how to use the mocking code already created with testing tools like `Jest` or `Storybook`.",
      "width": 2000,
      "height": 698
    },
    "nextjs-github-action-ci-cd": {
      "slug": "nextjs-github-action-ci-cd",
      "date": "2024-05-09T00:00:00.000Z",
      "title": "Implementing Next.js CI/CD with Docker using GitHub Actions",
      "description": "This post explains how to implement Next.js CI/CD using Docker with GitHub Actions.",
      "tags": [
        "docker",
        "github",
        "ci/cd",
        "Next.js"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/nextjs-github-action-ci-cd/oracle_cloud.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRjQAAABXRUJQVlA4ICgAAACwAQCdASoQABAABUB8JZwAAu06tbKAAP7x3xYuDpvoCbISu16AAAAA",
      "writer": "leey00nsu",
      "content": "\r\n## Implementing Next.js CI/CD with Docker using GitHub Actions\r\n\r\nAfter setting up a project using `Next.js`, it's time to move on to the deployment stage.\r\n\r\nWhile there is an easy way to deploy using Vercel, I decided to take this opportunity to challenge myself with CI/CD using the `Oracle Cloud` that I had previously set up.\r\n\r\n### What is CI/CD?\r\n\r\nTo briefly understand CI/CD, [Redhat](https://www.redhat.com/ko/topics/devops/what-is-ci-cd) describes it as follows:\r\n\r\n> CI/CD stands for Continuous Integration and Continuous Delivery/Deployment, aiming to simplify and accelerate the software development lifecycle.\r\n\r\nAccording to this description, a series of processes can be referred to as CI/CD:\r\n\r\n- **Continuous Integration (CI)**: This refers to the practice of frequently integrating code into a central repository by developers working simultaneously to prevent code conflicts or errors. It involves automatically building and testing new code periodically. If issues are found, notifications are sent to the team to resolve them.\r\n- **Continuous Deployment/Delivery (CD)**: Continuous deployment refers to automatically deploying new code changes to the production environment.\r\n\r\nHere, I will proceed with the process of **accessing the cloud and reflecting the code, building, and deploying whenever a new commit is registered in the repository**.\r\n\r\n### Building Next.js with Docker\r\n\r\nWhen deploying Next.js, the [official documentation](https://nextjs.org/docs/app/building-your-application/deploying#docker-image) provides the necessary configurations.\r\n\r\nI referred to this file to create `.dockerignore` and `Dockerfile`.\r\n\r\n**Note that to reduce the image size when building with Docker, you need to change the existing Next.js output setting to `standalone`.**\r\n\r\n```js title=\"next.config.mjs\"\r\n/** @type {import('next').NextConfig} */\r\nmodule.exports = {\r\n  output: 'standalone',\r\n}\r\n```\r\n\r\nAdditionally, the structure of the Oracle Cloud that I am currently operating is as follows:\r\n\r\n![oracle_cloud](/public/posts/nextjs-github-action-ci-cd/oracle_cloud.png)\r\n\r\nI am running Nginx in Docker, and since I am operating another project, I needed to connect the new Next.js project to the existing Nginx.\r\n\r\nTherefore, I created a `docker-compose` file to **connect it to Nginx through the same network configuration.**\r\n\r\n```yml title=\"docker-compose.yml\"\r\nservices:\r\n  noveloper:\r\n    container_name: noveloper\r\n    image: noveloper\r\n    ports:\r\n      - '4000:4000'\r\n    networks:\r\n      - nginx-network\r\n\r\nnetworks:\r\n  nginx-network:\r\n    external: true\r\n```\r\n\r\nNow, I need to add a workflow to detect commits through GitHub Actions and build with the new code.\r\n\r\n### Setting Up GitHub Actions\r\n\r\nLet's add a new workflow in the actions tab of the repository where we want to add GitHub Actions.\r\n\r\n```yml title=\"deploy.yml\"\r\nname: deploy\r\non:\r\n  push:\r\n    branches: ['main'] # This will run when a new commit is pushed to the main branch.\r\njobs:\r\n  deploy:\r\n    runs-on: ubuntu-latest\r\n    steps:\r\n      - uses: actions/checkout@v3.3.0\r\n\r\n      - name: execute remote ssh # Access the cloud instance via ssh.\r\n        uses: appleboy/ssh-action@master\r\n        with:\r\n          host: ${{ secrets.REMOTE_SSH_HOST }}\r\n          username: ${{ secrets.REMOTE_SSH_USERNAME }}\r\n          key: ${{ secrets.REMOTE_SSH_KEY }}\r\n          port: ${{ secrets.REMOTE_SSH_PORT }}\r\n          script: |\r\n            cd noveloper\r\n            git pull origin main\r\n            docker build -t noveloper .\r\n            docker compose down\r\n            docker compose up -d\r\n            docker rmi $(docker images -f \"dangling=true\" -q)\r\n```\r\n\r\nI configured it to access the cloud instance via ssh when a new commit is pushed to the main branch, and registered the necessary **host, username, key, and port** as environment variables to ensure successful ssh access.\r\n\r\nOnce connected, the script is set up to execute the following processes:\r\n\r\n1. `cd noveloper`: Navigate to the project folder\r\n2. `git pull origin main`: Pull the new commit\r\n3. `docker build -t noveloper .`: Build the Docker image for the project\r\n4. `docker compose up -d`: Run the Docker container based on the previously created docker-compose.yml\r\n5. `docker rmi $(docker images -f \"dangling=true\" -q)`: Remove old images\r\n\r\n### Result\r\n\r\nNow, whenever a new commit is registered, the actions we set up will be executed as follows.\r\n\r\n![actions_success](/public/posts/nextjs-github-action-ci-cd/actions_success.png)\r\n\r\nCurrently, my project takes about 3 minutes on average.\r\n\r\n### Conclusion\r\n\r\nI was able to easily deploy Next.js running in a Docker container by utilizing the pre-configured Nginx.\r\n\r\nAdditionally, I had relied on `vercel` for every project deployment, but by **using the cloud to deploy directly, I learned many new things.**\r\n\r\nThere may be incorrect parts in the process I configured, but I will continue to work on improving it in the future.",
      "width": 4136,
      "height": 4104
    },
    "nivo-chart": {
      "slug": "nivo-chart",
      "date": "2023-08-07T00:00:00.000Z",
      "title": "Visualizing Data with nivo Chart",
      "description": "This article explains how to visualize data using the nivo library.",
      "tags": [
        "react",
        "nivo",
        "chart",
        "graph",
        "artfolio"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/nivo-chart/result1.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRkYAAABXRUJQVlA4IDoAAADwAQCdASoQAAoABUB8JbAC7AEPApXr+gAA/u1kbeEZh9ajk3eGOSFXP8V2EtBgzubHSTfv721QAAAA",
      "writer": "leey00nsu",
      "content": "\n## Visualizing Data with nivo Chart\n\n![result1](/public/posts/nivo-chart/result1.png)\n![result2](/public/posts/nivo-chart/result2.png)\n\nWhile working on the `artfolio` project, I needed to implement a graph to display `real-time auction prices` and `tags` as shown above.\n\nI chose `nivo` because it is a **well-documented library that allows for extensive customization**.\n\n### What is nivo?\n\nThe [nivo documentation](https://nivo.rocks/) introduces the library as follows:\n\n> [nivo](https://github.com/plouc/nivo) provides supercharged React components to easily build dataviz apps, it's built on top of d3.\n>\n> Several libraries already exist for React d3 integration, but just a few provide server side rendering ability and fully declarative charts.\n\nAccording to the description, nivo is a React library that makes it easy to use the data visualization library `D3`.\n\n### Creating a Line Chart\n\nSince the real-time auction prices need to be drawn as a `line chart`, let's take a look at the Line section of nivo.\n\n![nivo-document](/public/posts/nivo-chart/nivo-document.png)\n\nOn the left, you can customize in real-time, while on the right, you can see the chart and the code.\n\nTo draw a line chart, you need the `ResponsiveLine` component, so you should install `@nivo/line`.\n\nAfter that, inserting the provided code will render an `svg` like the following.\n\n![line-example](/public/posts/nivo-chart/line-example.png)\n\nBy default, the chart is automatically drawn based on the dataset assigned to `data`.\n\nHowever, since the real-time auction price chart will display time on the x-axis and price on the y-axis, we need to change the data.\n\nCurrently, the dummy data is structured as follows:\n\n```jsx title=\"chartData\"\nconst chartData = [\n  {\n    id: 'japan',\n    color: 'hsl(148, 70%, 50%)',\n    data: [\n      {\n        x: 'plane',\n        y: 248,\n      },\n      {\n        x: 'helicopter',\n        y: 293,\n      },\n      {\n        x: 'boat',\n        y: 151,\n      },\n      {\n        x: 'train',\n        y: 55,\n      },\n      {\n        x: 'subway',\n        y: 282,\n      },\n      {\n        x: 'bus',\n        y: 90,\n      },\n      {\n        x: 'car',\n        y: 225,\n      },\n      {\n        x: 'moto',\n        y: 85,\n      },\n      {\n        x: 'bicycle',\n        y: 68,\n      },\n      {\n        x: 'horse',\n        y: 153,\n      },\n      {\n        x: 'skateboard',\n        y: 240,\n      },\n      {\n        x: 'others',\n        y: 298,\n      },\n    ],\n  },\n]\n```\n\nThe data will be changed to assign time to the x-axis as follows:\n\n```jsx title=\"chartData\"\nconst chartData = [\n  {\n    id: 'price',\n    color: 'hsl(148, 70%, 50%)',\n    data: [\n      {\n        x: new Date('2023-08-04 13:00'),\n        y: 1000,\n      },\n      {\n        x: new Date('2023-08-05 13:00'),\n        y: 1100,\n      },\n      {\n        x: new Date('2023-08-06 13:00'),\n        y: 1500,\n      },\n      {\n        x: new Date('2023-08-07 13:00'),\n        y: 2000,\n      },\n    ],\n  },\n]\n```\n\nNow we need to modify the `xScale` and `axisBottom` that handle the axes.\n\nWhen using time as data, there is a way to specify the type as time in `xScale`, but **in this case, it is difficult to accurately determine the data points because the midpoints are calculated automatically**.\n\nTherefore, I chose to specify it as point and use the format in axisBottom to format the time nicely using `intl`.\n\nAdditionally, the chart gradient color overflows beyond the x-axis, so **at this time**, you need to set the value of `areaBaselineValue` to the minimum value of the data y to prevent it from overflowing.\n\nThe final image and code are as follows.\n\n![line-example2](/public/posts/nivo-chart/line-example2.png)\n\n```jsx title=\"LineChart\"\nconst LineChart = () => {\n  return (\n    <ResponsiveLine\n      data={chartData}\n      margin={{ top: 50, right: 60, bottom: 50, left: 60 }}\n      xScale={{ type: 'point' }}\n      yScale={{\n        type: 'linear',\n        min: 'auto',\n        max: 'auto',\n        stacked: true,\n        reverse: false,\n      }}\n      axisTop={null}\n      axisRight={null}\n      axisBottom={{\n        format: (tick) =>\n          new Intl.DateTimeFormat('en', {\n            dateStyle: 'short',\n            timeStyle: 'short',\n          }).format(tick),\n        tickSize: 5,\n        tickPadding: 5,\n        tickRotation: 0,\n      }}\n      axisLeft={{\n        tickSize: 5,\n        tickPadding: 5,\n        tickRotation: 0,\n      }}\n      enableGridY={false}\n      pointSize={10}\n      pointColor={{ theme: 'background' }}\n      pointBorderWidth={2}\n      pointBorderColor={{ from: 'serieColor' }}\n      pointLabelYOffset={-12}\n      enableArea={true}\n      areaBaselineValue={chartData[0].data[0].y}\n      isInteractive={false}\n      useMesh={true}\n    />\n  )\n}\n```\n\n### Creating a Pie Chart\n\nNow let's create a `pie chart` to display the tags in the image.\n\nSimilar to the line chart, to draw a pie chart, you need the `ResponsivePie` component, so install `@nivo/pie`.\n\nAfter that, inserting the provided code will render a pie chart like the following.\n\n![pie-example](/public/posts/nivo-chart/pie-example.png)\n\nBy default, the chart is automatically drawn based on the dataset assigned to `data`.\n\nIt is similar to the tag chart I will implement, but the `value` and `label` should be displayed in reverse, with numbers coming out.\n\nThe text inside the pie corresponds to `arcLabel`, where you assign the `id`.\n\nThe text outside the pie corresponds to `arcLinkLabel`, where you assign the `value`.\n\nSince I want to display the value with a %, I will format it as `${d.value}%`.\n\nThe final image and code are as follows.\n\n![pie-example2](/public/posts/nivo-chart/pie-example2.png)\n\n```jsx title=\"PieChart\"\nconst PieChart = () => {\n  return (\n    <ResponsivePie\n      data={chartData}\n      margin={{ top: 40, right: 80, bottom: 80, left: 80 }}\n      innerRadius={0.5}\n      padAngle={0.7}\n      cornerRadius={3}\n      activeOuterRadiusOffset={8}\n      borderWidth={1}\n      borderColor={{\n        from: 'color',\n        modifiers: [['darker', 0.2]],\n      }}\n      arcLabel=\"id\"\n      arcLinkLabel={(d) => `${d.value}%`}\n      arcLinkLabelsSkipAngle={10}\n      arcLinkLabelsTextColor=\"#333333\"\n      arcLinkLabelsThickness={2}\n      arcLinkLabelsColor={{ from: 'color' }}\n      arcLabelsSkipAngle={10}\n      arcLabelsTextColor={{\n        from: 'color',\n        modifiers: [['darker', 2]],\n      }}\n      isInteractive={false}\n    />\n  )\n}\n```\n\n### Conclusion\n\nUsing nivo in a React environment made it easy to visualize data, which was very useful.\n\nThere are various chart libraries available, but I have not felt the need to use other libraries while using nivo, so I will continue to actively utilize nivo whenever I need charts in the future.",
      "width": 2000,
      "height": 1235
    },
    "optimistic-update": {
      "slug": "optimistic-update",
      "date": "2023-12-19T00:00:00.000Z",
      "title": "Optimistic Updates Using React Query",
      "description": "This post explains the process of implementing optimistic updates using React Query.",
      "tags": [
        "react-query",
        "optimistic update"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/optimistic-update/optimistic-X.gif",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRkoAAABXRUJQVlA4ID4AAADQAQCdASoNABAABUB8JZQAAl2+yUgLgAD+79eZWyJtlD1d+xfoiNvw13rI86QsDclAA0pffkQoLnd/IbgAAA==",
      "writer": "leey00nsu",
      "content": "\n## Performing Optimistic Updates with React Query\n\nWe are going to add a `like` feature to our project.\n\nWhen a user clicks the like button, we will call the API using `useMutation`.\n\n```jsx title=\"useMutation\"\nconst { mutate: toggleListLikeMutate } = useMutation({\n    mutationKey: ['toggleListLikeArticle'],\n    retry: false,\n    mutationFn: toggleLikeArticle,\n\t\t...\n})\n```\n\nTo display the result of the call on the screen, we can invalidate the corresponding `query key` through the `onSuccess` callback to refresh the data.\n\n```jsx title=\"onSuccess\"\nonSuccess: () => {\n    queryClient.invalidateQueries({ queryKey: ['getArticleList'] });\n},\n```\n\nHowever, depending on the network environment, **the UI will not change until the server responds.**\n\nTo improve the UX, we can use `Optimistic Updates`.\n\n### Optimistic Updates\n\n`Optimistic Updates` allow us to **immediately change the query data** to reflect the expected result when the `mutate` is successful.\n\nAccording to the [official documentation](https://tanstack.com/query/latest/docs/react/guides/optimistic-updates), the difference when using likes as an example is as follows:\n\n```markdown {5} title=\"Without Optimistic Updates\"\n-> Click like\n-> Request to the server\n-> Server response\n-> Refresh query with server data\n-> Client UI changes (Likes: 1, Like X → Likes: 2, Like O)\n```\n\n```markdown {3} title=\"With Optimistic Updates\"\n-> Click like\n-> Request to the server\n-> Client UI changes (Likes: 1, Like X → Likes: 2, Like O)\n-> Server response\n-> Refresh query with actual server data\n```\n\nLet's take a look at the actual implementation code.\n\n```jsx title=\"useToggleLike\"\nconst { mutateAsync: toggleLikeMutate } = useMutation({\n    mutationKey: ['toggleLikeArticle'],\n    retry: false,\n    mutationFn: toggleLikeArticle,\n    onMutate: async id => {\n\t\t\t// Cancel the detailed query. (to prevent optimistic update from overwriting)\n      await queryClient.cancelQueries({ queryKey: ['getArticle', id] });\n\n      const previousArticle = queryClient.getQueryData<\n        ApiResponse<ListArticle>\n      >(['getArticle', id]);\n\n      // Update the like status in the query data.\n      const uploadArticle = produce(previousArticle, draft => {\n        const article = draft?.data;\n        if (article) {\n          article.isLiked = !article?.isLiked;\n          article.likeCount += article?.isLiked ? 1 : -1;\n        }\n      });\n\n      // Apply the optimistic update to the query data.\n      queryClient.setQueryData(['getArticle', id], uploadArticle);\n\n      return { previousArticle, id };\n    },\n    onError: (err, _, context) => {\n\t\t\t// Rollback to the previous data in case of an error\n\t\t\tqueryClient.setQueryData(\n\t\t        ['getArticle', context?.id],\n\t\t        context?.previousArticle,\n\t\t      );\n    },\n    onSuccess: (err, _, context) => {\n\t\t\t// Re-fetch the query on success\n\t\t\tqueryClient.invalidateQueries({ queryKey: ['getArticle', context?.id] });\n    },\n  });\n```\n\nFirst, in the `onMutate` callback, we cancel the query using `cancelQueries`.\n\nThrough this process, **if an update occurs for that query key during the mutate, it will not be reflected.**\n\nThen, we modify the existing data to create the expected result.\n\nIn the example code, we used the immutability management library `immer` to modify the object.\n\nNow, when we apply the modified result to the corresponding query key, it will be updated as if **the server had responded.**\n\nAdditionally, if an error occurs, we can roll back to the previous query data, and on success, we can overwrite the data with the actual response.\n\nAlternatively, there is also a method to re-fetch regardless of the outcome using `onSettled`.\n\n```jsx title=\"onSettled\"\nonSettled: () => {\n      // Re-fetch the query on response\n      queryClient.invalidateQueries({\n        queryKey: [\n          'getArticleList',\n          currentOrderBy,\n          currentOrder,\n          filter.author,\n        ],\n      });\n    },\n```\n\n### Results\n\nLet's check the results of applying optimistic updates under `slow network conditions` in the browser.\n\n|                      Without Optimistic Updates                       |                      With Optimistic Updates                       |\n| :---------------------------------------------------------------: | :---------------------------------------------------------------: |\n| ![optimistic-X](/public/posts/optimistic-update/optimistic-X.gif) | ![optimistic-O](/public/posts/optimistic-update/optimistic-O.gif) |\n\nIt is clear at a glance that **the UI reflecting the optimistic update is faster.**\n\nSince it is not feasible to apply optimistic updates to all requests, considering where it can be applied can lead to **a better UX**.",
      "width": 374,
      "height": 454
    },
    "prettier-import-order": {
      "slug": "prettier-import-order",
      "date": "2023-11-05T00:00:00.000Z",
      "title": "Setting Up Prettier Import Order",
      "description": "This post explains how to sort import orders using Prettier.",
      "tags": [
        "prettier"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/prettier-import-order/messy-order.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRigAAABXRUJQVlA4IBwAAAAwAQCdASoQAAMABUB8JZwAA3AA/u4WN1ZGgAAA",
      "writer": "leey00nsu",
      "content": "\n## Sorting Import Order in Prettier\n\nAs you work on a project, imports can often pile up without any organization.\n\n![messy-order](/public/posts/prettier-import-order/messy-order.png)\n\n**By using Prettier to sort imports in a specific order, your code will be easier to read later on.**\n\nSo let's install the library that helps with this sorting, [prettier-plugin-sort-imports](https://github.com/trivago/prettier-plugin-sort-imports).\n\n```jsx title=\"@trivago/prettier-plugin-sort-imports\"\nnpm i @trivago/prettier-plugin-sort-imports\n```\n\nAfter installation, you need to add it to your existing Prettier configuration.\n\nIn my case, the configuration file is `.prettierrc`, so I added it there.\n\n```jsx title=\".prettierrc\"\n{\n\t...\n  \"importOrder\": [\n    \"<THIRD_PARTY_MODULES>\",\n    \"^@/constants/(.*)$\",\n    \"^@/apis/(.*)$\",\n    \"^@/store/(.*)$\",\n    \"^@/hooks/(.*)$\",\n    \"^@/pages/(.*)$\",\n    \"^@/features/(.*)$\",\n    \"^@/components/(.*)$\",\n    \"^@/ui/(.*)$\",\n    \"^[./]\"\n  ],\n  \"importOrderSeparation\": true,\n  \"importOrderSortSpecifiers\": true,\n  \"plugins\": [\n    \"@trivago/prettier-plugin-sort-imports\",\n\t\t...\n  ]\n}\n```\n\nYou specify the sorting order in `importOrder` using regular expressions.\n\nHere, `THIRD_PARTY_MODULES` refers to external libraries.\n\nSetting `importOrderSeparation` to true will add a blank line after each specified order.\n\n![ordered-order](/public/posts/prettier-import-order/ordered-order.png)\n\nNow, when you run Prettier again, you will see that the import order has been sorted.",
      "width": 1146,
      "height": 210
    },
    "react-infinite-scroll": {
      "slug": "react-infinite-scroll",
      "date": "2023-05-09T00:00:00.000Z",
      "title": "Implementing Infinite Scroll in React",
      "description": "This post explains how to implement infinite scroll in React.",
      "tags": [
        "react",
        "무한 스크롤"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/react-infinite-scroll/demo.gif",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRkQAAABXRUJQVlA4IDgAAACwAQCdASoIABAABUB8JaQAAucKdTAAAP68nwF/ysnuLP9aCe54uSJBvDTjGrkN88jnuKFZqIAAAA==",
      "writer": "leey00nsu",
      "content": "\n## Infinite Scroll\n\nWe want to implement a feature that adds to the list when it reaches the end by calling an API.\n\nThis method is commonly referred to as `Infinite Scroll`.\n\nThere are two ways to implement this functionality: **by monitoring the scroll event** and **by checking when the list enters the viewport**.\n\nHowever, the scroll event method can lead to performance issues and can be difficult to handle when there are many elements, so we will implement it using the viewport.\n\n### Implementation Using Intersection Observer API\n\nThe `Intersection Observer API` is one of the JavaScript APIs provided by the browser that **calls a callback function when an element appears or disappears from the viewport.**\n\nHere, we will implement a custom hook called `useIntersectionObserver`, but you can also use a custom hook library like `react-intersection-observer`.\n\n```jsx title=\"useIntersectionObserver\"\nimport { useRef } from \"react\";\nexport default function useIntersectionObserver(callback: () => void) {\n  const observer = useRef(\n    new IntersectionObserver(\n      (entries, observer) => {\n        entries.forEach((entry) => {\n          if (entry.isIntersecting) {\n            callback();\n          }\n        });\n      },\n      { threshold: 1 }\n    )\n  );\n\n  const observe = (element: any) => {\n    observer.current.observe(element);\n  };\n\n  const unObserve = (element: any) => {\n    observer.current.unobserve(element);\n  };\n\n  return [observe, unObserve];\n}\n```\n\nBy using `useRef`, we assign a ref property to the element that will serve as the reference point, and by registering this ref in the custom hook, the callback function will be executed every time this element appears in the viewport.\n\nHere, we will register a function that fetches the next page in the callback.\n\n```jsx title=\"useRef\"\n...\nconst infScroll = useRef(null);\n\nconst [observe, unObserve] = useIntersectionObserver(() => {\n  fetchNextPage(); // This function fetches the next page.\n});\n\nuseEffect(() => {\n    observe(infScroll.current);\n}, []);\n\n...\n\n<div ref={infScroll} >\n  ...\n</div>\n```\n\n### Result\n\n![infinite-scroll-demo](/public/posts/react-infinite-scroll/demo.gif)\n\nAs expected, when the end of the scroll is detected, we can see that the list continues to load.\n",
      "width": 600,
      "height": 1132
    },
    "syu-character-maker-retrospect": {
      "slug": "syu-character-maker-retrospect",
      "date": "2024-01-31T00:00:00.000Z",
      "title": "My Own Syu and Suho Character Creation Retrospective",
      "description": "Here are my thoughts on the project of creating my own Syu and Suho characters.",
      "tags": [
        "나만의 수야 수호 만들기",
        "회고"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/syu-character-maker-retrospect/syu-character-maker.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRlgAAABXRUJQVlA4IEwAAAAQAgCdASoQAAwABUB8JYgCdH8AE4hbWYIAAP7t2TKFgVfpxWwNQzz52hsFyxrgKkcmOkM0G688OWT3tPE41JUxGSne8Jo5vEPrZAAA",
      "writer": "leey00nsu",
      "content": "\r\n## My Own Syu and Suho Character Creation Retrospective\r\n\r\n### What is My Own Syu and Suho Character Creation?\r\n\r\nAfter a tumultuous first semester, I found myself with some free time after being rejected from all my internships.\r\n\r\nWhile pondering what to do, I decided to enhance a project that I had previously only set up a framework for.\r\n\r\nThat project is called `My Own Syu and Suho Character Creation`.\r\n\r\n`My Own Syu and Suho Character Creation` is a program that allows you to customize Syu and Suho, the mascots of Sahmyook University.\r\n\r\nThe idea was inspired by a project called [DevJeans](https://devjeans.dev-hee.com/).\r\n\r\nThe original structure involved selecting the characters Syu and Suho and drawing on them with a solid color pen.\r\n\r\n![syu-character-maker](/public/posts/syu-character-maker-retrospect/syu-character-maker.png)\r\n\r\n### How Will I Enhance It?\r\n\r\nCurrently, the project is a simple static page and is hosted through `vercel`.\r\n\r\nI plan to add a backend to the project and deploy both the frontend and backend on the `same domain`.\r\n\r\n### Why Deploy on the Same Domain?\r\n\r\nThe backend will use `nest` connected to `postgres` and `redis` to serve as a `REST API` server.\r\n\r\nSince users will need to save the drawings they create on the server, a `user authentication` feature is necessary.\r\n\r\nIn this case, I opted for a `session` method for user authentication, and here's why.\r\n\r\nIn previous team projects, whenever authentication was mentioned, everyone used the `jwt` method.\r\n\r\nAt that time, I thought it was just a common practice, but since I am responsible for the server this time, I needed a solid reason for my choice.\r\n\r\nCurious, I researched and found the characteristics and key differences between sessions and jwt as follows:\r\n\r\n> `Session`: The server stores information about the connected user and sends a session ID to the client.\r\n>\r\n> - Advantages: Since it is stored on the server, it is safe from exposure to the client. It is easy to expire on the server.\r\n> - Disadvantages: It can increase server load. Additionally, it complicates handling in a distributed environment.\r\n\r\n> `JWT`: A jwt is generated using user information and sent to the client.\r\n>\r\n> - Advantages: Since it is stored on the client, it reduces the burden on the server and makes it easy to share state in a distributed environment.\r\n> - Disadvantages: Since jwt is stored on the client, security must be considered. It is difficult to expire.\r\n\r\nIn fact, for the scale of the project I designed, it wouldn't matter which method I chose, so I decided to implement the session method, which I had never tried before.\r\n\r\nThe session ID is stored as a cookie on the client. Therefore, when the client **makes a request to the server, it must include the cookie in the header** for it to be processed.\r\n\r\nAt this point, the client must adhere to the notorious [CORS](https://evan-moon.github.io/2020/05/21/about-cors/) policy for frontend developers to send cookies.\r\n\r\n> For security reasons, browsers follow the Same-Origin Policy, which restricts access to resources only from the same origin.\r\n> However, since accessing resources from different domains occurs frequently, CORS (Cross-Origin Resource Sharing) allows access.\r\n\r\nTo comply with the CORS policy, the server must set the `response headers` accordingly.\r\n\r\nAdditionally, for security, the cookie's `HttpOnly` attribute should be set.\r\n\r\n```markdown title=\"CORS Settings\"\r\nAccess-Control-Allow-Origin: Indicates the allowed origin.\r\nAccess-Control-Allow-Methods: Indicates the allowed HTTP methods.\r\nAccess-Control-Allow-Credentials: Indicates whether to allow cookies and credentials.\r\n\r\nSameSite=None: Allows cookies to be included in cross-site requests at all times, but requires the Secure attribute.\r\nSameSite=Lax: Allows cookies to be included in cross-site requests only in certain situations (e.g., GET requests through navigation).\r\nSameSite=Strict: Restricts cookies from being sent in all cross-site requests.\r\n```\r\n\r\nThe client side must also set the `request headers` accordingly.\r\n\r\n```jsx title=\"Fetch or Axios Request Headers\"\r\ncredentials: include\r\n```\r\n\r\nAt this point, if the request header is set to `credentials: include` and `Access-Control-Allow-Origin` is set to '\\*', a browser error will occur.\r\n\r\nTherefore, **to send cookies from a different domain, you must specify the URL in `Access-Control-Allow-Origin`.**\r\n\r\nNow, we are ready to send cookies.\r\n\r\nTo send cookies to another domain, `SameSite=none` must be set, which requires `secure=true`.\r\n\r\nTo use secure, the protocol must be https, so the server's protocol needs to be changed to `https`. However, when the server's **protocol becomes https, it becomes a different domain from http**, so the client must also be changed to https.\r\n\r\nOnce everything is changed, the settings for cookie transmission are complete when both the client and server are https.\r\n\r\nI was also able to confirm that cookies were being transmitted correctly.\r\n\r\nHowever… **while conducting cross-browser testing, I discovered that cookies were not being transmitted in `safari`.**\r\n\r\n![safari-cookie-issue](/public/posts/syu-character-maker-retrospect/safari-cookie-issue.png)\r\n\r\nUpon searching, I found that **even if `SameSite=none` is set, Safari's default settings have changed to prevent cookies from being transmitted between different domains.**\r\n\r\nThus, **to accommodate Safari, the client and server must be on the same domain.**\r\n\r\n### Deploying on Oracle Cloud\r\n\r\nI concluded that the client and server must be deployed on the **same domain**.\r\n\r\nTherefore, the existing frontend, which was hosted on `vercel`, needs to be changed to be hosted on the cloud.\r\n\r\nThere are many well-known services in the cloud, such as `aws`, `gcp`, and `azure`. Most people commonly use aws.\r\n\r\nHowever, due to the **low performance of the free EC2 instances provided by aws**, I chose `oracle`.\r\n\r\n> Oracle Cloud, as a relatively latecomer, offers better performance for its free-tier instances (4 cores, 24 GB) compared to other cloud services and provides free outbound traffic up to 10TB.\r\n\r\nThe downside is that there is a **smaller user base, leading to less information and fewer solutions for errors.**\r\n\r\nStill, the performance aspect outweighs this disadvantage, so I decided on an Oracle instance.\r\n\r\nI had previously used aws, and although the terminology is slightly different, the basic structure of the services provided is similar, so I was able to adapt quickly.\r\n\r\nI also followed a well-organized [blog](https://sonhc.tistory.com/906) for the overall process.\r\n\r\n### Deployment Process\r\n\r\nThe project was structured as follows:\r\n\r\n![project-structure](/public/posts/syu-character-maker-retrospect/project-structure.png)\r\n\r\nI utilized `redis` as the session database along with `postgreSQL DB` in `nest`, and I made efforts to deploy easily using `docker` and `docker-compose`.\r\n\r\nIt was my first time setting this up, and after doing it once, I gained a good understanding of the overall flow of the project.\r\n\r\n### Conclusion\r\n\r\nWhile enhancing the project, I spent a lot of time thinking about **how to make it easy for users to use**.\r\n\r\nOf course, since the target user base is primarily students from the university, I didn't expect to attract a large number of users.\r\n\r\nHowever, out of curiosity about how many people would use it, I added `Google Analytics` to measure from the day of deployment.\r\n\r\n![everytime](/public/posts/syu-character-maker-retrospect/everytime.png)\r\n\r\n![analytics](/public/posts/syu-character-maker-retrospect/analytics.png)\r\n\r\nAfter deploying on January 3rd, about `300` people accessed the site, but it was clear that after a few days post-deployment, it did not attract much interest.\r\n\r\nThrough this deployment, I realized that **drawing in users is not an easy task**.\r\n\r\nNonetheless, I enjoyed the process of learning and creating, making it a satisfying project.\r\n",
      "width": 2000,
      "height": 1475
    },
    "taking-meal-retrospect": {
      "slug": "taking-meal-retrospect",
      "date": "2023-01-28T00:00:00.000Z",
      "title": "Reflection on Taking a Meal",
      "description": "A review of my experience after completing my first team project, Taking a Meal",
      "tags": [
        "react-native",
        "회고"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/taking-meal-retrospect/taking-meal-banner.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRk4AAABXRUJQVlA4IEIAAACQAQCdASoQAAkABUB8JbACdACWEYAA1wl6933/0ujVHOL7phxCIJroZERmBmpf/+BAhUx0ovic5bPfP60LO38gAAA=",
      "writer": "leey00nsu",
      "content": "\n## Taking a Meal\n\n![taking-meal-banner](/public/posts/taking-meal-retrospect/taking-meal-banner.png)\n\n[Taking a Meal](https://github.com/leey00nsu/TakingMeal) is a project created to participate in the Sookmyung Women's University SW competition.\n\nAt that time, I received a proposal from the GDSC lead and core members, along with a member from another club, and I accepted it.\n\nI had just transferred and was taking classes for one semester, spending my third-year summer vacation. It was not easy to solidify my programming basics in just one semester, and I was in need of additional study, so I was both happy and surprised to receive such a proposal. However, I believed that **project experience is the most important thing for a developer**, so I decided to participate in the project.\n\n### Role in the Team\n\nThe team consisted of 2 front-end developers, 2 back-end developers, and 1 designer, which could be considered ideal, but in reality, I was not much help on the front end (because I knew nothing). Therefore, the other front-end member took the lead while I followed along. The best part was that I could learn how to progress with the project. **It was my first time collaborating with the back end, and I realized that writing documentation, such as API specifications, was quite helpful for collaboration.**\n\nInitially, the project's goal was concretized into an app, and the lead front-end developer suggested developing it with React Native since he knew how to use React. At that time, I didn't know React, and naturally, I didn't know React Native either, so it didn't matter much to me. The lead front-end developer took charge of the map and store search features, while I was responsible for the nutrient chart, food search, and addition. Although I didn't fully understand React Native, I could make it work, so I focused on **development that prioritized functionality.**\n\n### Challenges Faced\n\nThe most challenging part of my role was drawing charts in React Native. I found a library called `victory-chart` that I liked and decided to use it, and there were no issues during testing, so I proceeded with development. However, during development, I noticed that rendering took too long on a specific screen, and upon checking, I found that there was a bottleneck in the chart section. Unable to find the cause, I gave up on the library and **decided to implement the chart myself.** Looking back, since it was just a simple bar graph, I could have made it quickly without using a library at all. When I attached the chart I created, it rendered quickly and worked well.\n\nAnother issue was the life cycle problem. At that time, I used a library called `react-native-tab-view` to implement screen swiping. Due to the way this library worked, all components were active when swiping between screens, so I had to be careful with `useEffect`. However, since I didn't know React well, I **overlooked dependencies and wrote numerous useEffects in one component, resulting in unexpected side effects and bugs.** At that time, I couldn't resolve these issues, so I finished the project by only fixing serious errors.\n\n### Reflection\n\nFor me, this was a significant first team project with a proper structure. Even as I write this reflection, I can't say that I handle React well, but I believe I have improved a lot since then. I have a desire to develop cross-platform applications, so I want to study more and take on a proper `react-native` project.\n",
      "width": 1920,
      "height": 1080
    },
    "why-i-do-not-use-vercel-anymore": {
      "slug": "why-i-do-not-use-vercel-anymore",
      "date": "2024-07-04T00:00:00.000Z",
      "title": "Why I Do Not Use Vercel Hosting Anymore",
      "description": "A story about moving from Vercel to the open-source self-hosting platform Coolify",
      "tags": [
        "ci/cd",
        "docker",
        "coolify"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/why-i-do-not-use-vercel-anymore/current-structure.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRigAAABXRUJQVlA4IBwAAAAwAQCdASoQAAwABUB8JZwAA3AA/vCTsLWcmgAA",
      "writer": "leey00nsu",
      "content": "\r\n## Why I Do Not Use Vercel Hosting Anymore\r\n\r\nUntil now, I have been deploying toy projects on `Oracle Cloud`.\r\n\r\n![current-structure](/public/posts/why-i-do-not-use-vercel-anymore/current-structure.png)\r\n\r\nI was using `Nginx` to apply SSL certificates and distribute connections through a reverse proxy for projects running on Docker.\r\n\r\nHowever, to add a new project in the current setup, I had to go through **cumbersome procedures** such as adding `Github Actions` to dockerize the project, adding the project to the Nginx configuration, and applying SSL.\r\n\r\n### Vercel\r\n\r\nTherefore, for static pages or Next.js projects, I also deployed them through [Vercel](https://vercel.com/).\r\n\r\nUsing Vercel's hosting service allows for easy CI/CD setup by automatically linking to GitHub repositories and deploying easily.\r\n\r\nHowever, while Vercel offers a free plan by default, costs may need to be considered if advanced features are required or if high traffic needs to be handled.\r\n\r\nAdditionally, to comfortably host projects like Nest.js and other container-based projects, I began to consider leaving Vercel for **the self-hosting approach using my existing Oracle Cloud.**\r\n\r\n### Coolify\r\n\r\n> Self-hosting with superpowers. An open-source & self-hostable Heroku / Netlify / Vercel alternative.\r\n\r\n`Coolify` is an open-source self-hosting platform that helps developers easily deploy and manage applications, providing features to manage infrastructure conveniently and deploy various applications, making it a viable alternative to managed services like **Vercel, Heroku, and Netlify.**\r\n\r\n### Why Coolify?\r\n\r\nSo why did I choose Coolify among various self-hosting platforms?\r\n\r\n1. **Self-hosting Platform**\r\n\r\n- `Coolify` is a self-hosting platform that users can install and operate directly on their own servers. This allows for cost savings and complete control over data and applications.\r\n\r\n2. **Support for Various Applications**\r\n\r\n- It supports applications written in various programming languages such as Node.js, Python, Ruby, and PHP. Applications written in any language can be easily deployed through Docker images.\r\n\r\n3. **Automated CI/CD Pipeline**\r\n\r\n- It provides a CI/CD pipeline that integrates with Git repositories, automatically building and deploying whenever code changes occur.\r\n\r\n4. **Easy Setup and Management**\r\n\r\n- Applications and servers can be easily set up and managed through an intuitive web interface. Applications can be deployed conveniently without complex configurations.\r\n\r\n5. **SSL/TLS Support**\r\n\r\n- Integrated with `Let's Encrypt`, it automatically issues and renews SSL/TLS certificates, making it easy to maintain security settings.\r\n\r\n6. **Reverse Proxy and Load Balancing**\r\n\r\n- It uses reverse proxies and load balancers like `Traefik` to efficiently manage traffic and maintain high availability.\r\n\r\n7. **Rolling Update Support**\r\n\r\n- The rolling update feature allows applications to be updated gradually without downtime. This helps maintain service continuity and ensures stability.\r\n\r\n8. **Monitoring and Logging**\r\n\r\n- It monitors the performance and status of applications and collects logs to quickly resolve issues.\r\n\r\n### Getting Started with Coolify\r\n\r\nTo get started with Coolify, you just need to run a simple bash command. Detailed instructions can be found in the [official documentation](https://coolify.io/docs/installation).\r\n\r\n```bash title=\"Install Coolify\"\r\ncurl -fsSL https://cdn.coollabs.io/coolify/install.sh | bash\r\n```\r\n\r\nOnce the installation is complete, you can access the Coolify dashboard at http://localhost:8000.\r\n\r\n![dashboard](/public/posts/why-i-do-not-use-vercel-anymore/dashboard.png)\r\n\r\n### Domain Setup\r\n\r\nTo set the domain for a Coolify project, you need to obtain a domain through a domain provider service like `Gabia`.\r\n\r\nAt this time, if you set up a **`wildcard domain`**, you can dynamically configure subdomains like project1.domain, project2.domain, ... as projects continue to be added.\r\n\r\n### Deployment\r\n\r\n![deploy](/public/posts/why-i-do-not-use-vercel-anymore/deploy.png)\r\n\r\nYou can add projects through the UI and start new deployments.\r\n\r\nBy default, Coolify uses a build pack called [Nixpacks](https://nixpacks.com/docs) to **detect the type of application being deployed and build accordingly.**\r\n\r\nAdditionally, you can deploy projects using `Docker images` or `Docker Compose` files, and you can also use applications that are pre-configured in Coolify.\r\n\r\nOnce a project is deployed, it will automatically be redeployed whenever a new commit occurs.\r\n\r\n### Zero-Downtime Deployment\r\n\r\n![rolling-updates](/public/posts/why-i-do-not-use-vercel-anymore/rolling-updates.png)\r\n\r\nCoolify also provides a `rolling update` feature, allowing for zero-downtime services during application deployment.\r\n\r\n1. **Container-Based Deployment**\r\n\r\n- Coolify primarily deploys containerized applications. It uses container technologies like Docker to run applications in isolated environments.\r\n\r\n2. **Incremental Instance Updates**\r\n\r\n- It updates application instances one at a time. For example, if 10 instances are running, it first updates one, and if that update is successful, it proceeds to update the next instance.\r\n\r\n3. **Load Balancing**\r\n\r\n- Instances that are not being updated continue to handle traffic. This helps maintain service continuity. Coolify uses load balancers like Traefik to manage traffic.\r\n\r\n4. **Health Checks**\r\n\r\n- After each instance is updated, Coolify checks the status of that instance. Only instances that pass the health check are allowed to handle traffic.\r\n\r\n5. **Automatic Rollback**\r\n\r\n- If an issue is found with an updated instance, Coolify rolls that instance back to the previous version. This helps ensure stability.\r\n\r\n### Conclusion\r\n\r\nIf you can accept the limitation that a certain level of instance specifications must be guaranteed to use Coolify, **I am currently satisfied with the move from Vercel to Coolify.**\r\n\r\nWhile exploring Coolify, I saw a YouTuber refer to Coolify as [Kubernetes for Babies](https://www.youtube.com/shorts/LrKqptIOFTw).\r\n\r\nKubernetes has a reputation for being difficult, making it hard to approach, but **Coolify seems to provide an easy way to experience tools for deploying, scaling, and managing containerized applications.**",
      "width": 5384,
      "height": 4201
    },
    "why-use-react-query": {
      "slug": "why-use-react-query",
      "date": "2023-08-02T00:00:00.000Z",
      "title": "Why Should We Use React Query?",
      "description": "This post explains how to use React Query for handling asynchronous functions.",
      "tags": [
        "react",
        "react-query",
        "artfolio"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/why-use-react-query/query-structure.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRiwAAABXRUJQVlA4ICAAAAAwAQCdASoQAAYABUB8JaQAA3AA/vCAarNcLCP6Ur44AA==",
      "writer": "leey00nsu",
      "content": "\n## Why Should We Use React Query?\n\nWhen you search for `react-query`, you will find that it is described as follows:\n\n> React Query is **a data-fetching and state management library for React applications that simplifies fetching, caching, and updating data**.\n\nAs the description states, `react-query` is a library that helps manage, cache, and update asynchronous data in React applications.\n\nDuring the `artfolio` project, we adopted the approach of using react-query to manage asynchronous operations instead of the previous method using `useEffect`.\n\nLet's take a look at the code for asynchronous processing using the existing useEffect.\n\n### Code Using useEffect\n\n```jsx title=\"useEffect\"\nimport React, { useEffect, useState } from 'react'\n\nfunction App() {\n  const [data, setData] = useState(null)\n  const [isLoading, setIsLoading] = useState(false)\n  const [error, setError] = useState(null)\n\n  useEffect(() => {\n    setIsLoading(true)\n    fetchData()\n      .then((response) => {\n        setData(response.data)\n        setIsLoading(false)\n      })\n      .catch((error) => {\n        setError(error)\n        setIsLoading(false)\n      })\n  }, [])\n\n  return (\n    <div>\n      {isLoading ? <p>Loading...</p> : null}\n      {error ? <p>Error: {error.message}</p> : null}\n      {data ? <p>Data: {data}</p> : null}\n    </div>\n  )\n}\n\nexport default App\n```\n\nOn the other hand, using react-query allows us to write more concise code.\n\n### Code Using react-query\n\n```jsx title=\"react-query\"\nimport React from 'react'\nimport { useQuery } from 'react-query'\n\nfunction App() {\n  const { data, isLoading, error } = useQuery('data', fetchData)\n\n  return (\n    <div>\n      {isLoading ? <p>Loading...</p> : null}\n      {error ? <p>Error: {error.message}</p> : null}\n      {data ? <p>Data: {data}</p> : null}\n    </div>\n  )\n}\n\nexport default App\n```\n\n`useQuery` is a hook provided by react-query that is used to fetch data asynchronously.\n\n```jsx title=\"useQuery\"\nconst { data, ...options } = useQuery(queryKey, queryFunction, options)\n```\n\n- `queryKey`: The query key indicates what data to fetch.\n- `queryFunction`: The function that fetches the data and must return a `Promise`.\n- `options`: Various options can be provided.\n\n## Introduction to useQuery\n\nNow, let's look at an example applied in the actual `artfolio` project.\n\n![description](/public/posts/why-use-react-query/description.png)\n\nThe image above shows the auction detail page.\n\nThe 22,350 won shown above and below represents the current auction price, and **the current auction price must be synchronized in real-time with the server data due to the WebSocket integration.**\n\nTherefore, the moment you click to bid, the current auction price is updated, and both components should display the same value.\n\nWhile it may seem like a simple task of passing data down through props drilling from a parent component, \n\n**the two components are not in a parent-child relationship and are separate, so they need to be managed globally or each needs to make requests to the server.**\n\nAt this point, I thought managing server data as a global state was not a good approach, so I considered another method.\n\n<br />\n\nThis issue was resolved by using the `queryKey`, which allows both components to fetch the same cached data when the same query key is used during requests.\n\nTo simplify the process, it can be described as follows.\n\n![query-structure](/public/posts/why-use-react-query/query-structure.png)\n\nWhen applied in practice, you can see that the auction page content (chart) changes simultaneously with the bid.\n\n![result](/public/posts/why-use-react-query/result.gif)\n\n## Conclusion\n\nIn addition to this, I have mostly used react-query when working with asynchronous functions.\n\nWith variables like isLoading and isError, you can track the data state, and there are many convenient features such as automatic fetching of data based on query options and setting expiration times, so I plan to continue using it in the future.",
      "width": 1642,
      "height": 606
    },
    "why-use-ui-library": {
      "slug": "why-use-ui-library",
      "date": "2024-05-19T00:00:00.000Z",
      "title": "Reasons to Use a Frontend UI Library",
      "description": "This post explains the reasons for using a frontend UI library.",
      "tags": [
        "design",
        "mantine"
      ],
      "section": "blog",
      "series": null,
      "thumbnail": "/public/posts/why-use-ui-library/mantine.png",
      "draft": false,
      "blurDataURL": "data:image/webp;base64,UklGRkIAAABXRUJQVlA4IDYAAADQAQCdASoQAAoABUB8JQBdgCHw+HpBwAD+1Ouizja34DlSdAPW0ALU1qFq0jqQ90JVQxQAAAA=",
      "writer": "leey00nsu",
      "content": "\r\n## Reasons to Use a Frontend UI Library\r\n\r\n![mantine](/public/posts/why-use-ui-library/mantine.png)\r\n\r\nIn the recent [noveloper](https://github.com/leey00nsu/noveloper) project, I used the UI library Mantine.\r\n\r\nAdditionally, I have used various frontend UI libraries such as `bootstrap`, `shadcn`, `daisyUI`, and `NextUI` in most of the projects I have worked on.\r\n\r\nSo, why did I use these **libraries**?\r\n\r\n### There's No Need to Reinvent the Wheel\r\n\r\n**Building all components from scratch and styling them from the ground up is not an easy task.**\r\n\r\nEven if you create visually appealing components using `CSS`, you still need to consider aspects such as `browser compatibility`, `accessibility`, `responsive design`, and `performance`.\r\n\r\nUI libraries take these factors into account, **testing and developing components, and maintaining them through the community, which allows for a more efficient solution than handling everything alone.**\r\n\r\n![mantine-issue](/public/posts/why-use-ui-library/mantine-issue.png)\r\n(With 24.7k stars, Mantine has only 24 issues, indicating how well it is maintained.)\r\n\r\nMoreover, using pre-built components allows for rapid prototyping of projects.\r\n\r\n### Frontend Developers and Designers\r\n\r\n**I am not good at design.**\r\n\r\nHowever, as a frontend developer, providing users with a **clean UI** has always been a concern for me.\r\n\r\nEnsuring that different UI components maintain consistency is not an easy task.\r\n\r\nUI libraries generally have a consistent design and present a clean and organized appearance, making them excellent as a **base design**.\r\n\r\n### Design Systems and Customization\r\n\r\nThat said, not all projects using a UI library will have the same design.\r\n\r\nMost libraries offer **customization options for individual components, as well as the ability to modify themes for overall project customization, allowing you to build a `design system` tailored to each project.**\r\n\r\nFor example, you can find out why Inflab developed its design system based on the open-source Mantine in their article on [building a design system](https://tech.inflab.com/20240224-design-system/).\r\n\r\n### Drawbacks\r\n\r\nSo, is using a UI library **always the right choice?**\r\n\r\nIt's important to consider the following drawbacks as well:\r\n\r\n- `Open Source`: Open-source projects always carry the risk of maintenance being halted. Additionally, the development direction of the open-source library may differ from what the project desires.\r\n- `Bundle Size`: Including all components of the library in the code can lead to performance issues.\r\n- `Dependencies`: If the UI library depends on other libraries, issues may arise during version updates.\r\n- `Learning Curve`: The team will need time to learn the library.\r\n\r\nTherefore, it seems wise to choose a UI library based on project requirements through discussions among team members.\r\n\r\n### Conclusion\r\n\r\nWhile I have used various UI libraries throughout my projects, I initially thought of it simply as a matter of convenience.\r\n\r\nBy posting this article, I feel that I can clearly articulate the reasons I had in mind while also exploring the thoughts of other developers regarding the use of UI libraries.",
      "width": 2268,
      "height": 1440
    }
  }
} as const satisfies GeneratedPostsMap
